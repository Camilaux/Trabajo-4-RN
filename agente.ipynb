{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader, TextLoader, Docx2txtLoader\n",
    "from langchain_community.document_loaders import UnstructuredWordDocumentLoader\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\hp\\documents\\trabajo-4-rn\\venv\\lib\\site-packages (0.3.19)\n",
      "Requirement already satisfied: langchain-community in c:\\users\\hp\\documents\\trabajo-4-rn\\venv\\lib\\site-packages (0.3.18)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.35 in c:\\users\\hp\\documents\\trabajo-4-rn\\venv\\lib\\site-packages (from langchain) (0.3.40)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.6 in c:\\users\\hp\\documents\\trabajo-4-rn\\venv\\lib\\site-packages (from langchain) (0.3.6)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in c:\\users\\hp\\documents\\trabajo-4-rn\\venv\\lib\\site-packages (from langchain) (0.3.11)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\hp\\documents\\trabajo-4-rn\\venv\\lib\\site-packages (from langchain) (2.10.6)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\hp\\documents\\trabajo-4-rn\\venv\\lib\\site-packages (from langchain) (2.0.38)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\hp\\documents\\trabajo-4-rn\\venv\\lib\\site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\hp\\documents\\trabajo-4-rn\\venv\\lib\\site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\hp\\documents\\trabajo-4-rn\\venv\\lib\\site-packages (from langchain) (3.11.13)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\users\\hp\\documents\\trabajo-4-rn\\venv\\lib\\site-packages (from langchain) (9.0.0)\n",
      "Requirement already satisfied: numpy<3,>=1.26.2 in c:\\users\\hp\\documents\\trabajo-4-rn\\venv\\lib\\site-packages (from langchain) (2.2.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\hp\\documents\\trabajo-4-rn\\venv\\lib\\site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in c:\\users\\hp\\documents\\trabajo-4-rn\\venv\\lib\\site-packages (from langchain-community) (2.8.1)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in c:\\users\\hp\\documents\\trabajo-4-rn\\venv\\lib\\site-packages (from langchain-community) (0.4.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\hp\\documents\\trabajo-4-rn\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.8)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\hp\\documents\\trabajo-4-rn\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\hp\\documents\\trabajo-4-rn\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\hp\\documents\\trabajo-4-rn\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\hp\\documents\\trabajo-4-rn\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\hp\\documents\\trabajo-4-rn\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\hp\\documents\\trabajo-4-rn\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\hp\\documents\\trabajo-4-rn\\venv\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\hp\\documents\\trabajo-4-rn\\venv\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\hp\\documents\\trabajo-4-rn\\venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.35->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\hp\\documents\\trabajo-4-rn\\venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.35->langchain) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\hp\\documents\\trabajo-4-rn\\venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.35->langchain) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\hp\\documents\\trabajo-4-rn\\venv\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\hp\\documents\\trabajo-4-rn\\venv\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.15)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\hp\\documents\\trabajo-4-rn\\venv\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\hp\\documents\\trabajo-4-rn\\venv\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\hp\\documents\\trabajo-4-rn\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\hp\\documents\\trabajo-4-rn\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\hp\\documents\\trabajo-4-rn\\venv\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.0.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hp\\documents\\trabajo-4-rn\\venv\\lib\\site-packages (from requests<3,>=2->langchain) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hp\\documents\\trabajo-4-rn\\venv\\lib\\site-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hp\\documents\\trabajo-4-rn\\venv\\lib\\site-packages (from requests<3,>=2->langchain) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\documents\\trabajo-4-rn\\venv\\lib\\site-packages (from requests<3,>=2->langchain) (2025.1.31)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\hp\\documents\\trabajo-4-rn\\venv\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\hp\\documents\\trabajo-4-rn\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (4.8.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\hp\\documents\\trabajo-4-rn\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\hp\\documents\\trabajo-4-rn\\venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\hp\\documents\\trabajo-4-rn\\venv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.35->langchain) (3.0.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\hp\\documents\\trabajo-4-rn\\venv\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\hp\\documents\\trabajo-4-rn\\venv\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install langchain_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pypdf\n",
      "  Downloading pypdf-5.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Downloading pypdf-5.3.1-py3-none-any.whl (302 kB)\n",
      "   ---------------------------------------- 0.0/302.0 kB ? eta -:--:--\n",
      "   - -------------------------------------- 10.2/302.0 kB ? eta -:--:--\n",
      "   ------------------------------------ --- 276.5/302.0 kB 3.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 302.0/302.0 kB 3.1 MB/s eta 0:00:00\n",
      "Installing collected packages: pypdf\n",
      "Successfully installed pypdf-5.3.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence-transformers\n",
      "  Downloading sentence_transformers-3.4.1-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting transformers<5.0.0,>=4.41.0 (from sentence-transformers)\n",
      "  Downloading transformers-4.49.0-py3-none-any.whl.metadata (44 kB)\n",
      "     ---------------------------------------- 0.0/44.0 kB ? eta -:--:--\n",
      "     ----------------- -------------------- 20.5/44.0 kB 682.7 kB/s eta 0:00:01\n",
      "     -------------------------------------- 44.0/44.0 kB 718.8 kB/s eta 0:00:00\n",
      "Collecting tqdm (from sentence-transformers)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "     ---------------------------------------- 0.0/57.7 kB ? eta -:--:--\n",
      "     ---------------------------------------- 57.7/57.7 kB 3.2 MB/s eta 0:00:00\n",
      "Collecting torch>=1.11.0 (from sentence-transformers)\n",
      "  Downloading torch-2.6.0-cp312-cp312-win_amd64.whl.metadata (28 kB)\n",
      "Collecting scikit-learn (from sentence-transformers)\n",
      "  Using cached scikit_learn-1.6.1-cp312-cp312-win_amd64.whl.metadata (15 kB)\n",
      "Collecting scipy (from sentence-transformers)\n",
      "  Downloading scipy-1.15.2-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "     ---------------------------------------- 0.0/60.8 kB ? eta -:--:--\n",
      "     ---------------------------------------- 60.8/60.8 kB 3.2 MB/s eta 0:00:00\n",
      "Collecting huggingface-hub>=0.20.0 (from sentence-transformers)\n",
      "  Downloading huggingface_hub-0.29.1-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting Pillow (from sentence-transformers)\n",
      "  Downloading pillow-11.1.0-cp312-cp312-win_amd64.whl.metadata (9.3 kB)\n",
      "Collecting filelock (from huggingface-hub>=0.20.0->sentence-transformers)\n",
      "  Downloading filelock-3.17.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub>=0.20.0->sentence-transformers)\n",
      "  Downloading fsspec-2025.2.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\hp\\documents\\trabajo-4-rn\\venv\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\hp\\documents\\trabajo-4-rn\\venv\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: requests in c:\\users\\hp\\documents\\trabajo-4-rn\\venv\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\hp\\documents\\trabajo-4-rn\\venv\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.12.2)\n",
      "Collecting networkx (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting jinja2 (from torch>=1.11.0->sentence-transformers)\n",
      "  Using cached jinja2-3.1.5-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting setuptools (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading setuptools-75.8.2-py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting sympy==1.13.1 (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch>=1.11.0->sentence-transformers)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\hp\\documents\\trabajo-4-rn\\venv\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\hp\\documents\\trabajo-4-rn\\venv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.2.3)\n",
      "Collecting regex!=2019.12.17 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Downloading regex-2024.11.6-cp312-cp312-win_amd64.whl.metadata (41 kB)\n",
      "     ---------------------------------------- 0.0/41.5 kB ? eta -:--:--\n",
      "     ---------------------------------------- 41.5/41.5 kB 2.1 MB/s eta 0:00:00\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Downloading tokenizers-0.21.0-cp39-abi3-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Downloading safetensors-0.5.3-cp38-abi3-win_amd64.whl.metadata (3.9 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn->sentence-transformers)\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn->sentence-transformers)\n",
      "  Using cached threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch>=1.11.0->sentence-transformers)\n",
      "  Using cached MarkupSafe-3.0.2-cp312-cp312-win_amd64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hp\\documents\\trabajo-4-rn\\venv\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hp\\documents\\trabajo-4-rn\\venv\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hp\\documents\\trabajo-4-rn\\venv\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\documents\\trabajo-4-rn\\venv\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.1.31)\n",
      "Downloading sentence_transformers-3.4.1-py3-none-any.whl (275 kB)\n",
      "   ---------------------------------------- 0.0/275.9 kB ? eta -:--:--\n",
      "   ------------------------------------- - 266.2/275.9 kB 16.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 275.9/275.9 kB 8.6 MB/s eta 0:00:00\n",
      "Downloading huggingface_hub-0.29.1-py3-none-any.whl (468 kB)\n",
      "   ---------------------------------------- 0.0/468.0 kB ? eta -:--:--\n",
      "   --------------------------------------  460.8/468.0 kB 14.5 MB/s eta 0:00:01\n",
      "   --------------------------------------- 468.0/468.0 kB 10.0 MB/s eta 0:00:00\n",
      "Downloading torch-2.6.0-cp312-cp312-win_amd64.whl (204.1 MB)\n",
      "   ---------------------------------------- 0.0/204.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.6/204.1 MB 12.2 MB/s eta 0:00:17\n",
      "   ---------------------------------------- 1.2/204.1 MB 13.2 MB/s eta 0:00:16\n",
      "   ---------------------------------------- 1.6/204.1 MB 12.5 MB/s eta 0:00:17\n",
      "   ---------------------------------------- 2.3/204.1 MB 13.2 MB/s eta 0:00:16\n",
      "    --------------------------------------- 3.0/204.1 MB 13.8 MB/s eta 0:00:15\n",
      "    --------------------------------------- 3.6/204.1 MB 13.6 MB/s eta 0:00:15\n",
      "    --------------------------------------- 4.2/204.1 MB 12.8 MB/s eta 0:00:16\n",
      "    --------------------------------------- 4.8/204.1 MB 12.7 MB/s eta 0:00:16\n",
      "   - -------------------------------------- 5.6/204.1 MB 13.3 MB/s eta 0:00:15\n",
      "   - -------------------------------------- 6.1/204.1 MB 13.4 MB/s eta 0:00:15\n",
      "   - -------------------------------------- 6.7/204.1 MB 13.4 MB/s eta 0:00:15\n",
      "   - -------------------------------------- 7.4/204.1 MB 13.2 MB/s eta 0:00:15\n",
      "   - -------------------------------------- 8.0/204.1 MB 13.4 MB/s eta 0:00:15\n",
      "   - -------------------------------------- 8.6/204.1 MB 13.5 MB/s eta 0:00:15\n",
      "   - -------------------------------------- 9.2/204.1 MB 13.4 MB/s eta 0:00:15\n",
      "   - -------------------------------------- 10.0/204.1 MB 13.7 MB/s eta 0:00:15\n",
      "   -- ------------------------------------- 10.8/204.1 MB 13.9 MB/s eta 0:00:14\n",
      "   -- ------------------------------------- 11.6/204.1 MB 13.9 MB/s eta 0:00:14\n",
      "   -- ------------------------------------- 12.3/204.1 MB 14.2 MB/s eta 0:00:14\n",
      "   -- ------------------------------------- 13.0/204.1 MB 14.6 MB/s eta 0:00:14\n",
      "   -- ------------------------------------- 13.9/204.1 MB 14.9 MB/s eta 0:00:13\n",
      "   -- ------------------------------------- 14.8/204.1 MB 15.2 MB/s eta 0:00:13\n",
      "   --- ------------------------------------ 15.5/204.1 MB 15.6 MB/s eta 0:00:13\n",
      "   --- ------------------------------------ 16.3/204.1 MB 15.2 MB/s eta 0:00:13\n",
      "   --- ------------------------------------ 16.9/204.1 MB 15.2 MB/s eta 0:00:13\n",
      "   --- ------------------------------------ 17.8/204.1 MB 15.6 MB/s eta 0:00:12\n",
      "   --- ------------------------------------ 18.5/204.1 MB 15.6 MB/s eta 0:00:12\n",
      "   --- ------------------------------------ 19.1/204.1 MB 15.6 MB/s eta 0:00:12\n",
      "   --- ------------------------------------ 19.7/204.1 MB 15.6 MB/s eta 0:00:12\n",
      "   --- ------------------------------------ 20.4/204.1 MB 15.2 MB/s eta 0:00:13\n",
      "   ---- ----------------------------------- 20.9/204.1 MB 15.6 MB/s eta 0:00:12\n",
      "   ---- ----------------------------------- 21.5/204.1 MB 15.2 MB/s eta 0:00:12\n",
      "   ---- ----------------------------------- 22.3/204.1 MB 15.2 MB/s eta 0:00:12\n",
      "   ---- ----------------------------------- 23.2/204.1 MB 15.6 MB/s eta 0:00:12\n",
      "   ---- ----------------------------------- 23.9/204.1 MB 15.2 MB/s eta 0:00:12\n",
      "   ---- ----------------------------------- 24.6/204.1 MB 14.9 MB/s eta 0:00:13\n",
      "   ---- ----------------------------------- 25.4/204.1 MB 14.9 MB/s eta 0:00:13\n",
      "   ----- ---------------------------------- 26.1/204.1 MB 14.9 MB/s eta 0:00:12\n",
      "   ----- ---------------------------------- 26.8/204.1 MB 14.9 MB/s eta 0:00:12\n",
      "   ----- ---------------------------------- 27.5/204.1 MB 15.2 MB/s eta 0:00:12\n",
      "   ----- ---------------------------------- 28.1/204.1 MB 15.2 MB/s eta 0:00:12\n",
      "   ----- ---------------------------------- 28.9/204.1 MB 15.6 MB/s eta 0:00:12\n",
      "   ----- ---------------------------------- 29.8/204.1 MB 15.6 MB/s eta 0:00:12\n",
      "   ----- ---------------------------------- 30.4/204.1 MB 15.6 MB/s eta 0:00:12\n",
      "   ------ --------------------------------- 31.3/204.1 MB 16.0 MB/s eta 0:00:11\n",
      "   ------ --------------------------------- 31.9/204.1 MB 16.0 MB/s eta 0:00:11\n",
      "   ------ --------------------------------- 32.4/204.1 MB 16.0 MB/s eta 0:00:11\n",
      "   ------ --------------------------------- 33.0/204.1 MB 15.6 MB/s eta 0:00:11\n",
      "   ------ --------------------------------- 33.7/204.1 MB 15.6 MB/s eta 0:00:11\n",
      "   ------ --------------------------------- 34.4/204.1 MB 16.0 MB/s eta 0:00:11\n",
      "   ------ --------------------------------- 35.2/204.1 MB 16.0 MB/s eta 0:00:11\n",
      "   ------ --------------------------------- 35.7/204.1 MB 16.4 MB/s eta 0:00:11\n",
      "   ------- -------------------------------- 36.5/204.1 MB 16.4 MB/s eta 0:00:11\n",
      "   ------- -------------------------------- 37.5/204.1 MB 16.8 MB/s eta 0:00:10\n",
      "   ------- -------------------------------- 38.3/204.1 MB 16.8 MB/s eta 0:00:10\n",
      "   ------- -------------------------------- 39.3/204.1 MB 16.8 MB/s eta 0:00:10\n",
      "   ------- -------------------------------- 40.2/204.1 MB 16.8 MB/s eta 0:00:10\n",
      "   -------- ------------------------------- 40.9/204.1 MB 17.3 MB/s eta 0:00:10\n",
      "   -------- ------------------------------- 41.4/204.1 MB 16.8 MB/s eta 0:00:10\n",
      "   -------- ------------------------------- 42.0/204.1 MB 17.2 MB/s eta 0:00:10\n",
      "   -------- ------------------------------- 42.9/204.1 MB 18.2 MB/s eta 0:00:09\n",
      "   -------- ------------------------------- 43.6/204.1 MB 18.2 MB/s eta 0:00:09\n",
      "   -------- ------------------------------- 44.4/204.1 MB 17.7 MB/s eta 0:00:10\n",
      "   -------- ------------------------------- 45.2/204.1 MB 17.7 MB/s eta 0:00:09\n",
      "   -------- ------------------------------- 45.8/204.1 MB 17.7 MB/s eta 0:00:09\n",
      "   --------- ------------------------------ 46.6/204.1 MB 17.7 MB/s eta 0:00:09\n",
      "   --------- ------------------------------ 47.3/204.1 MB 17.7 MB/s eta 0:00:09\n",
      "   --------- ------------------------------ 48.1/204.1 MB 17.7 MB/s eta 0:00:09\n",
      "   --------- ------------------------------ 48.8/204.1 MB 17.2 MB/s eta 0:00:10\n",
      "   --------- ------------------------------ 49.4/204.1 MB 17.2 MB/s eta 0:00:09\n",
      "   --------- ------------------------------ 50.3/204.1 MB 16.8 MB/s eta 0:00:10\n",
      "   ---------- ----------------------------- 51.1/204.1 MB 17.2 MB/s eta 0:00:09\n",
      "   ---------- ----------------------------- 52.0/204.1 MB 16.4 MB/s eta 0:00:10\n",
      "   ---------- ----------------------------- 52.7/204.1 MB 16.4 MB/s eta 0:00:10\n",
      "   ---------- ----------------------------- 53.7/204.1 MB 16.4 MB/s eta 0:00:10\n",
      "   ---------- ----------------------------- 54.4/204.1 MB 16.4 MB/s eta 0:00:10\n",
      "   ---------- ----------------------------- 55.2/204.1 MB 16.4 MB/s eta 0:00:10\n",
      "   ---------- ----------------------------- 55.8/204.1 MB 16.4 MB/s eta 0:00:10\n",
      "   ----------- ---------------------------- 56.7/204.1 MB 16.4 MB/s eta 0:00:10\n",
      "   ----------- ---------------------------- 57.3/204.1 MB 16.4 MB/s eta 0:00:09\n",
      "   ----------- ---------------------------- 58.0/204.1 MB 16.4 MB/s eta 0:00:09\n",
      "   ----------- ---------------------------- 58.8/204.1 MB 16.4 MB/s eta 0:00:09\n",
      "   ----------- ---------------------------- 59.6/204.1 MB 16.4 MB/s eta 0:00:09\n",
      "   ----------- ---------------------------- 60.3/204.1 MB 16.4 MB/s eta 0:00:09\n",
      "   ----------- ---------------------------- 61.0/204.1 MB 16.4 MB/s eta 0:00:09\n",
      "   ------------ --------------------------- 61.8/204.1 MB 16.4 MB/s eta 0:00:09\n",
      "   ------------ --------------------------- 62.6/204.1 MB 16.8 MB/s eta 0:00:09\n",
      "   ------------ --------------------------- 63.3/204.1 MB 16.4 MB/s eta 0:00:09\n",
      "   ------------ --------------------------- 63.9/204.1 MB 16.4 MB/s eta 0:00:09\n",
      "   ------------ --------------------------- 64.8/204.1 MB 16.4 MB/s eta 0:00:09\n",
      "   ------------ --------------------------- 65.4/204.1 MB 16.4 MB/s eta 0:00:09\n",
      "   ------------ --------------------------- 66.3/204.1 MB 16.8 MB/s eta 0:00:09\n",
      "   ------------- -------------------------- 67.3/204.1 MB 17.3 MB/s eta 0:00:08\n",
      "   ------------- -------------------------- 68.1/204.1 MB 17.3 MB/s eta 0:00:08\n",
      "   ------------- -------------------------- 69.0/204.1 MB 16.8 MB/s eta 0:00:09\n",
      "   ------------- -------------------------- 69.6/204.1 MB 16.8 MB/s eta 0:00:09\n",
      "   ------------- -------------------------- 70.4/204.1 MB 17.2 MB/s eta 0:00:08\n",
      "   ------------- -------------------------- 71.2/204.1 MB 17.2 MB/s eta 0:00:08\n",
      "   -------------- ------------------------- 72.0/204.1 MB 17.2 MB/s eta 0:00:08\n",
      "   -------------- ------------------------- 72.5/204.1 MB 16.8 MB/s eta 0:00:08\n",
      "   -------------- ------------------------- 73.1/204.1 MB 16.8 MB/s eta 0:00:08\n",
      "   -------------- ------------------------- 73.8/204.1 MB 16.8 MB/s eta 0:00:08\n",
      "   -------------- ------------------------- 74.4/204.1 MB 16.4 MB/s eta 0:00:08\n",
      "   -------------- ------------------------- 75.3/204.1 MB 16.8 MB/s eta 0:00:08\n",
      "   -------------- ------------------------- 76.0/204.1 MB 16.0 MB/s eta 0:00:09\n",
      "   --------------- ------------------------ 77.0/204.1 MB 16.0 MB/s eta 0:00:08\n",
      "   --------------- ------------------------ 77.5/204.1 MB 16.4 MB/s eta 0:00:08\n",
      "   --------------- ------------------------ 78.3/204.1 MB 16.0 MB/s eta 0:00:08\n",
      "   --------------- ------------------------ 79.0/204.1 MB 16.4 MB/s eta 0:00:08\n",
      "   --------------- ------------------------ 79.8/204.1 MB 16.4 MB/s eta 0:00:08\n",
      "   --------------- ------------------------ 80.7/204.1 MB 16.4 MB/s eta 0:00:08\n",
      "   --------------- ------------------------ 81.2/204.1 MB 16.4 MB/s eta 0:00:08\n",
      "   ---------------- ----------------------- 82.1/204.1 MB 16.4 MB/s eta 0:00:08\n",
      "   ---------------- ----------------------- 82.8/204.1 MB 16.8 MB/s eta 0:00:08\n",
      "   ---------------- ----------------------- 83.7/204.1 MB 17.2 MB/s eta 0:00:07\n",
      "   ---------------- ----------------------- 84.5/204.1 MB 17.2 MB/s eta 0:00:07\n",
      "   ---------------- ----------------------- 85.5/204.1 MB 17.2 MB/s eta 0:00:07\n",
      "   ---------------- ----------------------- 86.5/204.1 MB 17.7 MB/s eta 0:00:07\n",
      "   ----------------- ---------------------- 87.1/204.1 MB 17.7 MB/s eta 0:00:07\n",
      "   ----------------- ---------------------- 87.9/204.1 MB 17.7 MB/s eta 0:00:07\n",
      "   ----------------- ---------------------- 88.6/204.1 MB 17.7 MB/s eta 0:00:07\n",
      "   ----------------- ---------------------- 89.4/204.1 MB 17.7 MB/s eta 0:00:07\n",
      "   ----------------- ---------------------- 90.5/204.1 MB 18.2 MB/s eta 0:00:07\n",
      "   ----------------- ---------------------- 91.5/204.1 MB 18.7 MB/s eta 0:00:07\n",
      "   ------------------ --------------------- 92.4/204.1 MB 18.7 MB/s eta 0:00:06\n",
      "   ------------------ --------------------- 93.2/204.1 MB 18.7 MB/s eta 0:00:06\n",
      "   ------------------ --------------------- 93.7/204.1 MB 17.7 MB/s eta 0:00:07\n",
      "   ------------------ --------------------- 94.6/204.1 MB 18.2 MB/s eta 0:00:07\n",
      "   ------------------ --------------------- 95.3/204.1 MB 17.7 MB/s eta 0:00:07\n",
      "   ------------------ --------------------- 95.9/204.1 MB 17.7 MB/s eta 0:00:07\n",
      "   ------------------ --------------------- 96.9/204.1 MB 17.7 MB/s eta 0:00:07\n",
      "   ------------------- -------------------- 97.7/204.1 MB 18.2 MB/s eta 0:00:06\n",
      "   ------------------- -------------------- 98.6/204.1 MB 18.2 MB/s eta 0:00:06\n",
      "   ------------------- -------------------- 99.2/204.1 MB 17.7 MB/s eta 0:00:06\n",
      "   ------------------- ------------------- 100.1/204.1 MB 17.7 MB/s eta 0:00:06\n",
      "   ------------------- ------------------- 100.9/204.1 MB 17.7 MB/s eta 0:00:06\n",
      "   ------------------- ------------------- 101.6/204.1 MB 17.3 MB/s eta 0:00:06\n",
      "   ------------------- ------------------- 102.6/204.1 MB 17.3 MB/s eta 0:00:06\n",
      "   ------------------- ------------------- 103.3/204.1 MB 17.2 MB/s eta 0:00:06\n",
      "   ------------------- ------------------- 104.0/204.1 MB 17.2 MB/s eta 0:00:06\n",
      "   -------------------- ------------------ 104.8/204.1 MB 17.2 MB/s eta 0:00:06\n",
      "   -------------------- ------------------ 105.5/204.1 MB 17.2 MB/s eta 0:00:06\n",
      "   -------------------- ------------------ 106.3/204.1 MB 17.7 MB/s eta 0:00:06\n",
      "   -------------------- ------------------ 107.1/204.1 MB 16.8 MB/s eta 0:00:06\n",
      "   -------------------- ------------------ 107.9/204.1 MB 16.8 MB/s eta 0:00:06\n",
      "   -------------------- ------------------ 108.8/204.1 MB 16.8 MB/s eta 0:00:06\n",
      "   -------------------- ------------------ 109.6/204.1 MB 16.8 MB/s eta 0:00:06\n",
      "   --------------------- ----------------- 110.5/204.1 MB 17.2 MB/s eta 0:00:06\n",
      "   --------------------- ----------------- 111.3/204.1 MB 17.2 MB/s eta 0:00:06\n",
      "   --------------------- ----------------- 112.0/204.1 MB 17.2 MB/s eta 0:00:06\n",
      "   --------------------- ----------------- 113.0/204.1 MB 16.8 MB/s eta 0:00:06\n",
      "   --------------------- ----------------- 113.9/204.1 MB 17.2 MB/s eta 0:00:06\n",
      "   --------------------- ----------------- 114.5/204.1 MB 16.8 MB/s eta 0:00:06\n",
      "   ---------------------- ---------------- 115.3/204.1 MB 17.3 MB/s eta 0:00:06\n",
      "   ---------------------- ---------------- 116.2/204.1 MB 16.8 MB/s eta 0:00:06\n",
      "   ---------------------- ---------------- 117.1/204.1 MB 16.8 MB/s eta 0:00:06\n",
      "   ---------------------- ---------------- 118.0/204.1 MB 17.2 MB/s eta 0:00:06\n",
      "   ---------------------- ---------------- 118.8/204.1 MB 17.3 MB/s eta 0:00:05\n",
      "   ---------------------- ---------------- 119.6/204.1 MB 17.3 MB/s eta 0:00:05\n",
      "   ----------------------- --------------- 120.5/204.1 MB 17.2 MB/s eta 0:00:05\n",
      "   ----------------------- --------------- 121.3/204.1 MB 17.2 MB/s eta 0:00:05\n",
      "   ----------------------- --------------- 122.0/204.1 MB 17.7 MB/s eta 0:00:05\n",
      "   ----------------------- --------------- 122.8/204.1 MB 17.2 MB/s eta 0:00:05\n",
      "   ----------------------- --------------- 123.6/204.1 MB 17.2 MB/s eta 0:00:05\n",
      "   ----------------------- --------------- 124.3/204.1 MB 17.2 MB/s eta 0:00:05\n",
      "   ----------------------- --------------- 124.9/204.1 MB 16.8 MB/s eta 0:00:05\n",
      "   ----------------------- --------------- 125.6/204.1 MB 17.2 MB/s eta 0:00:05\n",
      "   ------------------------ -------------- 126.3/204.1 MB 16.8 MB/s eta 0:00:05\n",
      "   ------------------------ -------------- 127.2/204.1 MB 17.3 MB/s eta 0:00:05\n",
      "   ------------------------ -------------- 127.9/204.1 MB 17.3 MB/s eta 0:00:05\n",
      "   ------------------------ -------------- 128.8/204.1 MB 16.8 MB/s eta 0:00:05\n",
      "   ------------------------ -------------- 129.7/204.1 MB 16.8 MB/s eta 0:00:05\n",
      "   ------------------------ -------------- 130.5/204.1 MB 16.8 MB/s eta 0:00:05\n",
      "   ------------------------- ------------- 131.3/204.1 MB 16.8 MB/s eta 0:00:05\n",
      "   ------------------------- ------------- 132.2/204.1 MB 16.8 MB/s eta 0:00:05\n",
      "   ------------------------- ------------- 133.1/204.1 MB 16.8 MB/s eta 0:00:05\n",
      "   ------------------------- ------------- 133.9/204.1 MB 16.8 MB/s eta 0:00:05\n",
      "   ------------------------- ------------- 134.7/204.1 MB 16.8 MB/s eta 0:00:05\n",
      "   ------------------------- ------------- 135.5/204.1 MB 16.8 MB/s eta 0:00:05\n",
      "   ------------------------- ------------- 136.0/204.1 MB 16.8 MB/s eta 0:00:05\n",
      "   -------------------------- ------------ 136.8/204.1 MB 16.4 MB/s eta 0:00:05\n",
      "   -------------------------- ------------ 137.5/204.1 MB 16.4 MB/s eta 0:00:05\n",
      "   -------------------------- ------------ 138.4/204.1 MB 16.4 MB/s eta 0:00:05\n",
      "   -------------------------- ------------ 139.0/204.1 MB 16.4 MB/s eta 0:00:04\n",
      "   -------------------------- ------------ 139.8/204.1 MB 16.0 MB/s eta 0:00:05\n",
      "   -------------------------- ------------ 140.4/204.1 MB 16.4 MB/s eta 0:00:04\n",
      "   -------------------------- ------------ 141.0/204.1 MB 16.0 MB/s eta 0:00:04\n",
      "   --------------------------- ----------- 141.6/204.1 MB 16.4 MB/s eta 0:00:04\n",
      "   --------------------------- ----------- 142.3/204.1 MB 16.4 MB/s eta 0:00:04\n",
      "   --------------------------- ----------- 143.3/204.1 MB 16.4 MB/s eta 0:00:04\n",
      "   --------------------------- ----------- 144.1/204.1 MB 16.4 MB/s eta 0:00:04\n",
      "   --------------------------- ----------- 144.9/204.1 MB 16.4 MB/s eta 0:00:04\n",
      "   --------------------------- ----------- 145.7/204.1 MB 16.4 MB/s eta 0:00:04\n",
      "   ---------------------------- ---------- 146.6/204.1 MB 16.4 MB/s eta 0:00:04\n",
      "   ---------------------------- ---------- 147.4/204.1 MB 16.8 MB/s eta 0:00:04\n",
      "   ---------------------------- ---------- 148.1/204.1 MB 16.4 MB/s eta 0:00:04\n",
      "   ---------------------------- ---------- 148.8/204.1 MB 16.8 MB/s eta 0:00:04\n",
      "   ---------------------------- ---------- 149.7/204.1 MB 16.8 MB/s eta 0:00:04\n",
      "   ---------------------------- ---------- 150.5/204.1 MB 16.8 MB/s eta 0:00:04\n",
      "   ---------------------------- ---------- 151.4/204.1 MB 17.2 MB/s eta 0:00:04\n",
      "   ----------------------------- --------- 152.2/204.1 MB 16.8 MB/s eta 0:00:04\n",
      "   ----------------------------- --------- 153.0/204.1 MB 16.8 MB/s eta 0:00:04\n",
      "   ----------------------------- --------- 154.0/204.1 MB 16.8 MB/s eta 0:00:03\n",
      "   ----------------------------- --------- 154.8/204.1 MB 16.8 MB/s eta 0:00:03\n",
      "   ----------------------------- --------- 155.4/204.1 MB 17.2 MB/s eta 0:00:03\n",
      "   ----------------------------- --------- 156.2/204.1 MB 16.8 MB/s eta 0:00:03\n",
      "   ------------------------------ -------- 157.1/204.1 MB 17.3 MB/s eta 0:00:03\n",
      "   ------------------------------ -------- 157.7/204.1 MB 16.8 MB/s eta 0:00:03\n",
      "   ------------------------------ -------- 158.7/204.1 MB 16.8 MB/s eta 0:00:03\n",
      "   ------------------------------ -------- 159.2/204.1 MB 16.8 MB/s eta 0:00:03\n",
      "   ------------------------------ -------- 160.0/204.1 MB 16.8 MB/s eta 0:00:03\n",
      "   ------------------------------ -------- 160.7/204.1 MB 17.2 MB/s eta 0:00:03\n",
      "   ------------------------------ -------- 161.5/204.1 MB 16.8 MB/s eta 0:00:03\n",
      "   ------------------------------ -------- 162.2/204.1 MB 17.2 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 163.1/204.1 MB 16.8 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 164.1/204.1 MB 16.8 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 164.9/204.1 MB 16.8 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 165.7/204.1 MB 16.4 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 166.6/204.1 MB 16.8 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 167.4/204.1 MB 16.8 MB/s eta 0:00:03\n",
      "   -------------------------------- ------ 168.0/204.1 MB 17.2 MB/s eta 0:00:03\n",
      "   -------------------------------- ------ 168.9/204.1 MB 17.3 MB/s eta 0:00:03\n",
      "   -------------------------------- ------ 169.7/204.1 MB 17.3 MB/s eta 0:00:02\n",
      "   -------------------------------- ------ 170.6/204.1 MB 17.7 MB/s eta 0:00:02\n",
      "   -------------------------------- ------ 171.5/204.1 MB 17.2 MB/s eta 0:00:02\n",
      "   -------------------------------- ------ 172.1/204.1 MB 17.2 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 173.0/204.1 MB 17.7 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 173.4/204.1 MB 16.8 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 174.2/204.1 MB 16.4 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 175.0/204.1 MB 16.8 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 175.8/204.1 MB 16.8 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 176.6/204.1 MB 16.8 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 177.2/204.1 MB 17.3 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 178.2/204.1 MB 16.8 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 178.8/204.1 MB 16.8 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 179.6/204.1 MB 16.8 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 180.4/204.1 MB 16.8 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 181.3/204.1 MB 17.2 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 182.2/204.1 MB 17.2 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 183.0/204.1 MB 16.8 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 183.6/204.1 MB 16.8 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 184.2/204.1 MB 17.2 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 185.0/204.1 MB 17.2 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 185.9/204.1 MB 17.3 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 186.8/204.1 MB 17.7 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 187.6/204.1 MB 17.7 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 188.2/204.1 MB 17.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 189.0/204.1 MB 17.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 189.7/204.1 MB 17.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 190.6/204.1 MB 17.7 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 191.4/204.1 MB 17.7 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 192.3/204.1 MB 17.3 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 193.0/204.1 MB 17.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 193.8/204.1 MB 17.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 194.6/204.1 MB 17.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 195.6/204.1 MB 18.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 196.6/204.1 MB 17.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 197.2/204.1 MB 17.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 198.2/204.1 MB 18.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  199.2/204.1 MB 18.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  200.2/204.1 MB 18.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  201.0/204.1 MB 18.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  202.0/204.1 MB 18.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  202.7/204.1 MB 18.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  203.7/204.1 MB 18.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  204.1/204.1 MB 19.3 MB/s eta 0:00:01\n",
      "   --------------------------------------  204.1/204.1 MB 19.3 MB/s eta 0:00:01\n",
      "   --------------------------------------  204.1/204.1 MB 19.3 MB/s eta 0:00:01\n",
      "   --------------------------------------  204.1/204.1 MB 19.3 MB/s eta 0:00:01\n",
      "   --------------------------------------  204.1/204.1 MB 19.3 MB/s eta 0:00:01\n",
      "   --------------------------------------  204.1/204.1 MB 19.3 MB/s eta 0:00:01\n",
      "   --------------------------------------  204.1/204.1 MB 19.3 MB/s eta 0:00:01\n",
      "   --------------------------------------  204.1/204.1 MB 19.3 MB/s eta 0:00:01\n",
      "   --------------------------------------  204.1/204.1 MB 19.3 MB/s eta 0:00:01\n",
      "   --------------------------------------- 204.1/204.1 MB 10.9 MB/s eta 0:00:00\n",
      "Downloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "   ---------------------------------------- 0.0/6.2 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.7/6.2 MB 14.6 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 1.4/6.2 MB 14.3 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 2.1/6.2 MB 15.1 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 2.8/6.2 MB 14.9 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 3.5/6.2 MB 15.0 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 4.5/6.2 MB 16.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 5.4/6.2 MB 16.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  6.2/6.2 MB 16.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.2/6.2 MB 15.2 MB/s eta 0:00:00\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "   ---------------------------------------- 0.0/78.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 78.5/78.5 kB 2.2 MB/s eta 0:00:00\n",
      "Downloading transformers-4.49.0-py3-none-any.whl (10.0 MB)\n",
      "   ---------------------------------------- 0.0/10.0 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.6/10.0 MB 18.5 MB/s eta 0:00:01\n",
      "   ----- ---------------------------------- 1.2/10.0 MB 15.9 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 2.1/10.0 MB 16.5 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 2.9/10.0 MB 15.1 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 3.8/10.0 MB 16.1 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 4.7/10.0 MB 16.6 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 5.5/10.0 MB 16.6 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 6.4/10.0 MB 16.9 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 7.4/10.0 MB 17.4 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 7.9/10.0 MB 16.9 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 8.7/10.0 MB 16.9 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 9.6/10.0 MB 17.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 10.0/10.0 MB 16.4 MB/s eta 0:00:00\n",
      "Downloading pillow-11.1.0-cp312-cp312-win_amd64.whl (2.6 MB)\n",
      "   ---------------------------------------- 0.0/2.6 MB ? eta -:--:--\n",
      "   ----------- ---------------------------- 0.8/2.6 MB 24.4 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 1.4/2.6 MB 18.4 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 2.2/2.6 MB 20.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.6/2.6 MB 16.8 MB/s eta 0:00:00\n",
      "Using cached scikit_learn-1.6.1-cp312-cp312-win_amd64.whl (11.1 MB)\n",
      "Downloading scipy-1.15.2-cp312-cp312-win_amd64.whl (40.9 MB)\n",
      "   ---------------------------------------- 0.0/40.9 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.7/40.9 MB 22.5 MB/s eta 0:00:02\n",
      "   - -------------------------------------- 1.3/40.9 MB 14.1 MB/s eta 0:00:03\n",
      "   -- ------------------------------------- 2.3/40.9 MB 15.9 MB/s eta 0:00:03\n",
      "   --- ------------------------------------ 3.2/40.9 MB 17.0 MB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 4.2/40.9 MB 17.8 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 5.2/40.9 MB 17.3 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 6.0/40.9 MB 18.2 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 6.2/40.9 MB 18.1 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 7.4/40.9 MB 17.6 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 8.3/40.9 MB 17.7 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 9.1/40.9 MB 17.2 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 9.8/40.9 MB 17.3 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 10.6/40.9 MB 16.8 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 11.4/40.9 MB 17.2 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 12.5/40.9 MB 17.7 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 13.1/40.9 MB 17.2 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 14.0/40.9 MB 17.2 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 14.7/40.9 MB 17.2 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 15.5/40.9 MB 17.2 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 16.4/40.9 MB 16.8 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 17.0/40.9 MB 18.2 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 17.7/40.9 MB 17.2 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 18.8/40.9 MB 17.2 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 19.5/40.9 MB 17.7 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 20.4/40.9 MB 18.2 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 21.3/40.9 MB 18.2 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 22.4/40.9 MB 17.7 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 23.1/40.9 MB 18.2 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 24.2/40.9 MB 17.7 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 25.1/40.9 MB 18.2 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 26.1/40.9 MB 18.2 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 27.0/40.9 MB 18.7 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 27.8/40.9 MB 18.2 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 28.5/40.9 MB 18.2 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 29.4/40.9 MB 18.7 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 30.3/40.9 MB 18.7 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 30.9/40.9 MB 18.7 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 31.7/40.9 MB 18.7 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 32.2/40.9 MB 17.7 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 33.1/40.9 MB 17.7 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 34.0/40.9 MB 17.7 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 34.8/40.9 MB 17.7 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 35.8/40.9 MB 17.7 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 36.4/40.9 MB 17.7 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 37.3/40.9 MB 17.7 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 37.9/40.9 MB 17.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 38.7/40.9 MB 17.7 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 39.4/40.9 MB 17.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  40.3/40.9 MB 17.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  40.9/40.9 MB 17.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  40.9/40.9 MB 17.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  40.9/40.9 MB 17.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 40.9/40.9 MB 14.9 MB/s eta 0:00:00\n",
      "Downloading fsspec-2025.2.0-py3-none-any.whl (184 kB)\n",
      "   ---------------------------------------- 0.0/184.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 184.5/184.5 kB 5.6 MB/s eta 0:00:00\n",
      "Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Downloading regex-2024.11.6-cp312-cp312-win_amd64.whl (273 kB)\n",
      "   ---------------------------------------- 0.0/273.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 273.6/273.6 kB 8.5 MB/s eta 0:00:00\n",
      "Downloading safetensors-0.5.3-cp38-abi3-win_amd64.whl (308 kB)\n",
      "   ---------------------------------------- 0.0/308.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 308.9/308.9 kB 9.6 MB/s eta 0:00:00\n",
      "Using cached threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Downloading tokenizers-0.21.0-cp39-abi3-win_amd64.whl (2.4 MB)\n",
      "   ---------------------------------------- 0.0/2.4 MB ? eta -:--:--\n",
      "   -------------- ------------------------- 0.9/2.4 MB 27.2 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 1.8/2.4 MB 22.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.4/2.4 MB 19.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.4/2.4 MB 16.9 MB/s eta 0:00:00\n",
      "Downloading filelock-3.17.0-py3-none-any.whl (16 kB)\n",
      "Using cached jinja2-3.1.5-py3-none-any.whl (134 kB)\n",
      "Downloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ------------------- -------------------- 0.8/1.7 MB 17.6 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 1.5/1.7 MB 16.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.7/1.7 MB 13.7 MB/s eta 0:00:00\n",
      "Downloading setuptools-75.8.2-py3-none-any.whl (1.2 MB)\n",
      "   ---------------------------------------- 0.0/1.2 MB ? eta -:--:--\n",
      "   ------------------------------ --------- 0.9/1.2 MB 29.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.2/1.2 MB 15.6 MB/s eta 0:00:00\n",
      "Using cached MarkupSafe-3.0.2-cp312-cp312-win_amd64.whl (15 kB)\n",
      "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "   ---------------------------------------- 0.0/536.2 kB ? eta -:--:--\n",
      "   ------------------------------------ -- 501.8/536.2 kB 30.7 MB/s eta 0:00:01\n",
      "   --------------------------------------- 536.2/536.2 kB 11.2 MB/s eta 0:00:00\n",
      "Installing collected packages: mpmath, tqdm, threadpoolctl, sympy, setuptools, scipy, safetensors, regex, Pillow, networkx, MarkupSafe, joblib, fsspec, filelock, scikit-learn, jinja2, huggingface-hub, torch, tokenizers, transformers, sentence-transformers\n",
      "Successfully installed MarkupSafe-3.0.2 Pillow-11.1.0 filelock-3.17.0 fsspec-2025.2.0 huggingface-hub-0.29.1 jinja2-3.1.5 joblib-1.4.2 mpmath-1.3.0 networkx-3.4.2 regex-2024.11.6 safetensors-0.5.3 scikit-learn-1.6.1 scipy-1.15.2 sentence-transformers-3.4.1 setuptools-75.8.2 sympy-1.13.1 threadpoolctl-3.5.0 tokenizers-0.21.0 torch-2.6.0 tqdm-4.67.1 transformers-4.49.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: chromadb in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (0.6.3)\n",
      "Requirement already satisfied: build>=1.0.3 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from chromadb) (1.2.2.post1)\n",
      "Requirement already satisfied: pydantic>=1.9 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from chromadb) (2.10.6)\n",
      "Requirement already satisfied: chroma-hnswlib==0.7.6 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from chromadb) (0.7.6)\n",
      "Requirement already satisfied: fastapi>=0.95.2 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from chromadb) (0.115.11)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.34.0)\n",
      "Requirement already satisfied: numpy>=1.22.5 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from chromadb) (2.2.3)\n",
      "Requirement already satisfied: posthog>=2.4.0 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from chromadb) (3.18.1)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from chromadb) (4.12.2)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from chromadb) (1.20.1)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from chromadb) (1.30.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from chromadb) (1.30.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from chromadb) (0.51b0)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from chromadb) (1.30.0)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from chromadb) (0.21.0)\n",
      "Requirement already satisfied: pypika>=0.48.9 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from chromadb) (0.48.9)\n",
      "Requirement already satisfied: tqdm>=4.65.0 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from chromadb) (4.67.1)\n",
      "Requirement already satisfied: overrides>=7.3.1 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from chromadb) (7.7.0)\n",
      "Requirement already satisfied: importlib-resources in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from chromadb) (6.5.2)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from chromadb) (1.70.0)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from chromadb) (4.3.0)\n",
      "Requirement already satisfied: typer>=0.9.0 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from chromadb) (0.15.2)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from chromadb) (32.0.1)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from chromadb) (9.0.0)\n",
      "Requirement already satisfied: PyYAML>=6.0.0 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from chromadb) (6.0.2)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from chromadb) (5.1.0)\n",
      "Requirement already satisfied: orjson>=3.9.12 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from chromadb) (3.10.15)\n",
      "Requirement already satisfied: httpx>=0.27.0 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from chromadb) (0.28.1)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from chromadb) (13.9.4)\n",
      "Requirement already satisfied: packaging>=19.1 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from build>=1.0.3->chromadb) (24.2)\n",
      "Requirement already satisfied: pyproject_hooks in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from build>=1.0.3->chromadb) (0.4.6)\n",
      "Requirement already satisfied: starlette<0.47.0,>=0.40.0 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from fastapi>=0.95.2->chromadb) (0.46.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from httpx>=0.27.0->chromadb) (4.8.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from httpx>=0.27.0->chromadb) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from httpx>=0.27.0->chromadb) (1.0.7)\n",
      "Requirement already satisfied: idna in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from httpx>=0.27.0->chromadb) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.14.0)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.38.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
      "Requirement already satisfied: requests in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.32.3)\n",
      "Requirement already satisfied: requests-oauthlib in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.3.0)\n",
      "Requirement already satisfied: durationpy>=0.7 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (0.9)\n",
      "Requirement already satisfied: coloredlogs in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (25.2.10)\n",
      "Requirement already satisfied: protobuf in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (5.29.3)\n",
      "Requirement already satisfied: sympy in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (1.13.1)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.18)\n",
      "Requirement already satisfied: importlib-metadata<=8.5.0,>=6.0 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from opentelemetry-api>=1.2.0->chromadb) (8.5.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.69.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.30.0 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.30.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.30.0 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.30.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.51b0 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.51b0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation==0.51b0 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.51b0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.51b0 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.51b0)\n",
      "Requirement already satisfied: opentelemetry-util-http==0.51b0 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.51b0)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from opentelemetry-instrumentation==0.51b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.17.2)\n",
      "Requirement already satisfied: asgiref~=3.0 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from opentelemetry-instrumentation-asgi==0.51b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (3.8.1)\n",
      "Requirement already satisfied: monotonic>=1.5 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from posthog>=2.4.0->chromadb) (1.6)\n",
      "Requirement already satisfied: backoff>=1.10.0 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
      "Requirement already satisfied: distro>=1.5.0 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from posthog>=2.4.0->chromadb) (1.9.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from pydantic>=1.9->chromadb) (2.27.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from rich>=10.11.0->chromadb) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from rich>=10.11.0->chromadb) (2.19.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from tokenizers>=0.13.2->chromadb) (0.29.1)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from typer>=0.9.0->chromadb) (8.1.8)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
      "Requirement already satisfied: httptools>=0.6.3 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.4)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.1)\n",
      "Requirement already satisfied: watchfiles>=0.13 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.4)\n",
      "Requirement already satisfied: websockets>=10.4 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (15.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
      "Requirement already satisfied: filelock in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.17.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2025.2.0)\n",
      "Requirement already satisfied: zipp>=3.20 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from importlib-metadata<=8.5.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.21.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from requests->kubernetes>=28.1.0->chromadb) (3.4.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from anyio->httpx>=0.27.0->chromadb) (1.3.1)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
      "Requirement already satisfied: pyreadline3 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from humanfriendly>=9.1->coloredlogs->onnxruntime>=1.14.1->chromadb) (3.5.4)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (1.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting google-generativeai\n",
      "  Downloading google_generativeai-0.8.4-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting google-ai-generativelanguage==0.6.15 (from google-generativeai)\n",
      "  Downloading google_ai_generativelanguage-0.6.15-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting google-api-core (from google-generativeai)\n",
      "  Downloading google_api_core-2.24.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting google-api-python-client (from google-generativeai)\n",
      "  Downloading google_api_python_client-2.162.0-py2.py3-none-any.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from google-generativeai) (2.38.0)\n",
      "Requirement already satisfied: protobuf in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from google-generativeai) (5.29.3)\n",
      "Requirement already satisfied: pydantic in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from google-generativeai) (2.10.6)\n",
      "Requirement already satisfied: tqdm in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from google-generativeai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from google-generativeai) (4.12.2)\n",
      "Collecting proto-plus<2.0.0dev,>=1.22.3 (from google-ai-generativelanguage==0.6.15->google-generativeai)\n",
      "  Downloading proto_plus-1.26.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from google-api-core->google-generativeai) (1.69.0)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from google-api-core->google-generativeai) (2.32.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (4.9)\n",
      "Collecting httplib2<1.dev0,>=0.19.0 (from google-api-python-client->google-generativeai)\n",
      "  Downloading httplib2-0.22.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting google-auth-httplib2<1.0.0,>=0.2.0 (from google-api-python-client->google-generativeai)\n",
      "  Downloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting uritemplate<5,>=3.0.1 (from google-api-python-client->google-generativeai)\n",
      "  Downloading uritemplate-4.1.1-py2.py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from pydantic->google-generativeai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from pydantic->google-generativeai) (2.27.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from tqdm->google-generativeai) (0.4.6)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.70.0)\n",
      "Collecting grpcio-status<2.0.dev0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai)\n",
      "  Downloading grpcio_status-1.70.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai)\n",
      "  Downloading pyparsing-3.2.1-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2025.1.31)\n",
      "Downloading google_generativeai-0.8.4-py3-none-any.whl (175 kB)\n",
      "   ---------------------------------------- 0.0/175.4 kB ? eta -:--:--\n",
      "   -------------------------------- ------- 143.4/175.4 kB 4.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 175.4/175.4 kB 3.5 MB/s eta 0:00:00\n",
      "Downloading google_ai_generativelanguage-0.6.15-py3-none-any.whl (1.3 MB)\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   -------- ------------------------------- 0.3/1.3 MB 8.6 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 0.6/1.3 MB 7.6 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 1.0/1.3 MB 7.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.3/1.3 MB 7.0 MB/s eta 0:00:00\n",
      "Downloading google_api_core-2.24.1-py3-none-any.whl (160 kB)\n",
      "   ---------------------------------------- 0.0/160.1 kB ? eta -:--:--\n",
      "   --------------------------------------- 160.1/160.1 kB 10.0 MB/s eta 0:00:00\n",
      "Downloading google_api_python_client-2.162.0-py2.py3-none-any.whl (13.1 MB)\n",
      "   ---------------------------------------- 0.0/13.1 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.5/13.1 MB 10.2 MB/s eta 0:00:02\n",
      "   -- ------------------------------------- 0.9/13.1 MB 11.3 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 1.5/13.1 MB 11.7 MB/s eta 0:00:01\n",
      "   ------ --------------------------------- 2.1/13.1 MB 12.3 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 2.8/13.1 MB 13.0 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 3.3/13.1 MB 12.4 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 3.9/13.1 MB 13.2 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 4.6/13.1 MB 13.4 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 5.3/13.1 MB 13.6 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 6.1/13.1 MB 14.0 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 7.1/13.1 MB 14.7 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 8.1/13.1 MB 14.7 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 8.8/13.1 MB 15.1 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 9.5/13.1 MB 15.2 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 10.1/13.1 MB 15.5 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 10.9/13.1 MB 16.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 11.5/13.1 MB 16.0 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 12.0/13.1 MB 16.0 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 12.7/13.1 MB 16.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  13.1/13.1 MB 16.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 13.1/13.1 MB 15.2 MB/s eta 0:00:00\n",
      "Downloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl (9.3 kB)\n",
      "Downloading httplib2-0.22.0-py3-none-any.whl (96 kB)\n",
      "   ---------------------------------------- 0.0/96.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 96.9/96.9 kB 5.8 MB/s eta 0:00:00\n",
      "Downloading proto_plus-1.26.0-py3-none-any.whl (50 kB)\n",
      "   ---------------------------------------- 0.0/50.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 50.2/50.2 kB 2.5 MB/s eta 0:00:00\n",
      "Downloading uritemplate-4.1.1-py2.py3-none-any.whl (10 kB)\n",
      "Downloading grpcio_status-1.70.0-py3-none-any.whl (14 kB)\n",
      "Downloading pyparsing-3.2.1-py3-none-any.whl (107 kB)\n",
      "   ---------------------------------------- 0.0/107.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 107.7/107.7 kB 3.1 MB/s eta 0:00:00\n",
      "Installing collected packages: uritemplate, pyparsing, proto-plus, httplib2, grpcio-status, google-auth-httplib2, google-api-core, google-api-python-client, google-ai-generativelanguage, google-generativeai\n",
      "Successfully installed google-ai-generativelanguage-0.6.15 google-api-core-2.24.1 google-api-python-client-2.162.0 google-auth-httplib2-0.2.0 google-generativeai-0.8.4 grpcio-status-1.70.0 httplib2-0.22.0 proto-plus-1.26.0 pyparsing-3.2.1 uritemplate-4.1.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install google-generativeai\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leer el documentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cargar_documentos(ruta_archivo):\n",
    "    \"\"\"Carga documentos en PDF, TXT o DOCX y los convierte en texto.\"\"\"\n",
    "    if ruta_archivo.endswith(\".pdf\"):\n",
    "        loader = PyPDFLoader(ruta_archivo)\n",
    "    elif ruta_archivo.endswith(\".txt\"):\n",
    "        loader = TextLoader(ruta_archivo)\n",
    "    elif ruta_archivo.endswith(\".docx\"):\n",
    "        loader = Docx2txtLoader(ruta_archivo)\n",
    "    else:\n",
    "        raise ValueError(\"Formato no soportado. Usa PDF, TXT o DOCX.\")\n",
    "    \n",
    "    documentos = loader.load()\n",
    "    \n",
    "    return documentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'Acrobat Distiller 19.0 (Windows)', 'creator': 'PScript5.dll Version 5.2.2', 'creationdate': '2024-10-30T15:27:39-05:00', 'author': 'USUARIO', 'moddate': '2024-10-30T15:27:39-05:00', 'title': 'Microsoft PowerPoint - 1-01-Curso_PLN', 'source': 'data/1-01-Curso_PLN.pdf', 'total_pages': 4, 'page': 0, 'page_label': '1'}, page_content='30/10/2024\\n3011176 - Procesamiento del Lenguaje \\nNatural\\nFACULTAD DE MINAS\\nSede Medellín\\nSINTELWEB\\nGrupo de Investigación\\nSistemas Inteligentes Web\\nJAIME ALBERTO GUZMAN LUNA, Ph.D\\nInformación de contacto\\n\\uf06e Jaime Alberto Guzmán Luna\\n\\uf06e Doctor en Ingeniería de Sistemas e Informática\\n\\uf06e M.Sc. en Ingeniería de Sistemas e Informática\\n\\uf06e Especialista en comunicación educativa\\n\\uf06e Ingeniero Civil\\n\\uf06e Áreas de trabajo\\n\\uf06e Inteligencia Artificial\\n\\uf06e Sistemas de recuperación de información\\n\\uf06e Planificación automática de procesos \\n\\uf06e Aprendizaje de máquinas\\n\\uf06e PLN con aprendizaje profundo\\n\\uf06e Universidad Nacional de Colombia\\n\\uf06e Oficina M8A-306\\n\\uf06e Email: jaguzman@unal.edu.co \\n\\uf06e Horario de Atención virtual (citas previas): \\n\\uf06e Lunes de 2:30 a 4:30 pm\\n\\uf0a7 Apoyo: \\n\\uf0a7 Alejandro Jiménez Franco\\n\\uf0a7 Email: aljimenezfr@unal.edu.co\\n1\\n2'),\n",
       " Document(metadata={'producer': 'Acrobat Distiller 19.0 (Windows)', 'creator': 'PScript5.dll Version 5.2.2', 'creationdate': '2024-10-30T15:27:39-05:00', 'author': 'USUARIO', 'moddate': '2024-10-30T15:27:39-05:00', 'title': 'Microsoft PowerPoint - 1-01-Curso_PLN', 'source': 'data/1-01-Curso_PLN.pdf', 'total_pages': 4, 'page': 1, 'page_label': '2'}, page_content='30/10/2024\\nObjetivos\\n\\uf06e Objetivo general\\n\\uf06e El objetivo de este curso es proporcionar a los estudiantes las habilidades y\\nconocimientos fundamentales en el campo del Procesamiento de Lenguaje Natural,\\nun campo de la inteligencia artificial que permite a las máquinas comprender y\\nmanipular el lenguaje humano. Los temas abarcan desde el procesamiento de\\ntexto básico hasta la comprensión del lenguaje, con aplicaciones en análisis de\\nsentimientos, traducciónautomática, chatbots y más.\\n\\uf06e Objetivos específicos\\n\\uf06e Comprender los conceptos clave en Procesamiento del Lenguaje Natural\\nfamiliarizándose con las bibliotecas populares de PLN (como NLTK, SpaCy,\\nTransformers de Hugging Face, etc.)\\n\\uf06e Familiarizarse con las técnicas y algori tmos utilizados para el procesamiento de\\ntexto, análisis de sentimiento, clasificación de texto y extracción de la información.\\n\\uf06e Entender los Modelos de Lenguaje y sus aplicaciones prácticas.\\n\\uf06e Aplicar modelos y herramientas de PLN avanzadas a problemas del mundo real\\n(traducción automática, Preguntas&Respuestas- QA, análisis de conversaciones,\\netc)\\nContenido del Curso (1)\\n\\uf06e TEMA 1: Introducción al Procesamiento de Lenguaje Natural.\\n\\uf06e Generalidades del Procesamiento de Lenguaje Natural y su importancia.\\n\\uf06e Limpieza y normalización de textos en Python\\n\\uf06e Manejo de errores ortográficos: Pyspellchecker\\n\\uf06e TEMA 2: Procesamiento de Texto.\\n\\uf06e Tareas básicas de procesamiento de texto: tokenización, stopswords,\\nstemming y lematización\\n\\uf06e Bibliotecas populares; NLTK, spaCy y TextBlob\\n\\uf06e TEMA 3:Manejo de corpus de texto.\\n\\uf06e Modelos Estadísticos de Lenguaje (N-gramas y modelos probabilísticos;\\nmodelo TF-IDF; e introducción a la semántica latente-LSA).\\n\\uf06e Creación de corpus desde textos y la Web (text mining y web scraping)\\n\\uf06e Métricas básicas para corpus de texto\\n3\\n4'),\n",
       " Document(metadata={'producer': 'Acrobat Distiller 19.0 (Windows)', 'creator': 'PScript5.dll Version 5.2.2', 'creationdate': '2024-10-30T15:27:39-05:00', 'author': 'USUARIO', 'moddate': '2024-10-30T15:27:39-05:00', 'title': 'Microsoft PowerPoint - 1-01-Curso_PLN', 'source': 'data/1-01-Curso_PLN.pdf', 'total_pages': 4, 'page': 2, 'page_label': '3'}, page_content='30/10/2024\\nContenido del Curso (2)\\n\\uf06e TEMA 4:Análisis de Sentimientos, clasificación y extracción de información en textos.\\n\\uf06e Introducción al análisis de sentimientos; Métodos supervisados y no supervisados; y \\nAplicaciones prácticas y casos de estudio\\n\\uf06e Clasificación de Texto con algoritmos de aprendizaje automático (Modelos de clasificación \\npopulares: Naive Bayes, SVM, redes neuronales), Evaluación de modelos de clasificación de \\ntexto.\\n\\uf06e Extracción de Información, Reconocimiento de entidades nombradas (NER) y Extracción de \\nrelaciones entre entidades.\\n\\uf06e TEMA 5:Modelos Avanzados de Representación de Texto.\\n\\uf06e Word embeddings: Word2Vec, GloVe.\\n\\uf06e Modelos basados en redes neuronales: embeddings de contexto (FastText, ELMo).\\n\\uf06e Transformadores y el modelo BERT. \\n\\uf06e TEMA 6:Generación de Texto y Modelos de Lenguaje.\\n\\uf06e Redes neuronales recurrentes (RNN) y LSTM.\\n\\uf06e Transformadores para generación de texto (GPT).\\n\\uf06e Aplicaciones prácticas en PLN Traducción automática, chatbots, resumen de texto, QA \\n(Question Answering), análisis de conversaciones.\\nMetodología\\n\\uf06e Actividades presenciales: \\n\\uf06e Clases magistrales por parte del docente.\\n\\uf06e Talleres: Alumnos en compañía del docente y monitores\\n\\uf06e Exposiciones de los estudiantes\\n\\uf06e Presentación de prácticas por parte de los estudiantes.\\n\\uf06e Actividades Asíncronas: \\n\\uf06e Videos de temas complementarios\\n\\uf06e Talleres en casa\\n5\\n6'),\n",
       " Document(metadata={'producer': 'Acrobat Distiller 19.0 (Windows)', 'creator': 'PScript5.dll Version 5.2.2', 'creationdate': '2024-10-30T15:27:39-05:00', 'author': 'USUARIO', 'moddate': '2024-10-30T15:27:39-05:00', 'title': 'Microsoft PowerPoint - 1-01-Curso_PLN', 'source': 'data/1-01-Curso_PLN.pdf', 'total_pages': 4, 'page': 3, 'page_label': '4'}, page_content='30/10/2024\\nEvaluación\\n\\uf06e 2 trabajos prácticos: \\n\\uf06e Práctica 1: Aplicativo para el análisis de sentimientos desde \\ntextos(25%)\\n\\uf06e Fecha: miércoles 27 de noviembre de 4 a 8 pm. \\n\\uf06e Práctica 2: Aplicativo practico basado en la Generación de Texto y \\nModelos de Lenguaje (25%)\\n\\uf06e Fecha: miércoles 26 de febrero de 4 a 8 pm.\\n\\uf06e Exposiciones sobre temáticas (20%)\\n\\uf06e Fecha miércoles 15 de enero de 4 a 8 pm\\n\\uf06e Seguimiento a Talleres (30%)\\n\\uf06e Miércoles 12 m\\nLecturas y Recursos Recomendados\\n7\\n8')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Leer documento pdf\n",
    "loader = PyPDFLoader(\"data/1-01-Curso_PLN.pdf\")\n",
    "pages = loader.load()\n",
    "pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/10/2024\n",
      "3011176 - Procesamiento del Lenguaje \n",
      "Natural\n",
      "FACULTAD DE MINAS\n",
      "Sede Medellín\n",
      "SINTELWEB\n",
      "Grupo de Investigación\n",
      "Sistemas Inteligentes Web\n",
      "JAIME ALBERTO GUZMAN LUNA, Ph.D\n",
      "Información de contacto\n",
      "- Jaime Alberto Guzmán Luna\n",
      "- Doctor en Ingeniería de Sistemas e Informática\n",
      "- M.Sc. en Ingeniería de Sistemas e Informática\n",
      "- Especialista en comunicación educativa\n",
      "- Ingeniero Civil\n",
      "- Áreas de trabajo\n",
      "- Inteligencia Artificial\n",
      "- Sistemas de recuperación de información\n",
      "- Planificación automática de procesos \n",
      "- Aprendizaje de máquinas\n",
      "- PLN con aprendizaje profundo\n",
      "- Universidad Nacional de Colombia\n",
      "- Oficina M8A-306\n",
      "- Email: jaguzman@unal.edu.co \n",
      "- Horario de Atención virtual (citas previas): \n",
      "- Lunes de 2:30 a 4:30 pm\n",
      "- Apoyo: \n",
      "- Alejandro Jiménez Franco\n",
      "- Email: aljimenezfr@unal.edu.co\n",
      "1\n",
      "2\n",
      "\n",
      "30/10/2024\n",
      "Objetivos\n",
      "- Objetivo general\n",
      "- El objetivo de este curso es proporcionar a los estudiantes las habilidades y\n",
      "conocimientos fundamentales en el campo del Procesamiento de Lenguaje Natural,\n",
      "un campo de la inteligencia artificial que permite a las máquinas comprender y\n",
      "manipular el lenguaje humano. Los temas abarcan desde el procesamiento de\n",
      "texto básico hasta la comprensión del lenguaje, con aplicaciones en análisis de\n",
      "sentimientos, traducciónautomática, chatbots y más.\n",
      "- Objetivos específicos\n",
      "- Comprender los conceptos clave en Procesamiento del Lenguaje Natural\n",
      "familiarizándose con las bibliotecas populares de PLN (como NLTK, SpaCy,\n",
      "Transformers de Hugging Face, etc.)\n",
      "- Familiarizarse con las técnicas y algori tmos utilizados para el procesamiento de\n",
      "texto, análisis de sentimiento, clasificación de texto y extracción de la información.\n",
      "- Entender los Modelos de Lenguaje y sus aplicaciones prácticas.\n",
      "- Aplicar modelos y herramientas de PLN avanzadas a problemas del mundo real\n",
      "(traducción automática, Preguntas&Respuestas- QA, análisis de conversaciones,\n",
      "etc)\n",
      "Contenido del Curso (1)\n",
      "- TEMA 1: Introducción al Procesamiento de Lenguaje Natural.\n",
      "- Generalidades del Procesamiento de Lenguaje Natural y su importancia.\n",
      "- Limpieza y normalización de textos en Python\n",
      "- Manejo de errores ortográficos: Pyspellchecker\n",
      "- TEMA 2: Procesamiento de Texto.\n",
      "- Tareas básicas de procesamiento de texto: tokenización, stopswords,\n",
      "stemming y lematización\n",
      "- Bibliotecas populares; NLTK, spaCy y TextBlob\n",
      "- TEMA 3:Manejo de corpus de texto.\n",
      "- Modelos Estadísticos de Lenguaje (N-gramas y modelos probabilísticos;\n",
      "modelo TF-IDF; e introducción a la semántica latente-LSA).\n",
      "- Creación de corpus desde textos y la Web (text mining y web scraping)\n",
      "- Métricas básicas para corpus de texto\n",
      "3\n",
      "4\n",
      "\n",
      "30/10/2024\n",
      "Contenido del Curso (2)\n",
      "- TEMA 4:Análisis de Sentimientos, clasificación y extracción de información en textos.\n",
      "- Introducción al análisis de sentimientos; Métodos supervisados y no supervisados; y \n",
      "Aplicaciones prácticas y casos de estudio\n",
      "- Clasificación de Texto con algoritmos de aprendizaje automático (Modelos de clasificación \n",
      "populares: Naive Bayes, SVM, redes neuronales), Evaluación de modelos de clasificación de \n",
      "texto.\n",
      "- Extracción de Información, Reconocimiento de entidades nombradas (NER) y Extracción de \n",
      "relaciones entre entidades.\n",
      "- TEMA 5:Modelos Avanzados de Representación de Texto.\n",
      "- Word embeddings: Word2Vec, GloVe.\n",
      "- Modelos basados en redes neuronales: embeddings de contexto (FastText, ELMo).\n",
      "- Transformadores y el modelo BERT. \n",
      "- TEMA 6:Generación de Texto y Modelos de Lenguaje.\n",
      "- Redes neuronales recurrentes (RNN) y LSTM.\n",
      "- Transformadores para generación de texto (GPT).\n",
      "- Aplicaciones prácticas en PLN Traducción automática, chatbots, resumen de texto, QA \n",
      "(Question Answering), análisis de conversaciones.\n",
      "Metodología\n",
      "- Actividades presenciales: \n",
      "- Clases magistrales por parte del docente.\n",
      "- Talleres: Alumnos en compañía del docente y monitores\n",
      "- Exposiciones de los estudiantes\n",
      "- Presentación de prácticas por parte de los estudiantes.\n",
      "- Actividades Asíncronas: \n",
      "- Videos de temas complementarios\n",
      "- Talleres en casa\n",
      "5\n",
      "6\n",
      "\n",
      "30/10/2024\n",
      "Evaluación\n",
      "- 2 trabajos prácticos: \n",
      "- Práctica 1: Aplicativo para el análisis de sentimientos desde \n",
      "textos(25%)\n",
      "- Fecha: miércoles 27 de noviembre de 4 a 8 pm. \n",
      "- Práctica 2: Aplicativo practico basado en la Generación de Texto y \n",
      "Modelos de Lenguaje (25%)\n",
      "- Fecha: miércoles 26 de febrero de 4 a 8 pm.\n",
      "- Exposiciones sobre temáticas (20%)\n",
      "- Fecha miércoles 15 de enero de 4 a 8 pm\n",
      "- Seguimiento a Talleres (30%)\n",
      "- Miércoles 12 m\n",
      "Lecturas y Recursos Recomendados\n",
      "7\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "# Cargar el PDF\n",
    "loader = PyPDFLoader(\"data/1-01-Curso_PLN.pdf\")\n",
    "pages = loader.load()\n",
    "\n",
    "# Función de limpieza\n",
    "def clean_text(text):\n",
    "    # Eliminar metadatos innecesarios\n",
    "    text = re.sub(r'USUARIO|PScript5\\.dll.*?\\n|Acrobat Distiller.*?\\n', '', text)\n",
    "    \n",
    "    # Reemplazar caracteres especiales (\\uf06e, \\uf0a7, etc.)\n",
    "    text = re.sub(r'[\\uf06e\\uf0a7]', '-', text)\n",
    "\n",
    "    # Eliminar saltos de línea innecesarios, pero mantener párrafos\n",
    "    text = re.sub(r'\\n+', '\\n', text)\n",
    "\n",
    "    # Eliminar espacios en blanco al inicio y final del texto\n",
    "    text = text.strip()\n",
    "\n",
    "    return text\n",
    "\n",
    "# Limpiar cada página\n",
    "cleaned_pages = [clean_text(page.page_content) for page in pages]\n",
    "\n",
    "# Unir todas las páginas en un solo texto limpio\n",
    "final_text = \"\\n\\n\".join(cleaned_pages)\n",
    "\n",
    "# Mostrar el resultado limpio\n",
    "print(final_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fragmento 1:\n",
      "30/10/2024\n",
      "3011176 - Procesamiento del Lenguaje \n",
      "Natural\n",
      "FACULTAD DE MINAS\n",
      "Sede Medellín\n",
      "SINTELWEB\n",
      "Grupo de Investigación\n",
      "Sistemas Inteligentes Web\n",
      "JAIME ALBERTO GUZMAN LUNA, Ph.D\n",
      "Información de contacto\n",
      "- Jaime Alberto Guzmán Luna\n",
      "- Doctor en Ingeniería de Sistemas e Informática\n",
      "- M.Sc. en Ingeniería de Sistemas e Informática\n",
      "- Especialista en comunicación educativa\n",
      "- Ingeniero Civil\n",
      "- Áreas de trabajo\n",
      "- Inteligencia Artificial\n",
      "- Sistemas de recuperación de información\n",
      "--------------------------------------------------\n",
      "\n",
      "Fragmento 2:\n",
      "- Sistemas de recuperación de información\n",
      "- Planificación automática de procesos \n",
      "- Aprendizaje de máquinas\n",
      "- PLN con aprendizaje profundo\n",
      "- Universidad Nacional de Colombia\n",
      "- Oficina M8A-306\n",
      "- Email: jaguzman@unal.edu.co \n",
      "- Horario de Atención virtual (citas previas): \n",
      "- Lunes de 2:30 a 4:30 pm\n",
      "- Apoyo: \n",
      "- Alejandro Jiménez Franco\n",
      "- Email: aljimenezfr@unal.edu.co\n",
      "1\n",
      "2\n",
      "--------------------------------------------------\n",
      "\n",
      "Fragmento 3:\n",
      "30/10/2024\n",
      "Objetivos\n",
      "- Objetivo general\n",
      "- El objetivo de este curso es proporcionar a los estudiantes las habilidades y\n",
      "conocimientos fundamentales en el campo del Procesamiento de Lenguaje Natural,\n",
      "un campo de la inteligencia artificial que permite a las máquinas comprender y\n",
      "manipular el lenguaje humano. Los temas abarcan desde el procesamiento de\n",
      "texto básico hasta la comprensión del lenguaje, con aplicaciones en análisis de\n",
      "sentimientos, traducciónautomática, chatbots y más.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "\n",
    "# Paso 1: Convertir el texto limpio en un objeto Document\n",
    "# Asegúrate de que final_text es un string que contiene el contenido limpio\n",
    "document = Document(page_content=final_text)  # Debe ser un objeto Document\n",
    "\n",
    "# Paso 2: Función para dividir el texto en fragmentos\n",
    "def split_text(document):\n",
    "    \"\"\"Divide el texto en fragmentos más pequeños para procesamiento.\"\"\"\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=500,      # Número de caracteres por fragmento\n",
    "        chunk_overlap=50,    # Traslape entre fragmentos\n",
    "        length_function=len, # Función de longitud\n",
    "        separators=[\"\\n\\n\", \"\\n\", \" \"]  # Separadores\n",
    "    )\n",
    "\n",
    "    # Aplicar el splitter al documento (documento debe ser una lista)\n",
    "    textos_fragmentados = text_splitter.split_documents([document])  # Pasamos una lista de documentos\n",
    "\n",
    "    return textos_fragmentados\n",
    "\n",
    "# Paso 3: Ejecutar la función y obtener los fragmentos\n",
    "chunks = split_text(document)\n",
    "\n",
    "# Mostrar un fragmento de ejemplo\n",
    "for i, chunk in enumerate(chunks[:3]):  # Mostramos solo los 3 primeros\n",
    "    print(f\"\\nFragmento {i+1}:\\n{chunk.page_content}\\n{'-'*50}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crear embeddings\n",
    "\n",
    "Se hará uso de un modelo de Hugging Face all-MiniLM-L6-v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usar modelo de Hugging Face\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Almacenar  embeddings en ChromaDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "def create_vectorstore(chunks, embedding_function, vectorstore_path):\n",
    "\n",
    "    # Lista de valores unicos para documentos\n",
    "    ids = [str(uuid.uuid5(uuid.NAMESPACE_DNS, doc.page_content)) for doc in chunks]\n",
    "    \n",
    "    unique_ids = set()\n",
    "    unique_chunks = []\n",
    "    \n",
    "    unique_chunks = [] \n",
    "    for chunk, id in zip(chunks, ids):     \n",
    "        if id not in unique_ids:       \n",
    "            unique_ids.add(id)\n",
    "            unique_chunks.append(chunk) \n",
    "\n",
    "    #Crea una database de chroma\n",
    "    vectorstore = Chroma.from_documents(documents=unique_chunks, \n",
    "                                        ids=list(unique_ids),\n",
    "                                        embedding=embedding_function, \n",
    "                                        persist_directory = vectorstore_path)\n",
    "\n",
    "    vectorstore.persist()\n",
    "    \n",
    "    return vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = create_vectorstore(chunks=chunck, \n",
    "                                 embedding_function=embeddings, \n",
    "                                 vectorstore_path=\"./vectorstore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Consulta de datos relevantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cargamos el vectorstore\n",
    "database = Chroma(persist_directory=\"vectorstore\",embedding_function=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Eres un asistente para la generación de materiales educativos basados en un programa de curso.\n",
      "Utiliza la siguiente información recuperada para crear materiales de aprendizaje estructurados.\n",
      "\n",
      "---\n",
      "\n",
      "**Título del curso:** ¿Cuál es el título del curso? [Document(metadata={'author': 'USUARIO', 'creationdate': '2024-10-30T15:27:39-05:00', 'creator': 'PScript5.dll Version 5.2.2', 'moddate': '2024-10-30T15:27:39-05:00', 'page': 1, 'page_label': '2', 'producer': 'Acrobat Distiller 19.0 (Windows)', 'source': 'data/1-01-Curso_PLN.pdf', 'title': 'Microsoft PowerPoint - 1-01-Curso_PLN', 'total_pages': 4}, page_content='\\uf06e Aplicar modelos y herramientas de PLN avanzadas a problemas del mundo real\\n(traducción automática, Preguntas&Respuestas- QA, análisis de conversaciones,\\netc)\\nContenido del Curso (1)\\n\\uf06e TEMA 1: Introducción al Procesamiento de Lenguaje Natural.\\n\\uf06e Generalidades del Procesamiento de Lenguaje Natural y su importancia.\\n\\uf06e Limpieza y normalización de textos en Python\\n\\uf06e Manejo de errores ortográficos: Pyspellchecker\\n\\uf06e TEMA 2: Procesamiento de Texto.'), Document(metadata={'author': 'USUARIO', 'creationdate': '2024-10-30T15:27:39-05:00', 'creator': 'PScript5.dll Version 5.2.2', 'moddate': '2024-10-30T15:27:39-05:00', 'page': 1, 'page_label': '2', 'producer': 'Acrobat Distiller 19.0 (Windows)', 'source': 'data/1-01-Curso_PLN.pdf', 'title': 'Microsoft PowerPoint - 1-01-Curso_PLN', 'total_pages': 4}, page_content='30/10/2024\\nObjetivos\\n\\uf06e Objetivo general\\n\\uf06e El objetivo de este curso es proporcionar a los estudiantes las habilidades y\\nconocimientos fundamentales en el campo del Procesamiento de Lenguaje Natural,\\nun campo de la inteligencia artificial que permite a las máquinas comprender y\\nmanipular el lenguaje humano. Los temas abarcan desde el procesamiento de\\ntexto básico hasta la comprensión del lenguaje, con aplicaciones en análisis de\\nsentimientos, traducciónautomática, chatbots y más.'), Document(metadata={'author': 'USUARIO', 'creationdate': '2024-10-30T15:27:39-05:00', 'creator': 'PScript5.dll Version 5.2.2', 'moddate': '2024-10-30T15:27:39-05:00', 'page': 2, 'page_label': '3', 'producer': 'Acrobat Distiller 19.0 (Windows)', 'source': 'data/1-01-Curso_PLN.pdf', 'title': 'Microsoft PowerPoint - 1-01-Curso_PLN', 'total_pages': 4}, page_content='30/10/2024\\nContenido del Curso (2)\\n\\uf06e TEMA 4:Análisis de Sentimientos, clasificación y extracción de información en textos.\\n\\uf06e Introducción al análisis de sentimientos; Métodos supervisados y no supervisados; y \\nAplicaciones prácticas y casos de estudio\\n\\uf06e Clasificación de Texto con algoritmos de aprendizaje automático (Modelos de clasificación \\npopulares: Naive Bayes, SVM, redes neuronales), Evaluación de modelos de clasificación de \\ntexto.'), Document(metadata={'author': 'USUARIO', 'creationdate': '2024-10-30T15:27:39-05:00', 'creator': 'PScript5.dll Version 5.2.2', 'moddate': '2024-10-30T15:27:39-05:00', 'page': 2, 'page_label': '3', 'producer': 'Acrobat Distiller 19.0 (Windows)', 'source': 'data/1-01-Curso_PLN.pdf', 'title': 'Microsoft PowerPoint - 1-01-Curso_PLN', 'total_pages': 4}, page_content='\\uf06e Talleres en casa\\n5\\n6')]\n",
      "\n",
      "**Temas principales:** ¿Cuáles son los temas principales que se cubren en el curso? [Document(metadata={'author': 'USUARIO', 'creationdate': '2024-10-30T15:27:39-05:00', 'creator': 'PScript5.dll Version 5.2.2', 'moddate': '2024-10-30T15:27:39-05:00', 'page': 2, 'page_label': '3', 'producer': 'Acrobat Distiller 19.0 (Windows)', 'source': 'data/1-01-Curso_PLN.pdf', 'title': 'Microsoft PowerPoint - 1-01-Curso_PLN', 'total_pages': 4}, page_content='\\uf06e Transformadores para generación de texto (GPT).\\n\\uf06e Aplicaciones prácticas en PLN Traducción automática, chatbots, resumen de texto, QA \\n(Question Answering), análisis de conversaciones.\\nMetodología\\n\\uf06e Actividades presenciales: \\n\\uf06e Clases magistrales por parte del docente.\\n\\uf06e Talleres: Alumnos en compañía del docente y monitores\\n\\uf06e Exposiciones de los estudiantes\\n\\uf06e Presentación de prácticas por parte de los estudiantes.\\n\\uf06e Actividades Asíncronas: \\n\\uf06e Videos de temas complementarios\\n\\uf06e Talleres en casa'), Document(metadata={'author': 'USUARIO', 'creationdate': '2024-10-30T15:27:39-05:00', 'creator': 'PScript5.dll Version 5.2.2', 'moddate': '2024-10-30T15:27:39-05:00', 'page': 2, 'page_label': '3', 'producer': 'Acrobat Distiller 19.0 (Windows)', 'source': 'data/1-01-Curso_PLN.pdf', 'title': 'Microsoft PowerPoint - 1-01-Curso_PLN', 'total_pages': 4}, page_content='\\uf06e Talleres en casa\\n5\\n6'), Document(metadata={'author': 'USUARIO', 'creationdate': '2024-10-30T15:27:39-05:00', 'creator': 'PScript5.dll Version 5.2.2', 'moddate': '2024-10-30T15:27:39-05:00', 'page': 1, 'page_label': '2', 'producer': 'Acrobat Distiller 19.0 (Windows)', 'source': 'data/1-01-Curso_PLN.pdf', 'title': 'Microsoft PowerPoint - 1-01-Curso_PLN', 'total_pages': 4}, page_content='\\uf06e Aplicar modelos y herramientas de PLN avanzadas a problemas del mundo real\\n(traducción automática, Preguntas&Respuestas- QA, análisis de conversaciones,\\netc)\\nContenido del Curso (1)\\n\\uf06e TEMA 1: Introducción al Procesamiento de Lenguaje Natural.\\n\\uf06e Generalidades del Procesamiento de Lenguaje Natural y su importancia.\\n\\uf06e Limpieza y normalización de textos en Python\\n\\uf06e Manejo de errores ortográficos: Pyspellchecker\\n\\uf06e TEMA 2: Procesamiento de Texto.'), Document(metadata={'author': 'USUARIO', 'creationdate': '2024-10-30T15:27:39-05:00', 'creator': 'PScript5.dll Version 5.2.2', 'moddate': '2024-10-30T15:27:39-05:00', 'page': 1, 'page_label': '2', 'producer': 'Acrobat Distiller 19.0 (Windows)', 'source': 'data/1-01-Curso_PLN.pdf', 'title': 'Microsoft PowerPoint - 1-01-Curso_PLN', 'total_pages': 4}, page_content='30/10/2024\\nObjetivos\\n\\uf06e Objetivo general\\n\\uf06e El objetivo de este curso es proporcionar a los estudiantes las habilidades y\\nconocimientos fundamentales en el campo del Procesamiento de Lenguaje Natural,\\nun campo de la inteligencia artificial que permite a las máquinas comprender y\\nmanipular el lenguaje humano. Los temas abarcan desde el procesamiento de\\ntexto básico hasta la comprensión del lenguaje, con aplicaciones en análisis de\\nsentimientos, traducciónautomática, chatbots y más.')]\n",
      "\n",
      "**Objetivos de aprendizaje:** ¿Cuáles son los objetivos de aprendizaje de este curso? [Document(metadata={'author': 'USUARIO', 'creationdate': '2024-10-30T15:27:39-05:00', 'creator': 'PScript5.dll Version 5.2.2', 'moddate': '2024-10-30T15:27:39-05:00', 'page': 2, 'page_label': '3', 'producer': 'Acrobat Distiller 19.0 (Windows)', 'source': 'data/1-01-Curso_PLN.pdf', 'title': 'Microsoft PowerPoint - 1-01-Curso_PLN', 'total_pages': 4}, page_content='30/10/2024\\nContenido del Curso (2)\\n\\uf06e TEMA 4:Análisis de Sentimientos, clasificación y extracción de información en textos.\\n\\uf06e Introducción al análisis de sentimientos; Métodos supervisados y no supervisados; y \\nAplicaciones prácticas y casos de estudio\\n\\uf06e Clasificación de Texto con algoritmos de aprendizaje automático (Modelos de clasificación \\npopulares: Naive Bayes, SVM, redes neuronales), Evaluación de modelos de clasificación de \\ntexto.'), Document(metadata={'author': 'USUARIO', 'creationdate': '2024-10-30T15:27:39-05:00', 'creator': 'PScript5.dll Version 5.2.2', 'moddate': '2024-10-30T15:27:39-05:00', 'page': 1, 'page_label': '2', 'producer': 'Acrobat Distiller 19.0 (Windows)', 'source': 'data/1-01-Curso_PLN.pdf', 'title': 'Microsoft PowerPoint - 1-01-Curso_PLN', 'total_pages': 4}, page_content='\\uf06e Aplicar modelos y herramientas de PLN avanzadas a problemas del mundo real\\n(traducción automática, Preguntas&Respuestas- QA, análisis de conversaciones,\\netc)\\nContenido del Curso (1)\\n\\uf06e TEMA 1: Introducción al Procesamiento de Lenguaje Natural.\\n\\uf06e Generalidades del Procesamiento de Lenguaje Natural y su importancia.\\n\\uf06e Limpieza y normalización de textos en Python\\n\\uf06e Manejo de errores ortográficos: Pyspellchecker\\n\\uf06e TEMA 2: Procesamiento de Texto.'), Document(metadata={'author': 'USUARIO', 'creationdate': '2024-10-30T15:27:39-05:00', 'creator': 'PScript5.dll Version 5.2.2', 'moddate': '2024-10-30T15:27:39-05:00', 'page': 0, 'page_label': '1', 'producer': 'Acrobat Distiller 19.0 (Windows)', 'source': 'data/1-01-Curso_PLN.pdf', 'title': 'Microsoft PowerPoint - 1-01-Curso_PLN', 'total_pages': 4}, page_content='\\uf06e Sistemas de recuperación de información\\n\\uf06e Planificación automática de procesos \\n\\uf06e Aprendizaje de máquinas\\n\\uf06e PLN con aprendizaje profundo\\n\\uf06e Universidad Nacional de Colombia\\n\\uf06e Oficina M8A-306\\n\\uf06e Email: jaguzman@unal.edu.co \\n\\uf06e Horario de Atención virtual (citas previas): \\n\\uf06e Lunes de 2:30 a 4:30 pm\\n\\uf0a7 Apoyo: \\n\\uf0a7 Alejandro Jiménez Franco\\n\\uf0a7 Email: aljimenezfr@unal.edu.co\\n1\\n2'), Document(metadata={'author': 'USUARIO', 'creationdate': '2024-10-30T15:27:39-05:00', 'creator': 'PScript5.dll Version 5.2.2', 'moddate': '2024-10-30T15:27:39-05:00', 'page': 2, 'page_label': '3', 'producer': 'Acrobat Distiller 19.0 (Windows)', 'source': 'data/1-01-Curso_PLN.pdf', 'title': 'Microsoft PowerPoint - 1-01-Curso_PLN', 'total_pages': 4}, page_content='\\uf06e Transformadores para generación de texto (GPT).\\n\\uf06e Aplicaciones prácticas en PLN Traducción automática, chatbots, resumen de texto, QA \\n(Question Answering), análisis de conversaciones.\\nMetodología\\n\\uf06e Actividades presenciales: \\n\\uf06e Clases magistrales por parte del docente.\\n\\uf06e Talleres: Alumnos en compañía del docente y monitores\\n\\uf06e Exposiciones de los estudiantes\\n\\uf06e Presentación de prácticas por parte de los estudiantes.\\n\\uf06e Actividades Asíncronas: \\n\\uf06e Videos de temas complementarios\\n\\uf06e Talleres en casa')]\n",
      "\n",
      "**Lecturas y recursos recomendados:** ¿Cuáles son las lecturas o recursos recomendados para este curso? [Document(metadata={'author': 'USUARIO', 'creationdate': '2024-10-30T15:27:39-05:00', 'creator': 'PScript5.dll Version 5.2.2', 'moddate': '2024-10-30T15:27:39-05:00', 'page': 1, 'page_label': '2', 'producer': 'Acrobat Distiller 19.0 (Windows)', 'source': 'data/1-01-Curso_PLN.pdf', 'title': 'Microsoft PowerPoint - 1-01-Curso_PLN', 'total_pages': 4}, page_content='\\uf06e Aplicar modelos y herramientas de PLN avanzadas a problemas del mundo real\\n(traducción automática, Preguntas&Respuestas- QA, análisis de conversaciones,\\netc)\\nContenido del Curso (1)\\n\\uf06e TEMA 1: Introducción al Procesamiento de Lenguaje Natural.\\n\\uf06e Generalidades del Procesamiento de Lenguaje Natural y su importancia.\\n\\uf06e Limpieza y normalización de textos en Python\\n\\uf06e Manejo de errores ortográficos: Pyspellchecker\\n\\uf06e TEMA 2: Procesamiento de Texto.'), Document(metadata={'author': 'USUARIO', 'creationdate': '2024-10-30T15:27:39-05:00', 'creator': 'PScript5.dll Version 5.2.2', 'moddate': '2024-10-30T15:27:39-05:00', 'page': 2, 'page_label': '3', 'producer': 'Acrobat Distiller 19.0 (Windows)', 'source': 'data/1-01-Curso_PLN.pdf', 'title': 'Microsoft PowerPoint - 1-01-Curso_PLN', 'total_pages': 4}, page_content='\\uf06e Transformadores para generación de texto (GPT).\\n\\uf06e Aplicaciones prácticas en PLN Traducción automática, chatbots, resumen de texto, QA \\n(Question Answering), análisis de conversaciones.\\nMetodología\\n\\uf06e Actividades presenciales: \\n\\uf06e Clases magistrales por parte del docente.\\n\\uf06e Talleres: Alumnos en compañía del docente y monitores\\n\\uf06e Exposiciones de los estudiantes\\n\\uf06e Presentación de prácticas por parte de los estudiantes.\\n\\uf06e Actividades Asíncronas: \\n\\uf06e Videos de temas complementarios\\n\\uf06e Talleres en casa'), Document(metadata={'author': 'USUARIO', 'creationdate': '2024-10-30T15:27:39-05:00', 'creator': 'PScript5.dll Version 5.2.2', 'moddate': '2024-10-30T15:27:39-05:00', 'page': 1, 'page_label': '2', 'producer': 'Acrobat Distiller 19.0 (Windows)', 'source': 'data/1-01-Curso_PLN.pdf', 'title': 'Microsoft PowerPoint - 1-01-Curso_PLN', 'total_pages': 4}, page_content='30/10/2024\\nObjetivos\\n\\uf06e Objetivo general\\n\\uf06e El objetivo de este curso es proporcionar a los estudiantes las habilidades y\\nconocimientos fundamentales en el campo del Procesamiento de Lenguaje Natural,\\nun campo de la inteligencia artificial que permite a las máquinas comprender y\\nmanipular el lenguaje humano. Los temas abarcan desde el procesamiento de\\ntexto básico hasta la comprensión del lenguaje, con aplicaciones en análisis de\\nsentimientos, traducciónautomática, chatbots y más.'), Document(metadata={'author': 'USUARIO', 'creationdate': '2024-10-30T15:27:39-05:00', 'creator': 'PScript5.dll Version 5.2.2', 'moddate': '2024-10-30T15:27:39-05:00', 'page': 1, 'page_label': '2', 'producer': 'Acrobat Distiller 19.0 (Windows)', 'source': 'data/1-01-Curso_PLN.pdf', 'title': 'Microsoft PowerPoint - 1-01-Curso_PLN', 'total_pages': 4}, page_content='\\uf06e Objetivos específicos\\n\\uf06e Comprender los conceptos clave en Procesamiento del Lenguaje Natural\\nfamiliarizándose con las bibliotecas populares de PLN (como NLTK, SpaCy,\\nTransformers de Hugging Face, etc.)\\n\\uf06e Familiarizarse con las técnicas y algori tmos utilizados para el procesamiento de\\ntexto, análisis de sentimiento, clasificación de texto y extracción de la información.\\n\\uf06e Entender los Modelos de Lenguaje y sus aplicaciones prácticas.')]\n",
      "\n",
      "**Preguntas para discusión:** ¿Cuáles son algunas preguntas para discusión en este curso? [Document(metadata={'author': 'USUARIO', 'creationdate': '2024-10-30T15:27:39-05:00', 'creator': 'PScript5.dll Version 5.2.2', 'moddate': '2024-10-30T15:27:39-05:00', 'page': 2, 'page_label': '3', 'producer': 'Acrobat Distiller 19.0 (Windows)', 'source': 'data/1-01-Curso_PLN.pdf', 'title': 'Microsoft PowerPoint - 1-01-Curso_PLN', 'total_pages': 4}, page_content='\\uf06e Transformadores para generación de texto (GPT).\\n\\uf06e Aplicaciones prácticas en PLN Traducción automática, chatbots, resumen de texto, QA \\n(Question Answering), análisis de conversaciones.\\nMetodología\\n\\uf06e Actividades presenciales: \\n\\uf06e Clases magistrales por parte del docente.\\n\\uf06e Talleres: Alumnos en compañía del docente y monitores\\n\\uf06e Exposiciones de los estudiantes\\n\\uf06e Presentación de prácticas por parte de los estudiantes.\\n\\uf06e Actividades Asíncronas: \\n\\uf06e Videos de temas complementarios\\n\\uf06e Talleres en casa'), Document(metadata={'author': 'USUARIO', 'creationdate': '2024-10-30T15:27:39-05:00', 'creator': 'PScript5.dll Version 5.2.2', 'moddate': '2024-10-30T15:27:39-05:00', 'page': 2, 'page_label': '3', 'producer': 'Acrobat Distiller 19.0 (Windows)', 'source': 'data/1-01-Curso_PLN.pdf', 'title': 'Microsoft PowerPoint - 1-01-Curso_PLN', 'total_pages': 4}, page_content='\\uf06e Talleres en casa\\n5\\n6'), Document(metadata={'author': 'USUARIO', 'creationdate': '2024-10-30T15:27:39-05:00', 'creator': 'PScript5.dll Version 5.2.2', 'moddate': '2024-10-30T15:27:39-05:00', 'page': 2, 'page_label': '3', 'producer': 'Acrobat Distiller 19.0 (Windows)', 'source': 'data/1-01-Curso_PLN.pdf', 'title': 'Microsoft PowerPoint - 1-01-Curso_PLN', 'total_pages': 4}, page_content='30/10/2024\\nContenido del Curso (2)\\n\\uf06e TEMA 4:Análisis de Sentimientos, clasificación y extracción de información en textos.\\n\\uf06e Introducción al análisis de sentimientos; Métodos supervisados y no supervisados; y \\nAplicaciones prácticas y casos de estudio\\n\\uf06e Clasificación de Texto con algoritmos de aprendizaje automático (Modelos de clasificación \\npopulares: Naive Bayes, SVM, redes neuronales), Evaluación de modelos de clasificación de \\ntexto.'), Document(metadata={'author': 'USUARIO', 'creationdate': '2024-10-30T15:27:39-05:00', 'creator': 'PScript5.dll Version 5.2.2', 'moddate': '2024-10-30T15:27:39-05:00', 'page': 1, 'page_label': '2', 'producer': 'Acrobat Distiller 19.0 (Windows)', 'source': 'data/1-01-Curso_PLN.pdf', 'title': 'Microsoft PowerPoint - 1-01-Curso_PLN', 'total_pages': 4}, page_content='\\uf06e Aplicar modelos y herramientas de PLN avanzadas a problemas del mundo real\\n(traducción automática, Preguntas&Respuestas- QA, análisis de conversaciones,\\netc)\\nContenido del Curso (1)\\n\\uf06e TEMA 1: Introducción al Procesamiento de Lenguaje Natural.\\n\\uf06e Generalidades del Procesamiento de Lenguaje Natural y su importancia.\\n\\uf06e Limpieza y normalización de textos en Python\\n\\uf06e Manejo de errores ortográficos: Pyspellchecker\\n\\uf06e TEMA 2: Procesamiento de Texto.')]\n",
      "\n",
      "**Ejercicios y problemas de práctica:** ¿Qué ejercicios o problemas de práctica se incluyen en el programa del curso? [Document(metadata={'author': 'USUARIO', 'creationdate': '2024-10-30T15:27:39-05:00', 'creator': 'PScript5.dll Version 5.2.2', 'moddate': '2024-10-30T15:27:39-05:00', 'page': 1, 'page_label': '2', 'producer': 'Acrobat Distiller 19.0 (Windows)', 'source': 'data/1-01-Curso_PLN.pdf', 'title': 'Microsoft PowerPoint - 1-01-Curso_PLN', 'total_pages': 4}, page_content='\\uf06e Aplicar modelos y herramientas de PLN avanzadas a problemas del mundo real\\n(traducción automática, Preguntas&Respuestas- QA, análisis de conversaciones,\\netc)\\nContenido del Curso (1)\\n\\uf06e TEMA 1: Introducción al Procesamiento de Lenguaje Natural.\\n\\uf06e Generalidades del Procesamiento de Lenguaje Natural y su importancia.\\n\\uf06e Limpieza y normalización de textos en Python\\n\\uf06e Manejo de errores ortográficos: Pyspellchecker\\n\\uf06e TEMA 2: Procesamiento de Texto.'), Document(metadata={'author': 'USUARIO', 'creationdate': '2024-10-30T15:27:39-05:00', 'creator': 'PScript5.dll Version 5.2.2', 'moddate': '2024-10-30T15:27:39-05:00', 'page': 2, 'page_label': '3', 'producer': 'Acrobat Distiller 19.0 (Windows)', 'source': 'data/1-01-Curso_PLN.pdf', 'title': 'Microsoft PowerPoint - 1-01-Curso_PLN', 'total_pages': 4}, page_content='30/10/2024\\nContenido del Curso (2)\\n\\uf06e TEMA 4:Análisis de Sentimientos, clasificación y extracción de información en textos.\\n\\uf06e Introducción al análisis de sentimientos; Métodos supervisados y no supervisados; y \\nAplicaciones prácticas y casos de estudio\\n\\uf06e Clasificación de Texto con algoritmos de aprendizaje automático (Modelos de clasificación \\npopulares: Naive Bayes, SVM, redes neuronales), Evaluación de modelos de clasificación de \\ntexto.'), Document(metadata={'author': 'USUARIO', 'creationdate': '2024-10-30T15:27:39-05:00', 'creator': 'PScript5.dll Version 5.2.2', 'moddate': '2024-10-30T15:27:39-05:00', 'page': 2, 'page_label': '3', 'producer': 'Acrobat Distiller 19.0 (Windows)', 'source': 'data/1-01-Curso_PLN.pdf', 'title': 'Microsoft PowerPoint - 1-01-Curso_PLN', 'total_pages': 4}, page_content='\\uf06e Transformadores para generación de texto (GPT).\\n\\uf06e Aplicaciones prácticas en PLN Traducción automática, chatbots, resumen de texto, QA \\n(Question Answering), análisis de conversaciones.\\nMetodología\\n\\uf06e Actividades presenciales: \\n\\uf06e Clases magistrales por parte del docente.\\n\\uf06e Talleres: Alumnos en compañía del docente y monitores\\n\\uf06e Exposiciones de los estudiantes\\n\\uf06e Presentación de prácticas por parte de los estudiantes.\\n\\uf06e Actividades Asíncronas: \\n\\uf06e Videos de temas complementarios\\n\\uf06e Talleres en casa'), Document(metadata={'author': 'USUARIO', 'creationdate': '2024-10-30T15:27:39-05:00', 'creator': 'PScript5.dll Version 5.2.2', 'moddate': '2024-10-30T15:27:39-05:00', 'page': 0, 'page_label': '1', 'producer': 'Acrobat Distiller 19.0 (Windows)', 'source': 'data/1-01-Curso_PLN.pdf', 'title': 'Microsoft PowerPoint - 1-01-Curso_PLN', 'total_pages': 4}, page_content='\\uf06e Sistemas de recuperación de información\\n\\uf06e Planificación automática de procesos \\n\\uf06e Aprendizaje de máquinas\\n\\uf06e PLN con aprendizaje profundo\\n\\uf06e Universidad Nacional de Colombia\\n\\uf06e Oficina M8A-306\\n\\uf06e Email: jaguzman@unal.edu.co \\n\\uf06e Horario de Atención virtual (citas previas): \\n\\uf06e Lunes de 2:30 a 4:30 pm\\n\\uf0a7 Apoyo: \\n\\uf0a7 Alejandro Jiménez Franco\\n\\uf0a7 Email: aljimenezfr@unal.edu.co\\n1\\n2')]\n",
      "\n",
      "---\n",
      "\n",
      "Basándote en la información anterior, genera los siguientes materiales educativos:\n",
      "1. Notas detalladas de clase.\n",
      "2. Problemas de práctica con soluciones.\n",
      "3. Preguntas para discusión.\n",
      "4. Objetivos de aprendizaje específicos para cada tema.\n",
      "5. Lecturas y recursos sugeridos.\n",
      "\n",
      "Estructura la respuesta de manera clara y detallada. Si no encuentras algo en el documento puedes utilizar información de internet\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "#Hacemos el prompt configurado con el retrieve\n",
    "PROMPT_TEMPLATE = \"\"\"\n",
    "Eres un asistente para la generación de materiales educativos basados en un programa de curso.\n",
    "Utiliza la siguiente información recuperada para crear materiales de aprendizaje estructurados.\n",
    "\n",
    "---\n",
    "\n",
    "**Título del curso:** ¿Cuál es el título del curso? {title}\n",
    "\n",
    "**Temas principales:** ¿Cuáles son los temas principales que se cubren en el curso? {topics}\n",
    "\n",
    "**Objetivos de aprendizaje:** ¿Cuáles son los objetivos de aprendizaje de este curso? {objectives}\n",
    "\n",
    "**Lecturas y recursos recomendados:** ¿Cuáles son las lecturas o recursos recomendados para este curso? {resources}\n",
    "\n",
    "**Preguntas para discusión:** ¿Cuáles son algunas preguntas para discusión en este curso? {discussion_questions}\n",
    "\n",
    "**Ejercicios y problemas de práctica:** ¿Qué ejercicios o problemas de práctica se incluyen en el programa del curso? {practice_problems}\n",
    "\n",
    "---\n",
    "\n",
    "Basándote en la información anterior, genera los siguientes materiales educativos:\n",
    "1. Notas detalladas de clase.\n",
    "2. Problemas de práctica con soluciones.\n",
    "3. Preguntas para discusión.\n",
    "4. Objetivos de aprendizaje específicos para cada tema.\n",
    "5. Lecturas y recursos sugeridos.\n",
    "\n",
    "Estructura la respuesta de manera clara y detallada. Si no encuentras algo en el documento puedes utilizar información de internet\n",
    "\"\"\"\n",
    "\n",
    "#Llamamos al retriever\n",
    "retriever = vectorstore.as_retriever(search_type=\"similarity\")\n",
    "\n",
    "title = retriever.invoke(\"¿Cuál es el título del curso?\")\n",
    "topics = retriever.invoke(\"¿Cuáles son los temas principales que se cubren en el curso?\")\n",
    "objectives = retriever.invoke(\"¿Cuáles son los objetivos de aprendizaje de este curso?\")\n",
    "resources = retriever.invoke(\"¿Cuáles son las lecturas o recursos recomendados para este curso?\")\n",
    "discussion_questions = retriever.invoke(\"¿Cuáles son algunas preguntas para discusión en este curso?\")\n",
    "practice_problems = retriever.invoke(\"¿Qué ejercicios o problemas de práctica se incluyen en el programa del curso?\")\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_template(PROMPT_TEMPLATE)\n",
    "#Insertamos los valores en el prompt\n",
    "final_prompt = PROMPT_TEMPLATE.format(\n",
    "    title=title,\n",
    "    topics=topics,\n",
    "    objectives=objectives,\n",
    "    resources=resources,\n",
    "    discussion_questions=discussion_questions,\n",
    "    practice_problems=practice_problems\n",
    ")\n",
    "\n",
    "print(final_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definimos el LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importamos el API Key de las variables de entorno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "os.environ['GOOGLE_API_KEY'] = os.getenv('GOOGLE_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementamos el modelo de Gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¡Absolutamente! Aquí tienes un conjunto de materiales educativos estructurados basados en la información proporcionada sobre el curso de Procesamiento del Lenguaje Natural (PLN).\n",
      "\n",
      "**Título del Curso:** Procesamiento del Lenguaje Natural\n",
      "\n",
      "**Objetivo General del Curso:** Proporcionar a los estudiantes las habilidades y conocimientos fundamentales en el campo del Procesamiento del Lenguaje Natural, un campo de la inteligencia artificial que permite a las máquinas comprender y manipular el lenguaje humano.\n",
      "\n",
      "**1. Notas Detalladas de Clase**\n",
      "\n",
      "**TEMA 1: Introducción al Procesamiento de Lenguaje Natural**\n",
      "\n",
      "*   **Generalidades del Procesamiento de Lenguaje Natural y su importancia:**\n",
      "\n",
      "    *   Definición de PLN: Campo de la IA que se centra en la interacción entre computadoras y el lenguaje humano.\n",
      "    *   Importancia: Permite a las máquinas comprender, interpretar y generar lenguaje humano de manera útil.\n",
      "    *   Aplicaciones: Amplias y variadas (traducción automática, chatbots, análisis de sentimientos, etc.).\n",
      "*   **Limpieza y normalización de textos en Python:**\n",
      "\n",
      "    *   Importancia de la limpieza: Elimina ruido y datos irrelevantes para mejorar la calidad del análisis.\n",
      "    *   Técnicas comunes: Eliminación de mayúsculas, puntuación, caracteres especiales, espacios en blanco adicionales.\n",
      "    *   Librerías de Python: `re` (expresiones regulares), `string` (manipulación de cadenas).\n",
      "*   **Manejo de errores ortográficos: Pyspellchecker:**\n",
      "\n",
      "    *   Importancia de corregir errores: Mejora la precisión y coherencia del análisis.\n",
      "    *   `Pyspellchecker`: Biblioteca de Python para detectar y corregir errores ortográficos.\n",
      "    *   Funcionamiento: Utiliza diccionarios y algoritmos probabilísticos para sugerir correcciones.\n",
      "\n",
      "**TEMA 2: Procesamiento de Texto**\n",
      "\n",
      "*(No hay detalles específicos proporcionados en el extracto, pero se puede asumir que cubre temas como tokenización, lematización, stemming, etc. - ver abajo en \"Lecturas y Recursos Sugeridos\" para complementar)*\n",
      "\n",
      "**TEMA 4: Análisis de Sentimientos, clasificación y extracción de información en textos.**\n",
      "\n",
      "*   **Introducción al análisis de sentimientos:**\n",
      "    *   Definición: Proceso de determinar la emoción o actitud expresada en un texto.\n",
      "    *   Métodos supervisados: Utilizan datos etiquetados para entrenar modelos de clasificación.\n",
      "    *   Métodos no supervisados: Se basan en diccionarios de sentimientos y reglas heurísticas.\n",
      "    *   Aplicaciones prácticas y casos de estudio: análisis de redes sociales, reseñas de productos, etc.\n",
      "*   **Clasificación de Texto con algoritmos de aprendizaje automático:**\n",
      "    *   Modelos de clasificación populares: Naive Bayes, SVM, redes neuronales.\n",
      "    *   Evaluación de modelos de clasificación de texto.\n",
      "\n",
      "**TEMA Adicional: Transformadores para generación de texto (GPT)**\n",
      "\n",
      "*   **Transformadores (GPT):**\n",
      "    *   Arquitectura: Funcionamiento interno de los modelos Transformer.\n",
      "    *   Entrenamiento: Cómo se entrenan estos modelos con grandes cantidades de texto.\n",
      "*   **Aplicaciones prácticas en PLN:**\n",
      "    *   Traducción automática: De un idioma a otro.\n",
      "    *   Chatbots: Interacción conversacional con usuarios.\n",
      "    *   Resumen de texto: Generación de resúmenes concisos.\n",
      "    *   QA (Question Answering): Responder preguntas basadas en texto.\n",
      "    *   Análisis de conversaciones: Identificación de temas, sentimientos y patrones.\n",
      "\n",
      "**2. Problemas de Práctica con Soluciones**\n",
      "\n",
      "*(Nota: Los problemas aquí son ejemplos y pueden necesitar ser adaptados según el nivel del curso)*\n",
      "\n",
      "**Tema 1: Limpieza y Normalización**\n",
      "\n",
      "*   **Problema:** Dado el siguiente texto, escribe un script en Python para eliminar la puntuación, convertir todo a minúsculas y eliminar las palabras vacías (stop words):\n",
      "\n",
      "    ```python\n",
      "    texto = \"¡Este es un ejemplo de texto! con... algunas MAYÚSCULAS y palabras vacías como: el, la, un.\"\n",
      "    ```\n",
      "\n",
      "    *   **Solución:**\n",
      "\n",
      "    ```python\n",
      "    import string\n",
      "    from nltk.corpus import stopwords\n",
      "    from nltk.tokenize import word_tokenize\n",
      "\n",
      "    texto = \"¡Este es un ejemplo de texto! con... algunas MAYÚSCULAS y palabras vacías como: el, la, un.\"\n",
      "\n",
      "    # Eliminar puntuación\n",
      "    texto = texto.translate(str.maketrans('', '', string.punctuation))\n",
      "\n",
      "    # Convertir a minúsculas\n",
      "    texto = texto.lower()\n",
      "\n",
      "    # Tokenizar\n",
      "    tokens = word_tokenize(texto)\n",
      "\n",
      "    # Eliminar palabras vacías\n",
      "    stop_words = set(stopwords.words('spanish'))  # Puedes cambiar a 'english' si es necesario\n",
      "    tokens_sin_stopwords = [w for w in tokens if not w in stop_words]\n",
      "\n",
      "    print(tokens_sin_stopwords)\n",
      "    #Resultado: ['ejemplo', 'texto', 'mayúsculas', 'palabras', 'vacías']\n",
      "    ```\n",
      "\n",
      "**Tema 2: Análisis de Sentimientos**\n",
      "\n",
      "*   **Problema:** Utiliza la librería `TextBlob` para determinar el sentimiento (polaridad y subjetividad) de las siguientes frases:\n",
      "\n",
      "    1.  \"Este es un día maravilloso.\"\n",
      "    2.  \"Estoy muy decepcionado con este producto.\"\n",
      "\n",
      "    *   **Solución:**\n",
      "\n",
      "    ```python\n",
      "    from textblob import TextBlob\n",
      "\n",
      "    frases = [\"Este es un día maravilloso.\", \"Estoy muy decepcionado con este producto.\"]\n",
      "\n",
      "    for frase in frases:\n",
      "        analisis = TextBlob(frase)\n",
      "        polaridad = analisis.sentiment.polarity\n",
      "        subjetividad = analisis.sentiment.subjectivity\n",
      "        print(f\"Frase: {frase}\")\n",
      "        print(f\"Polaridad: {polaridad}, Subjetividad: {subjetividad}\\n\")\n",
      "    ```\n",
      "\n",
      "**Tema 4: Clasificación de Texto**\n",
      "\n",
      "*   **Problema:** Construir un clasificador Naive Bayes que determine si un mensaje es spam o no spam.\n",
      "*   **Solución:**\n",
      "\n",
      "    ```python\n",
      "    import nltk\n",
      "    import random\n",
      "    from nltk.corpus import movie_reviews\n",
      "\n",
      "    # construir lista de documentos\n",
      "    documents = [(list(movie_reviews.words(fileid)), category)\n",
      "                 for category in movie_reviews.categories()\n",
      "                 for fileid in movie_reviews.fileids(category)]\n",
      "\n",
      "    random.shuffle(documents)\n",
      "\n",
      "    # definir lista de todas las palabras\n",
      "    all_words = []\n",
      "    for w in movie_reviews.words():\n",
      "        all_words.append(w.lower())\n",
      "\n",
      "    # ordenar palabras por frecuencia\n",
      "    all_words = nltk.FreqDist(all_words)\n",
      "\n",
      "    # seleccionar las 3000 palabras mas frecuentes\n",
      "    word_features = list(all_words.keys())[:3000]\n",
      "\n",
      "    # determinar si las palabras mas frecuentes estan presentes en cada documento\n",
      "    def find_features(document):\n",
      "        words = set(document)\n",
      "        features = {}\n",
      "        for w in word_features:\n",
      "            features[w] = (w in words)\n",
      "\n",
      "        return features\n",
      "\n",
      "    # crea set de features\n",
      "    featuresets = [(find_features(rev), category) for (rev, category) in documents]\n",
      "\n",
      "    # dividir set de features en entrenamiento y test\n",
      "    training_set = featuresets[:1900]\n",
      "    testing_set = featuresets[1900:]\n",
      "\n",
      "    # crear clasificador\n",
      "    classifier = nltk.NaiveBayesClassifier.train(training_set)\n",
      "\n",
      "    print(\"Naive Bayes Algo accuracy percent:\", (nltk.classify.accuracy(classifier, testing_set))*100)\n",
      "\n",
      "    classifier.show_most_informative_features(15)\n",
      "    ```\n",
      "\n",
      "**3. Preguntas para Discusión**\n",
      "\n",
      "*   ¿Cuáles son los desafíos éticos asociados con el uso de modelos de lenguaje como GPT en aplicaciones como la generación de noticias o la creación de contenido?\n",
      "*   ¿Cómo podemos mitigar los sesgos presentes en los datos de entrenamiento para evitar la discriminación en los sistemas de PLN?\n",
      "*   ¿Cuál es el futuro del PLN en la interacción humano-computadora? ¿Cómo cambiará la forma en que interactuamos con las máquinas?\n",
      "*   ¿Cómo se puede mejorar la interpretabilidad de los modelos de PLN para comprender mejor sus decisiones y resultados?\n",
      "*   ¿Cuáles son las limitaciones actuales de las técnicas de análisis de sentimientos y cómo podemos superarlas?\n",
      "*   ¿Qué consideraciones de privacidad son importantes al trabajar con datos de texto para aplicaciones de PLN?\n",
      "*   ¿Cuáles son algunas formas creativas de aplicar el PLN en campos no tradicionales como la medicina, el arte o la música?\n",
      "\n",
      "**4. Objetivos de Aprendizaje Específicos para Cada Tema**\n",
      "\n",
      "*   **Tema 1: Introducción al PLN**\n",
      "    *   Definir el concepto de Procesamiento del Lenguaje Natural y su importancia en el campo de la Inteligencia Artificial.\n",
      "    *   Identificar las principales etapas de un proyecto de PLN (recopilación de datos, preprocesamiento, modelado, evaluación).\n",
      "    *   Implementar scripts básicos en Python para limpiar y normalizar texto.\n",
      "    *   Utilizar la librería `Pyspellchecker` para corregir errores ortográficos en textos.\n",
      "*   **Tema 2: Procesamiento de Texto**\n",
      "    *   Comprender y aplicar técnicas de tokenización, stemming y lematización.\n",
      "    *   Utilizar expresiones regulares para buscar y manipular patrones en texto.\n",
      "    *   Extraer características relevantes de texto para su uso en modelos de PLN.\n",
      "*   **Tema 4: Análisis de Sentimientos, Clasificación y Extracción de Información**\n",
      "    *   Comprender los conceptos fundamentales del análisis de sentimientos y sus aplicaciones.\n",
      "    *   Implementar métodos supervisados y no supervisados para el análisis de sentimientos.\n",
      "    *   Construir y evaluar modelos de clasificación de texto utilizando algoritmos de aprendizaje automático (Naive Bayes, SVM, redes neuronales).\n",
      "    *   Aplicar técnicas de extracción de información para identificar entidades y relaciones en texto.\n",
      "*   **Tema Adicional: Transformadores para Generación de Texto (GPT)**\n",
      "    *   Comprender la arquitectura y el funcionamiento de los modelos Transformer.\n",
      "    *   Utilizar modelos pre-entrenados como GPT para tareas de generación de texto (traducción, chatbots, resumen).\n",
      "    *   Adaptar y ajustar modelos Transformer para aplicaciones específicas de PLN.\n",
      "\n",
      "**5. Lecturas y Recursos Sugeridos**\n",
      "\n",
      "*   **Libros:**\n",
      "    *   \"Speech and Language Processing\" de Jurafsky y Martin (un clásico en el campo).\n",
      "    *   \"Natural Language Processing with Python\" de Steven Bird, Ewan Klein y Edward Loper (NLTK Book).\n",
      "    *   \"Deep Learning for Natural Language Processing\" de Jason Brownlee\n",
      "*   **Bibliotecas de Python:**\n",
      "    *   NLTK (Natural Language Toolkit): [http://www.nltk.org/](http://www.nltk.org/)\n",
      "    *   SpaCy: [https://spacy.io/](https://spacy.io/)\n",
      "    *   Transformers de Hugging Face: [https://huggingface.co/transformers/](https://huggingface.co/transformers/)\n",
      "    *   TextBlob: [https://textblob.readthedocs.io/en/dev/](https://textblob.readthedocs.io/en/dev/)\n",
      "*   **Cursos en línea:**\n",
      "    *   Coursera: Cursos de PLN ofrecidos por universidades como Stanford, Universidad de Washington, etc.\n",
      "    *   Udemy: Amplia variedad de cursos sobre PLN y aprendizaje profundo.\n",
      "    *   Fast.ai: Cursos prácticos sobre PLN utilizando aprendizaje profundo.\n",
      "*   **Artículos de investigación:**\n",
      "    *   ACL Anthology: Colección de artículos de investigación en PLN.\n",
      "    *   Google Scholar: Para buscar artículos específicos sobre temas de interés.\n",
      "\n",
      "Espero que este material sea útil para tu curso. ¡Avísame si necesitas algo más!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "# Inicializa el modelo Gemini\n",
    "model = genai.GenerativeModel('gemini-2.0-flash-001')\n",
    "\n",
    "# Genera una respuesta\n",
    "response = model.generate_content(final_prompt)\n",
    "\n",
    "# Imprime la respuesta\n",
    "print(response.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
