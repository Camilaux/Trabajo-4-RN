{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader, TextLoader, Docx2txtLoader\n",
    "from langchain_community.document_loaders import UnstructuredWordDocumentLoader\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "import re\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importamos el API Key de las variables de entorno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "os.environ['GOOGLE_API_KEY'] = os.getenv('GOOGLE_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install langchain_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install google-generativeai\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leer el documentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cargar_documentos(ruta_archivo):\n",
    "    \"\"\"Carga documentos en PDF, TXT o DOCX y los convierte en texto.\"\"\"\n",
    "    if ruta_archivo.endswith(\".pdf\"):\n",
    "        loader = PyPDFLoader(ruta_archivo)\n",
    "    elif ruta_archivo.endswith(\".txt\"):\n",
    "        loader = TextLoader(ruta_archivo)\n",
    "    elif ruta_archivo.endswith(\".docx\"):\n",
    "        loader = Docx2txtLoader(ruta_archivo)\n",
    "    else:\n",
    "        raise ValueError(\"Formato no soportado. Usa PDF, TXT o DOCX.\")\n",
    "    \n",
    "    documentos = loader.load()\n",
    "    \n",
    "    return documentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función de limpieza\n",
    "def clean_text(text):\n",
    "    # Eliminar fechas en formato dd/mm/yyyy\n",
    "    text = re.sub(r'\\d{2}/\\d{2}/\\d{4}', '', text)\n",
    "    \n",
    "    # Eliminar metadatos innecesarios\n",
    "    text = re.sub(r'USUARIO|PScript5\\.dll.*?\\n|Acrobat Distiller.*?\\n', '', text)\n",
    "    \n",
    "    # Reemplazar caracteres especiales y símbolos unicode, excluyendo caracteres españoles\n",
    "    text = re.sub(r'[\\uf06e\\uf0a7]|[^\\x00-\\x7F\\xC0-\\xFF]+', '-', text)\n",
    "    \n",
    "    # Eliminar múltiples espacios en blanco\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    \n",
    "    # Eliminar saltos de línea innecesarios, pero mantener párrafos\n",
    "    text = re.sub(r'\\n{3,}', '\\n\\n', text)\n",
    "    \n",
    "    # Eliminar espacios al inicio y final de cada línea\n",
    "    text = '\\n'.join(line.strip() for line in text.split('\\n'))\n",
    "    \n",
    "    # Eliminar espacios en blanco al inicio y final del texto\n",
    "    text = text.strip()\n",
    "    \n",
    "    # Eliminar caracteres especiales y símbolos repetidos\n",
    "    text = re.sub(r'[-]{2,}', '-', text)\n",
    "    text = re.sub(r'[.]{2,}', '.', text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "# page = cargar_documentos(\"data/1-01-Curso_PLN.pdf\")\n",
    "\n",
    "# # Limpiar cada página\n",
    "# cleaned_pages = [clean_text(pag.page_content) for pag in page]\n",
    "\n",
    "# # Unir todas las páginas en un solo texto limpio\n",
    "# final_text = \"\\n\\n\".join(cleaned_pages)\n",
    "\n",
    "# # Mostrar el resultado limpio\n",
    "# print(final_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "\n",
    "# Paso 1: Convertir el texto limpio en un objeto Document\n",
    "# Asegúrate de que final_text es un string que contiene el contenido limpio\n",
    "# document = Document(page_content=final_text)  # Debe ser un objeto Document\n",
    "\n",
    "# Paso 2: Función para dividir el texto en fragmentos\n",
    "def split_text(document):\n",
    "    \"\"\"Divide el texto en fragmentos más pequeños para procesamiento.\"\"\"\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=500,      # Número de caracteres por fragmento\n",
    "        chunk_overlap=50,    # Traslape entre fragmentos\n",
    "        length_function=len, # Función de longitud\n",
    "        separators=[\"\\n\\n\", \"\\n\", \" \"]  # Separadores\n",
    "    )\n",
    "\n",
    "    # Aplicar el splitter al documento (documento debe ser una lista)\n",
    "    textos_fragmentados = text_splitter.split_documents([document])  # Pasamos una lista de documentos\n",
    "\n",
    "    return textos_fragmentados\n",
    "\n",
    "# Paso 3: Ejecutar la función y obtener los fragmentos\n",
    "# chunks = split_text(document)\n",
    "\n",
    "# Mostrar un fragmento de ejemplo\n",
    "# for i, chunk in enumerate(chunks[:]):  # Mostramos solo los 3 primeros\n",
    "#     print(f\"\\nFragmento {i+1}:\\n{chunk.page_content}\\n{'-'*50}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crear embeddings\n",
    "\n",
    "Se hará uso de un modelo de Hugging Face all-MiniLM-L6-v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usar modelo de Hugging Face\n",
    "# embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Almacenar  embeddings en ChromaDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "def create_vectorstore(chunks, embedding_function, vectorstore_path):\n",
    "\n",
    "    # Lista de valores unicos para documentos\n",
    "    ids = [str(uuid.uuid5(uuid.NAMESPACE_DNS, doc.page_content)) for doc in chunks]\n",
    "    \n",
    "    unique_ids = set()\n",
    "    unique_chunks = []\n",
    "    \n",
    "    unique_chunks = [] \n",
    "    for chunk, id in zip(chunks, ids):     \n",
    "        if id not in unique_ids:       \n",
    "            unique_ids.add(id)\n",
    "            unique_chunks.append(chunk) \n",
    "\n",
    "    #Crea una database de chroma\n",
    "    vectorstore = Chroma.from_documents(documents=unique_chunks, \n",
    "                                        ids=list(unique_ids),\n",
    "                                        embedding=embedding_function, \n",
    "                                        persist_directory = vectorstore_path)\n",
    "\n",
    "    vectorstore.persist()\n",
    "    \n",
    "    return vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorstore = create_vectorstore(chunks=chunks, \n",
    "#                                  embedding_function=embeddings, \n",
    "#                                  vectorstore_path=\"./vectorstore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definimos el LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "def generate_response(final_prompt):\n",
    "    # Inicializa el modelo Gemini\n",
    "    model = genai.GenerativeModel('gemini-2.0-flash-001')\n",
    "\n",
    "    # Genera una respuesta\n",
    "    response = model.generate_content(final_prompt)\n",
    "\n",
    "    return response.text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Consulta de datos relevantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cargamos el vectorstore\n",
    "# database = Chroma(persist_directory=\"vectorstore\",embedding_function=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "def generate_materials_by_section(vectorstore):\n",
    "    \"\"\"\n",
    "    Genera materiales educativos dividiendo el proceso en diferentes prompts específicos.\n",
    "    \"\"\"\n",
    "    # Configurar el retriever\n",
    "    retriever = vectorstore.as_retriever(\n",
    "        search_type=\"similarity\",\n",
    "        search_kwargs={\"k\": 3}\n",
    "    )\n",
    "    \n",
    "    prompts = {\n",
    "        \"title\": \"¿Cúal es el mejor título para el material didáctico?\",\n",
    "        \"topics\": \"¿Cuáles son los temas principales que se cubren en el curso?\",\n",
    "        \"objectives\": \"¿Cuáles son los objetivos de aprendizaje de este curso?\",\n",
    "        \"resources\": \"¿Cuáles son las lecturas o recursos recomendados para este curso?\",\n",
    "        \"discussion_questions\": \"¿Cuáles son algunas preguntas para discusión en este curso?\",\n",
    "        \"practice_problems\": \"¿Qué ejercicios o problemas de práctica se incluyen en el programa del curso?\"\n",
    "    }\n",
    "    \n",
    "    retrieved_data = {key: retriever.invoke(query) for key, query in prompts.items()}\n",
    "    \n",
    "    prompt_templates = {\n",
    "        \"notas_clase\": \"\"\"\n",
    "        Eres un asistente para la generación de materiales educativos basados en un programa de curso.\n",
    "        Utiliza la siguiente información recuperada para crear notas de clase estructuradas:\n",
    "\n",
    "        ---\n",
    "        **Título del curso:** {title}\n",
    "        **Temas principales:** {topics}\n",
    "        \n",
    "        **Notas detalladas de clase:**\n",
    "        - Organiza los temas principales en secciones claras.\n",
    "        - Incluye explicaciones concisas, ejemplos prácticos y aplicaciones relevantes.\n",
    "        - Evita introducciones genéricas o frases como \"Dado que la información es limitada\".\n",
    "        \"\"\",\n",
    "        \n",
    "        \"problemas_practica\": \"\"\"\n",
    "        Eres un asistente para la generación de materiales educativos basados en un programa de curso.\n",
    "        Utiliza la siguiente información recuperada para generar problemas de práctica con soluciones:\n",
    "        \n",
    "        ---\n",
    "        **Título del curso:** {title}\n",
    "        **Ejercicios y problemas de práctica:** {practice_problems}\n",
    "        \n",
    "        **Problemas de práctica con soluciones:**\n",
    "        - Diseña problemas que refuercen los conceptos clave del curso.\n",
    "        - Incluye soluciones detalladas y explicaciones paso a paso.\n",
    "        \"\"\",\n",
    "        \n",
    "        \"preguntas_discusion\": \"\"\"\n",
    "        Eres un asistente para la generación de materiales educativos basados en un programa de curso.\n",
    "        Utiliza la siguiente información recuperada para generar preguntas de discusión:\n",
    "        \n",
    "        ---\n",
    "        **Título del curso:** {title}\n",
    "        **Preguntas para discusión:** {discussion_questions}\n",
    "        \n",
    "        **Preguntas para discusión:**\n",
    "        - Propón preguntas que fomenten el análisis crítico y la reflexión sobre los temas del curso.\n",
    "        - Asegúrate de que las preguntas estén relacionadas directamente con los objetivos de aprendizaje.\n",
    "        \"\"\",\n",
    "        \n",
    "        \"objetivos_aprendizaje\": \"\"\"\n",
    "        Eres un asistente para la generación de materiales educativos basados en un programa de curso.\n",
    "        Utiliza la siguiente información recuperada para definir objetivos de aprendizaje:\n",
    "        \n",
    "        ---\n",
    "        **Título del curso:** {title}\n",
    "        **Objetivos de aprendizaje:** {objectives}\n",
    "        \n",
    "        **Objetivos de aprendizaje específicos para cada tema:**\n",
    "        - Define objetivos claros y medibles para cada tema principal.\n",
    "        - Relaciona los objetivos con las habilidades y conocimientos que los estudiantes deben adquirir.\n",
    "        \"\"\",\n",
    "        \n",
    "        \"lecturas_sugeridas\": \"\"\"\n",
    "        Eres un asistente para la generación de materiales educativos basados en un programa de curso.\n",
    "        Utiliza la siguiente información recuperada para recomendar lecturas y recursos:\n",
    "        \n",
    "        ---\n",
    "        **Título del curso:** {title}\n",
    "        **Lecturas y recursos recomendados:** {resources}\n",
    "        \n",
    "        **Lecturas y recursos sugeridos:**\n",
    "        - Proporciona una lista de lecturas, artículos, libros y recursos en línea que complementen los temas del curso.\n",
    "        - Incluye enlaces o referencias directas cuando sea posible.\n",
    "        \"\"\"\n",
    "    }\n",
    "    \n",
    "    # Generar los prompts finales con la información obtenida\n",
    "    final_prompts = {\n",
    "        key: ChatPromptTemplate.from_template(template).format(**retrieved_data)\n",
    "        for key, template in prompt_templates.items()\n",
    "    }\n",
    "    \n",
    "    # Generar las respuestas utilizando el modelo Gemini\n",
    "    generated_materials = {\n",
    "        key: generate_response(prompt)\n",
    "        for key, prompt in final_prompts.items()\n",
    "    }\n",
    "    \n",
    "    return generated_materials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exportar a pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reportlab.lib.pagesizes import letter\n",
    "from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle\n",
    "from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer\n",
    "from reportlab.lib.units import inch\n",
    "import re\n",
    "\n",
    "# Estilo para los bloques de código con fondo azul y texto blanco\n",
    "code_block_style = ParagraphStyle(\n",
    "    name=\"CodeBlockStyle\",\n",
    "    fontName=\"Courier\",\n",
    "    fontSize=9,\n",
    "    leading=11,\n",
    "    spaceBefore=4,\n",
    "    spaceAfter=4,\n",
    "    backColor=\"#E0F7FA\",  # Fondo azul claro\n",
    "    textColor=\"#01579B\"    # Texto color azul oscuro\n",
    ")\n",
    "\n",
    "# Estilo para texto normal, con fondo blanco y texto negro\n",
    "normal_text_style = ParagraphStyle(\n",
    "    name=\"NormalTextStyle\",\n",
    "    fontName=\"Helvetica\",\n",
    "    fontSize=10,\n",
    "    leading=12,\n",
    "    spaceBefore=6,\n",
    "    spaceAfter=6,\n",
    "    textColor=\"#212121\"  # Texto en gris oscuro\n",
    ")\n",
    "\n",
    "# Estilo para los títulos de las secciones con color de fondo y texto personalizado\n",
    "section_title_style = ParagraphStyle(\n",
    "    name=\"SectionTitleStyle\",\n",
    "    fontName=\"Helvetica-Bold\",\n",
    "    fontSize=14,\n",
    "    leading=16,\n",
    "    spaceBefore=10,\n",
    "    spaceAfter=10,\n",
    "    textColor=\"#FFFFFF\",  # Texto blanco\n",
    "    backColor=\"#00796B\"   # Fondo verde oscuro\n",
    ")\n",
    "\n",
    "def convert_to_html_bold(text):\n",
    "    \"\"\"Convierte texto en negrita usando etiquetas HTML <b>.\"\"\"\n",
    "    return re.sub(r'\\*\\*(.*?)\\*\\*', r'<b>\\1</b>', text)\n",
    "\n",
    "def extract_code_and_text(input_text):\n",
    "    \"\"\"Separa el texto en bloques de código y texto normal detectando `````.\"\"\"\n",
    "    parts = re.split(r\"```\", input_text)\n",
    "    formatted_parts = []\n",
    "    \n",
    "    for idx, part in enumerate(parts):\n",
    "        if idx % 2 == 0:\n",
    "            formatted_parts.append((\"text\", convert_to_html_bold(part.strip())))\n",
    "        else:\n",
    "            # Código, reemplazando saltos de línea y espacios\n",
    "            formatted_code = part.strip().replace(\"\\n\", \"<br/>\")\n",
    "            formatted_code = formatted_code.replace(\" \", \"&nbsp;\")\n",
    "            formatted_parts.append((\"code\", formatted_code))\n",
    "    \n",
    "    return formatted_parts\n",
    "\n",
    "def generate_material_pdf(materials_dict, pdf_filename):\n",
    "    \"\"\"Genera un archivo PDF con los materiales procesados y formateados.\"\"\"\n",
    "    pdf_filename = pdf_filename + \".pdf\"\n",
    "    document = SimpleDocTemplate(pdf_filename, pagesize=letter)\n",
    "    styles = getSampleStyleSheet()\n",
    "    content_elements = []\n",
    "\n",
    "    # Agregar un título general al PDF\n",
    "    header = Paragraph(\"<b>Material Didáctico Generado</b>\", styles[\"Title\"])\n",
    "    content_elements.append(header)\n",
    "    content_elements.append(Spacer(1, 0.3 * inch))  # Espaciado para el título\n",
    "\n",
    "    # Procesar cada sección de los materiales\n",
    "    for section_name, section_text in materials_dict.items():\n",
    "        # Añadir el título de la sección con un fondo verde oscuro y texto blanco\n",
    "        section_header = Paragraph(f\"<b>{section_name.replace('_', ' ').title()}</b>\", section_title_style)\n",
    "        content_elements.append(section_header)\n",
    "        content_elements.append(Spacer(1, 0.2 * inch))  # Espaciado entre título de sección\n",
    "\n",
    "        # Procesar las secciones de texto y código\n",
    "        sections = extract_code_and_text(section_text)\n",
    "        for type_of_section, content in sections:\n",
    "            if type_of_section == \"text\":\n",
    "                paragraphs = content.split(\"\\n\\n\")  # Separar en párrafos\n",
    "                for para in paragraphs:\n",
    "                    content_elements.append(Paragraph(para, normal_text_style))  # Texto normal\n",
    "                    content_elements.append(Spacer(1, 0.1 * inch))  # Espaciado entre párrafos\n",
    "            elif type_of_section == \"code\":\n",
    "                content_elements.append(Paragraph(f'<font face=\"Courier\">{content}</font>', code_block_style))  # Bloques de código\n",
    "                content_elements.append(Spacer(1, 0.25 * inch))  # Espaciado después del bloque de código\n",
    "\n",
    "    # Crear el PDF\n",
    "    document.build(content_elements)\n",
    "    print(f\"✅ PDF generado exitosamente: {pdf_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tkinter import Tk, filedialog\n",
    "def main():\n",
    "    # Sección de input\n",
    "    try:\n",
    "        # Abrir diálogo para seleccionar archivo\n",
    "        root = Tk()\n",
    "        root.attributes('-topmost', True)\n",
    "        file_path = filedialog.askopenfilename(\n",
    "            parent=root,\n",
    "            title=\"Selecciona un archivo (PDF, TXT o DOCX)\",\n",
    "            filetypes=(('PDF files', '*.pdf'), ('Word documents', '*.docx'), ('Text files', '*.txt'))\n",
    "        )\n",
    "        root.destroy()\n",
    "        if not file_path:\n",
    "            raise FileNotFoundError(\"No se seleccionó ningún archivo.\")\n",
    "        \n",
    "        # Cargar documentos\n",
    "        documents = cargar_documentos(file_path)\n",
    "\n",
    "        # Limpiar cada página\n",
    "        cleaned_pages = [clean_text(pag.page_content) for pag in documents]\n",
    "\n",
    "        # Unir todas las páginas en un solo texto limpio\n",
    "        final_text = \"\\n\\n\".join(cleaned_pages)\n",
    "\n",
    "        # Paso 1: Convertir el texto limpio en un objeto Document\n",
    "        document = Document(page_content=final_text)  # Debe ser un objeto Document\n",
    "\n",
    "        # Paso 2: Función para dividir el texto en fragmentos\n",
    "        chunks = split_text(document)\n",
    "\n",
    "        # Paso 3: embeddings\n",
    "        embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "        # Paso 4: Crear vectorstore\n",
    "        vectorstore = create_vectorstore(chunks=chunks, \n",
    "                                         embedding_function=embeddings, \n",
    "                                         vectorstore_path=\"./vectorstore\")\n",
    "        \n",
    "        # Paso 5: Crear el prompt\n",
    "        response = generate_materials_by_section(vectorstore)\n",
    "\n",
    "        generate_material_pdf(response, input(\"Ingresa el nombre del archivo a generar: \"))\n",
    "\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"File error: {str(e)}\")\n",
    "    except ValueError as e:\n",
    "        print(f\"Input error: {str(e)}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error inesperado: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ PDF generado exitosamente: material_didactico.pdf\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
