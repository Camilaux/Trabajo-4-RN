{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader, TextLoader, Docx2txtLoader\n",
    "from langchain_community.document_loaders import UnstructuredWordDocumentLoader\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "import re\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importamos el API Key de las variables de entorno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "os.environ['GOOGLE_API_KEY'] = os.getenv('GOOGLE_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install langchain_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install google-generativeai\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leer el documentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cargar_documentos(ruta_archivo):\n",
    "    \"\"\"Carga documentos en PDF, TXT o DOCX y los convierte en texto.\"\"\"\n",
    "    if ruta_archivo.endswith(\".pdf\"):\n",
    "        loader = PyPDFLoader(ruta_archivo)\n",
    "    elif ruta_archivo.endswith(\".txt\"):\n",
    "        loader = TextLoader(ruta_archivo)\n",
    "    elif ruta_archivo.endswith(\".docx\"):\n",
    "        loader = Docx2txtLoader(ruta_archivo)\n",
    "    else:\n",
    "        raise ValueError(\"Formato no soportado. Usa PDF, TXT o DOCX.\")\n",
    "    \n",
    "    documentos = loader.load()\n",
    "    \n",
    "    return documentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función de limpieza\n",
    "def clean_text(text):\n",
    "    # Eliminar fechas en formato dd/mm/yyyy\n",
    "    text = re.sub(r'\\d{2}/\\d{2}/\\d{4}', '', text)\n",
    "    \n",
    "    # Eliminar metadatos innecesarios\n",
    "    text = re.sub(r'USUARIO|PScript5\\.dll.*?\\n|Acrobat Distiller.*?\\n', '', text)\n",
    "    \n",
    "    # Reemplazar caracteres especiales y símbolos unicode, excluyendo caracteres españoles\n",
    "    text = re.sub(r'[\\uf06e\\uf0a7]|[^\\x00-\\x7F\\xC0-\\xFF]+', '-', text)\n",
    "    \n",
    "    # Eliminar múltiples espacios en blanco\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    \n",
    "    # Eliminar saltos de línea innecesarios, pero mantener párrafos\n",
    "    text = re.sub(r'\\n{3,}', '\\n\\n', text)\n",
    "    \n",
    "    # Eliminar espacios al inicio y final de cada línea\n",
    "    text = '\\n'.join(line.strip() for line in text.split('\\n'))\n",
    "    \n",
    "    # Eliminar espacios en blanco al inicio y final del texto\n",
    "    text = text.strip()\n",
    "    \n",
    "    # Eliminar caracteres especiales y símbolos repetidos\n",
    "    text = re.sub(r'[-]{2,}', '-', text)\n",
    "    text = re.sub(r'[.]{2,}', '.', text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "# page = cargar_documentos(\"data/1-01-Curso_PLN.pdf\")\n",
    "\n",
    "# # Limpiar cada página\n",
    "# cleaned_pages = [clean_text(pag.page_content) for pag in page]\n",
    "\n",
    "# # Unir todas las páginas en un solo texto limpio\n",
    "# final_text = \"\\n\\n\".join(cleaned_pages)\n",
    "\n",
    "# # Mostrar el resultado limpio\n",
    "# print(final_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "\n",
    "# Paso 1: Convertir el texto limpio en un objeto Document\n",
    "# Asegúrate de que final_text es un string que contiene el contenido limpio\n",
    "# document = Document(page_content=final_text)  # Debe ser un objeto Document\n",
    "\n",
    "# Paso 2: Función para dividir el texto en fragmentos\n",
    "def split_text(document):\n",
    "    \"\"\"Divide el texto en fragmentos más pequeños para procesamiento.\"\"\"\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=500,      # Número de caracteres por fragmento\n",
    "        chunk_overlap=50,    # Traslape entre fragmentos\n",
    "        length_function=len, # Función de longitud\n",
    "        separators=[\"\\n\\n\", \"\\n\", \" \"]  # Separadores\n",
    "    )\n",
    "\n",
    "    # Aplicar el splitter al documento (documento debe ser una lista)\n",
    "    textos_fragmentados = text_splitter.split_documents([document])  # Pasamos una lista de documentos\n",
    "\n",
    "    return textos_fragmentados\n",
    "\n",
    "# Paso 3: Ejecutar la función y obtener los fragmentos\n",
    "# chunks = split_text(document)\n",
    "\n",
    "# Mostrar un fragmento de ejemplo\n",
    "# for i, chunk in enumerate(chunks[:]):  # Mostramos solo los 3 primeros\n",
    "#     print(f\"\\nFragmento {i+1}:\\n{chunk.page_content}\\n{'-'*50}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crear embeddings\n",
    "\n",
    "Se hará uso de un modelo de Hugging Face all-MiniLM-L6-v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usar modelo de Hugging Face\n",
    "# embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Almacenar  embeddings en ChromaDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "def create_vectorstore(chunks, embedding_function, vectorstore_path):\n",
    "\n",
    "    # Lista de valores unicos para documentos\n",
    "    ids = [str(uuid.uuid5(uuid.NAMESPACE_DNS, doc.page_content)) for doc in chunks]\n",
    "    \n",
    "    unique_ids = set()\n",
    "    unique_chunks = []\n",
    "    \n",
    "    unique_chunks = [] \n",
    "    for chunk, id in zip(chunks, ids):     \n",
    "        if id not in unique_ids:       \n",
    "            unique_ids.add(id)\n",
    "            unique_chunks.append(chunk) \n",
    "\n",
    "    #Crea una database de chroma\n",
    "    vectorstore = Chroma.from_documents(documents=unique_chunks, \n",
    "                                        ids=list(unique_ids),\n",
    "                                        embedding=embedding_function, \n",
    "                                        persist_directory = vectorstore_path)\n",
    "\n",
    "    vectorstore.persist()\n",
    "    \n",
    "    return vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorstore = create_vectorstore(chunks=chunks, \n",
    "#                                  embedding_function=embeddings, \n",
    "#                                  vectorstore_path=\"./vectorstore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Consulta de datos relevantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cargamos el vectorstore\n",
    "# database = Chroma(persist_directory=\"vectorstore\",embedding_function=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "def prompt_template(vectorstore, title_input):\n",
    "    #Hacemos el prompt configurado con el retrieve\n",
    "    PROMPT_TEMPLATE = \"\"\"\n",
    "    Eres un asistente para la generación de materiales educativos basados en un programa de curso.\n",
    "    Utiliza la siguiente información recuperada para crear materiales de aprendizaje estructurados.\n",
    "\n",
    "    ---\n",
    "\n",
    "    **Título del curso:** ¿Cuál es el título del curso? {title}\n",
    "\n",
    "    **Temas principales:** ¿Cuáles son los temas principales que se cubren en el curso? {topics}\n",
    "\n",
    "    **Objetivos de aprendizaje:** ¿Cuáles son los objetivos de aprendizaje de este curso? {objectives}\n",
    "\n",
    "    **Lecturas y recursos recomendados:** ¿Cuáles son las lecturas o recursos recomendados para este curso? {resources}\n",
    "\n",
    "    **Preguntas para discusión:** ¿Cuáles son algunas preguntas para discusión en este curso? {discussion_questions}\n",
    "\n",
    "    **Ejercicios y problemas de práctica:** ¿Qué ejercicios o problemas de práctica se incluyen en el programa del curso? {practice_problems}\n",
    "\n",
    "    ---\n",
    "\n",
    "    Basándote en la información anterior, genera los siguientes materiales educativos:\n",
    "    1. Notas detalladas de clase.\n",
    "    2. Problemas de práctica con soluciones.\n",
    "    3. Preguntas para discusión.\n",
    "    4. Objetivos de aprendizaje específicos para cada tema.\n",
    "    5. Lecturas y recursos sugeridos.\n",
    "\n",
    "    Estructura la respuesta de manera clara y detallada. Si no encuentras algo en el documento puedes utilizar información de internet\n",
    "    \"\"\"\n",
    "    \n",
    "    # Configure the retriever\n",
    "    retriever = vectorstore.as_retriever(\n",
    "        search_type=\"similarity\",\n",
    "        search_kwargs={\n",
    "            \"k\": 3\n",
    "        }\n",
    "    )\n",
    "\n",
    "    topics = retriever.invoke(\"¿Cuáles son los temas principales que se cubren en el curso?\")\n",
    "    objectives = retriever.invoke(\"¿Cuáles son los objetivos de aprendizaje de este curso?\")\n",
    "    resources = retriever.invoke(\"¿Cuáles son las lecturas o recursos recomendados para este curso?\")\n",
    "    discussion_questions = retriever.invoke(\"¿Cuáles son algunas preguntas para discusión en este curso?\")\n",
    "    practice_problems = retriever.invoke(\"¿Qué ejercicios o problemas de práctica se incluyen en el programa del curso?\")\n",
    "\n",
    "    prompt_template = ChatPromptTemplate.from_template(PROMPT_TEMPLATE)\n",
    "    #Insertamos los valores en el prompt\n",
    "    final_prompt = PROMPT_TEMPLATE.format(\n",
    "        title=title_input,\n",
    "        topics=topics,\n",
    "        objectives=objectives,\n",
    "        resources=resources,\n",
    "        discussion_questions=discussion_questions,\n",
    "        practice_problems=practice_problems\n",
    "    )\n",
    "\n",
    "    return final_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definimos el LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementamos el modelo de Gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Usuario\\Documents\\Universidad\\Redes Neuronales\\Trabajo-4-RN\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "def generate_response(final_prompt):\n",
    "    # Inicializa el modelo Gemini\n",
    "    model = genai.GenerativeModel('gemini-2.0-flash-001')\n",
    "\n",
    "    # Genera una respuesta\n",
    "    response = model.generate_content(final_prompt)\n",
    "\n",
    "    return response.text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Sección de input\n",
    "    try:\n",
    "        file_path = input(\"Introduce la ruta del archivo a procesar (PDF, TXT or DOCX): \").strip()\n",
    "        if not os.path.exists(file_path):\n",
    "            raise FileNotFoundError(\"El archivo no existe.\")\n",
    "    \n",
    "        # Nombre asignatura\n",
    "        title = input(\"Introduce el nombre de la asignatura: \").strip()\n",
    "        if not title:\n",
    "            raise ValueError(\"El nombre de la asignatura no puede estar vacío.\")\n",
    "        \n",
    "        # Cargar documentos\n",
    "        documents = cargar_documentos(file_path)\n",
    "\n",
    "        # Limpiar cada página\n",
    "        cleaned_pages = [clean_text(pag.page_content) for pag in documents]\n",
    "\n",
    "        # Unir todas las páginas en un solo texto limpio\n",
    "        final_text = \"\\n\\n\".join(cleaned_pages)\n",
    "\n",
    "        # Paso 1: Convertir el texto limpio en un objeto Document\n",
    "        document = Document(page_content=final_text)  # Debe ser un objeto Document\n",
    "\n",
    "        # Paso 2: Función para dividir el texto en fragmentos\n",
    "        chunks = split_text(document)\n",
    "\n",
    "        # Paso 3: embeddings\n",
    "        embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "        # Paso 4: Crear vectorstore\n",
    "        vectorstore = create_vectorstore(chunks=chunks, \n",
    "                                        embedding_function=embeddings, \n",
    "                                        vectorstore_path=\"./vectorstore\")\n",
    "        \n",
    "        # Paso 5: Crear el prompt\n",
    "        final_prompt = prompt_template(vectorstore, title)\n",
    "\n",
    "        # Paso 6: Generar respuesta\n",
    "        response = generate_response(final_prompt)\n",
    "\n",
    "        print(response)\n",
    "\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"File error: {str(e)}\")\n",
    "    except ValueError as e:\n",
    "        print(f\"Input error: {str(e)}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error inesperado: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usuario\\AppData\\Local\\Temp\\ipykernel_21436\\2038879979.py:29: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
      "Delete of nonexisting embedding ID: 22d2e6b4-a6a3-5aff-869b-c18c2e049867\n",
      "Delete of nonexisting embedding ID: ec1a055e-5a81-544a-af2d-a95b3eec58a4\n",
      "Delete of nonexisting embedding ID: 8816a309-1018-5e36-b431-6afa83a35031\n",
      "Delete of nonexisting embedding ID: 48610763-8dff-5068-93a2-d39aacf89cf1\n",
      "Delete of nonexisting embedding ID: e0d60b93-f560-5f98-a66b-8a1b2ea2efec\n",
      "Delete of nonexisting embedding ID: 57ff4786-4701-59f8-ac4a-b20c107df80b\n",
      "Delete of nonexisting embedding ID: 211f0219-9f23-5a15-99f2-ae2cf8722ef2\n",
      "Delete of nonexisting embedding ID: 9ce1a247-082e-5401-a340-bed6fcddc6db\n",
      "Delete of nonexisting embedding ID: ff45e6df-edf1-5a80-a0af-236c09dabde8\n",
      "Delete of nonexisting embedding ID: 93ecb396-0b60-5ff4-987c-e228c50d9986\n",
      "Delete of nonexisting embedding ID: 3770c9b1-1610-577a-beb4-0858802e12df\n",
      "Delete of nonexisting embedding ID: 22d2e6b4-a6a3-5aff-869b-c18c2e049867\n",
      "Delete of nonexisting embedding ID: ec1a055e-5a81-544a-af2d-a95b3eec58a4\n",
      "Delete of nonexisting embedding ID: 8816a309-1018-5e36-b431-6afa83a35031\n",
      "Delete of nonexisting embedding ID: 48610763-8dff-5068-93a2-d39aacf89cf1\n",
      "Delete of nonexisting embedding ID: e0d60b93-f560-5f98-a66b-8a1b2ea2efec\n",
      "Delete of nonexisting embedding ID: 57ff4786-4701-59f8-ac4a-b20c107df80b\n",
      "Delete of nonexisting embedding ID: 211f0219-9f23-5a15-99f2-ae2cf8722ef2\n",
      "Delete of nonexisting embedding ID: 9ce1a247-082e-5401-a340-bed6fcddc6db\n",
      "Delete of nonexisting embedding ID: ff45e6df-edf1-5a80-a0af-236c09dabde8\n",
      "Delete of nonexisting embedding ID: 93ecb396-0b60-5ff4-987c-e228c50d9986\n",
      "Delete of nonexisting embedding ID: 3770c9b1-1610-577a-beb4-0858802e12df\n",
      "Delete of nonexisting embedding ID: 22d2e6b4-a6a3-5aff-869b-c18c2e049867\n",
      "Delete of nonexisting embedding ID: ec1a055e-5a81-544a-af2d-a95b3eec58a4\n",
      "Delete of nonexisting embedding ID: 8816a309-1018-5e36-b431-6afa83a35031\n",
      "Delete of nonexisting embedding ID: 48610763-8dff-5068-93a2-d39aacf89cf1\n",
      "Delete of nonexisting embedding ID: e0d60b93-f560-5f98-a66b-8a1b2ea2efec\n",
      "Delete of nonexisting embedding ID: 57ff4786-4701-59f8-ac4a-b20c107df80b\n",
      "Delete of nonexisting embedding ID: 211f0219-9f23-5a15-99f2-ae2cf8722ef2\n",
      "Delete of nonexisting embedding ID: 9ce1a247-082e-5401-a340-bed6fcddc6db\n",
      "Delete of nonexisting embedding ID: ff45e6df-edf1-5a80-a0af-236c09dabde8\n",
      "Delete of nonexisting embedding ID: 93ecb396-0b60-5ff4-987c-e228c50d9986\n",
      "Delete of nonexisting embedding ID: 3770c9b1-1610-577a-beb4-0858802e12df\n",
      "Delete of nonexisting embedding ID: 22d2e6b4-a6a3-5aff-869b-c18c2e049867\n",
      "Delete of nonexisting embedding ID: ec1a055e-5a81-544a-af2d-a95b3eec58a4\n",
      "Delete of nonexisting embedding ID: 8816a309-1018-5e36-b431-6afa83a35031\n",
      "Delete of nonexisting embedding ID: 48610763-8dff-5068-93a2-d39aacf89cf1\n",
      "Delete of nonexisting embedding ID: e0d60b93-f560-5f98-a66b-8a1b2ea2efec\n",
      "Delete of nonexisting embedding ID: 57ff4786-4701-59f8-ac4a-b20c107df80b\n",
      "Delete of nonexisting embedding ID: 211f0219-9f23-5a15-99f2-ae2cf8722ef2\n",
      "Delete of nonexisting embedding ID: 9ce1a247-082e-5401-a340-bed6fcddc6db\n",
      "Delete of nonexisting embedding ID: ff45e6df-edf1-5a80-a0af-236c09dabde8\n",
      "Delete of nonexisting embedding ID: 93ecb396-0b60-5ff4-987c-e228c50d9986\n",
      "Delete of nonexisting embedding ID: 3770c9b1-1610-577a-beb4-0858802e12df\n",
      "Delete of nonexisting embedding ID: 22d2e6b4-a6a3-5aff-869b-c18c2e049867\n",
      "Delete of nonexisting embedding ID: ec1a055e-5a81-544a-af2d-a95b3eec58a4\n",
      "Delete of nonexisting embedding ID: 8816a309-1018-5e36-b431-6afa83a35031\n",
      "Delete of nonexisting embedding ID: 48610763-8dff-5068-93a2-d39aacf89cf1\n",
      "Delete of nonexisting embedding ID: e0d60b93-f560-5f98-a66b-8a1b2ea2efec\n",
      "Delete of nonexisting embedding ID: 57ff4786-4701-59f8-ac4a-b20c107df80b\n",
      "Delete of nonexisting embedding ID: 211f0219-9f23-5a15-99f2-ae2cf8722ef2\n",
      "Delete of nonexisting embedding ID: 9ce1a247-082e-5401-a340-bed6fcddc6db\n",
      "Delete of nonexisting embedding ID: ff45e6df-edf1-5a80-a0af-236c09dabde8\n",
      "Delete of nonexisting embedding ID: 93ecb396-0b60-5ff4-987c-e228c50d9986\n",
      "Delete of nonexisting embedding ID: 3770c9b1-1610-577a-beb4-0858802e12df\n",
      "Delete of nonexisting embedding ID: 22d2e6b4-a6a3-5aff-869b-c18c2e049867\n",
      "Delete of nonexisting embedding ID: ec1a055e-5a81-544a-af2d-a95b3eec58a4\n",
      "Delete of nonexisting embedding ID: 8816a309-1018-5e36-b431-6afa83a35031\n",
      "Delete of nonexisting embedding ID: 48610763-8dff-5068-93a2-d39aacf89cf1\n",
      "Delete of nonexisting embedding ID: e0d60b93-f560-5f98-a66b-8a1b2ea2efec\n",
      "Delete of nonexisting embedding ID: 57ff4786-4701-59f8-ac4a-b20c107df80b\n",
      "Delete of nonexisting embedding ID: 211f0219-9f23-5a15-99f2-ae2cf8722ef2\n",
      "Delete of nonexisting embedding ID: 9ce1a247-082e-5401-a340-bed6fcddc6db\n",
      "Delete of nonexisting embedding ID: ff45e6df-edf1-5a80-a0af-236c09dabde8\n",
      "Delete of nonexisting embedding ID: 93ecb396-0b60-5ff4-987c-e228c50d9986\n",
      "Delete of nonexisting embedding ID: 3770c9b1-1610-577a-beb4-0858802e12df\n",
      "Delete of nonexisting embedding ID: 22d2e6b4-a6a3-5aff-869b-c18c2e049867\n",
      "Delete of nonexisting embedding ID: ec1a055e-5a81-544a-af2d-a95b3eec58a4\n",
      "Delete of nonexisting embedding ID: 8816a309-1018-5e36-b431-6afa83a35031\n",
      "Delete of nonexisting embedding ID: 48610763-8dff-5068-93a2-d39aacf89cf1\n",
      "Delete of nonexisting embedding ID: e0d60b93-f560-5f98-a66b-8a1b2ea2efec\n",
      "Delete of nonexisting embedding ID: 57ff4786-4701-59f8-ac4a-b20c107df80b\n",
      "Delete of nonexisting embedding ID: 211f0219-9f23-5a15-99f2-ae2cf8722ef2\n",
      "Delete of nonexisting embedding ID: 9ce1a247-082e-5401-a340-bed6fcddc6db\n",
      "Delete of nonexisting embedding ID: ff45e6df-edf1-5a80-a0af-236c09dabde8\n",
      "Delete of nonexisting embedding ID: 93ecb396-0b60-5ff4-987c-e228c50d9986\n",
      "Delete of nonexisting embedding ID: 3770c9b1-1610-577a-beb4-0858802e12df\n",
      "Delete of nonexisting embedding ID: 22d2e6b4-a6a3-5aff-869b-c18c2e049867\n",
      "Delete of nonexisting embedding ID: ec1a055e-5a81-544a-af2d-a95b3eec58a4\n",
      "Delete of nonexisting embedding ID: 8816a309-1018-5e36-b431-6afa83a35031\n",
      "Delete of nonexisting embedding ID: 48610763-8dff-5068-93a2-d39aacf89cf1\n",
      "Delete of nonexisting embedding ID: e0d60b93-f560-5f98-a66b-8a1b2ea2efec\n",
      "Delete of nonexisting embedding ID: 57ff4786-4701-59f8-ac4a-b20c107df80b\n",
      "Delete of nonexisting embedding ID: 211f0219-9f23-5a15-99f2-ae2cf8722ef2\n",
      "Delete of nonexisting embedding ID: 9ce1a247-082e-5401-a340-bed6fcddc6db\n",
      "Delete of nonexisting embedding ID: ff45e6df-edf1-5a80-a0af-236c09dabde8\n",
      "Delete of nonexisting embedding ID: 93ecb396-0b60-5ff4-987c-e228c50d9986\n",
      "Delete of nonexisting embedding ID: 3770c9b1-1610-577a-beb4-0858802e12df\n",
      "Delete of nonexisting embedding ID: 22d2e6b4-a6a3-5aff-869b-c18c2e049867\n",
      "Delete of nonexisting embedding ID: ec1a055e-5a81-544a-af2d-a95b3eec58a4\n",
      "Delete of nonexisting embedding ID: 8816a309-1018-5e36-b431-6afa83a35031\n",
      "Delete of nonexisting embedding ID: 48610763-8dff-5068-93a2-d39aacf89cf1\n",
      "Delete of nonexisting embedding ID: e0d60b93-f560-5f98-a66b-8a1b2ea2efec\n",
      "Delete of nonexisting embedding ID: 57ff4786-4701-59f8-ac4a-b20c107df80b\n",
      "Delete of nonexisting embedding ID: 211f0219-9f23-5a15-99f2-ae2cf8722ef2\n",
      "Delete of nonexisting embedding ID: 9ce1a247-082e-5401-a340-bed6fcddc6db\n",
      "Delete of nonexisting embedding ID: ff45e6df-edf1-5a80-a0af-236c09dabde8\n",
      "Delete of nonexisting embedding ID: 93ecb396-0b60-5ff4-987c-e228c50d9986\n",
      "Delete of nonexisting embedding ID: 3770c9b1-1610-577a-beb4-0858802e12df\n",
      "Delete of nonexisting embedding ID: 22d2e6b4-a6a3-5aff-869b-c18c2e049867\n",
      "Delete of nonexisting embedding ID: ec1a055e-5a81-544a-af2d-a95b3eec58a4\n",
      "Delete of nonexisting embedding ID: 8816a309-1018-5e36-b431-6afa83a35031\n",
      "Delete of nonexisting embedding ID: 48610763-8dff-5068-93a2-d39aacf89cf1\n",
      "Delete of nonexisting embedding ID: e0d60b93-f560-5f98-a66b-8a1b2ea2efec\n",
      "Delete of nonexisting embedding ID: 57ff4786-4701-59f8-ac4a-b20c107df80b\n",
      "Delete of nonexisting embedding ID: 211f0219-9f23-5a15-99f2-ae2cf8722ef2\n",
      "Delete of nonexisting embedding ID: 9ce1a247-082e-5401-a340-bed6fcddc6db\n",
      "Delete of nonexisting embedding ID: ff45e6df-edf1-5a80-a0af-236c09dabde8\n",
      "Delete of nonexisting embedding ID: 93ecb396-0b60-5ff4-987c-e228c50d9986\n",
      "Delete of nonexisting embedding ID: 3770c9b1-1610-577a-beb4-0858802e12df\n",
      "C:\\Users\\Usuario\\AppData\\Local\\Temp\\ipykernel_21436\\3124993982.py:23: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
      "  vectorstore.persist()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¡Absolutamente! Aquí tienes un esquema de materiales educativos basados en la información proporcionada, complementada con información estándar en el campo del Análisis y Diseño de Algoritmos:\n",
      "\n",
      "**Título del Curso:** Análisis y Diseño de Algoritmos\n",
      "\n",
      "**I. Notas Detalladas de Clase (Esquema General)**\n",
      "\n",
      "*   **Introducción al Curso**\n",
      "    *   Motivación: Por qué es importante el análisis y diseño de algoritmos.\n",
      "    *   Objetivos del curso: Aprender a analizar y diseñar algoritmos eficientes.\n",
      "    *   Metodología: Clases magistrales, talleres, exposiciones, prácticas.\n",
      "    *   Consideraciones importantes: Confianza profesor-estudiante, prohibición de copiar código, uso de ayudas disponibles.\n",
      "*   **Análisis de Algoritmos**\n",
      "    *   **Fundamentos:**\n",
      "        *   ¿Qué es un algoritmo? Definición formal.\n",
      "        *   Criterios de corrección y eficiencia.\n",
      "        *   Modelos de computación (ej., RAM).\n",
      "    *   **Notación Asintótica:**\n",
      "        *   Notación Big-O, Omega, Theta. Definiciones formales y ejemplos.\n",
      "        *   Análisis de casos peor, promedio y mejor.\n",
      "        *   Reglas para el cálculo de la complejidad temporal y espacial.\n",
      "    *   **Técnicas de Análisis:**\n",
      "        *   Análisis iterativo (bucles).\n",
      "        *   Análisis recursivo (árboles de recursión, teorema maestro).\n",
      "*   **Técnicas de Diseño de Algoritmos**\n",
      "    *   **Divide y Vencerás:**\n",
      "        *   Estrategia general.\n",
      "        *   Ejemplos clásicos: Ordenamiento por mezcla (merge sort), búsqueda binaria.\n",
      "    *   **Programación Dinámica:**\n",
      "        *   Solapamiento de subproblemas y optimización.\n",
      "        *   Ejemplos clásicos: Secuencia de Fibonacci, problema de la mochila.\n",
      "    *   **Algoritmos Voraces (Greedy):**\n",
      "        *   Estrategia general.\n",
      "        *   Ejemplos clásicos: Problema de la selección de actividades, árbol de expansión mínimo (Kruskal, Prim).\n",
      "    *   **Backtracking:**\n",
      "        *   Estrategia general.\n",
      "        *   Ejemplos clásicos: Problema de las N reinas, laberintos.\n",
      "*   **Estructuras de Datos Avanzadas**\n",
      "    *   **Árboles:**\n",
      "        *   Árboles binarios de búsqueda (BST).\n",
      "        *   Árboles balanceados (AVL, Rojo-Negro).\n",
      "        *   Montículos (heaps).\n",
      "    *   **Grafos:**\n",
      "        *   Representación (matrices de adyacencia, listas de adyacencia).\n",
      "        *   Búsqueda en anchura (BFS).\n",
      "        *   Búsqueda en profundidad (DFS).\n",
      "*   **Temas Adicionales (Opcional)**\n",
      "    *   Algoritmos de ordenamiento avanzados (ej., Quicksort, Radix sort).\n",
      "    *   Algoritmos de búsqueda de patrones (ej., Knuth-Morris-Pratt).\n",
      "    *   Introducción a la complejidad computacional (clases P, NP).\n",
      "    *   Algoritmos aproximados.\n",
      "\n",
      "**II. Problemas de Práctica con Soluciones (Ejemplos)**\n",
      "\n",
      "*   **Análisis Asintótico:**\n",
      "    *   Problema: Determina la complejidad temporal de los siguientes fragmentos de código:\n",
      "        *   Bucle simple: `for i in range(n): print(i)`\n",
      "        *   Bucle anidado: `for i in range(n): for j in range(n): print(i, j)`\n",
      "        *   Recursión simple: `def factorial(n): if n == 0: return 1; else: return n * factorial(n-1)`\n",
      "    *   Soluciones: Explicación detallada de cómo llegar a las complejidades O(n), O(n^2), O(n).\n",
      "*   **Divide y Vencerás:**\n",
      "    *   Problema: Implementa el algoritmo de ordenamiento por mezcla (merge sort).\n",
      "    *   Solución: Código en Python con comentarios explicativos.\n",
      "*   **Programación Dinámica:**\n",
      "    *   Problema: Resuelve el problema de la mochila (0/1 knapsack) utilizando programación dinámica.\n",
      "    *   Solución: Código en Python con comentarios explicativos.\n",
      "*   **Algoritmos Voraces:**\n",
      "    *   Problema: Implementa el algoritmo de Kruskal para encontrar el árbol de expansión mínimo de un grafo.\n",
      "    *   Solución: Código en Python con comentarios explicativos.\n",
      "\n",
      "**III. Preguntas para Discusión**\n",
      "\n",
      "*   ¿Por qué es importante elegir el algoritmo correcto para un problema?\n",
      "*   ¿Cuándo es apropiado usar una técnica de diseño de algoritmos en lugar de otra?\n",
      "*   ¿Cuáles son las ventajas y desventajas de las diferentes estructuras de datos?\n",
      "*   ¿Cómo se puede mejorar la eficiencia de un algoritmo existente?\n",
      "*   ¿Qué significa que un problema sea NP-completo?\n",
      "\n",
      "**IV. Objetivos de Aprendizaje Específicos para Cada Tema**\n",
      "\n",
      "*   **Análisis de Algoritmos:**\n",
      "    *   Comprender la importancia de la eficiencia en el diseño de algoritmos.\n",
      "    *   Dominar la notación asintótica para expresar la complejidad temporal y espacial.\n",
      "    *   Ser capaz de analizar la complejidad de algoritmos iterativos y recursivos.\n",
      "*   **Técnicas de Diseño de Algoritmos:**\n",
      "    *   Aplicar la técnica de divide y vencerás para resolver problemas complejos.\n",
      "    *   Utilizar la programación dinámica para optimizar soluciones a problemas con solapamiento de subproblemas.\n",
      "    *   Aplicar algoritmos voraces para encontrar soluciones óptimas o aproximadas.\n",
      "    *   Utilizar la técnica de backtracking para resolver problemas de búsqueda.\n",
      "*   **Estructuras de Datos Avanzadas:**\n",
      "    *   Comprender las propiedades y aplicaciones de los árboles y grafos.\n",
      "    *   Implementar y utilizar diferentes tipos de árboles (BST, AVL, Rojo-Negro, heaps).\n",
      "    *   Implementar y utilizar algoritmos de búsqueda en grafos (BFS, DFS).\n",
      "\n",
      "**V. Lecturas y Recursos Sugeridos**\n",
      "\n",
      "*   **Libros de texto:**\n",
      "    *   \"Introduction to Algorithms\" (Cormen, Leiserson, Rivest, Stein)\n",
      "    *   \"Algorithms\" (Sedgewick, Wayne)\n",
      "*   **Recursos en línea:**\n",
      "    *   MIT OpenCourseware: \"Introduction to Algorithms\"\n",
      "    *   Coursera/edX: Cursos sobre algoritmos y estructuras de datos\n",
      "    *   GeeksforGeeks, HackerRank, LeetCode: Plataformas para practicar problemas de algoritmos\n",
      "*   **Artículos de investigación:**\n",
      "    *   Dependiendo de los temas avanzados que se cubran.\n",
      "\n",
      "Espero que esto te sea de gran ayuda para estructurar tus materiales educativos.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
