{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader, TextLoader, Docx2txtLoader\n",
    "from langchain_community.document_loaders import UnstructuredWordDocumentLoader\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\hp\\documents\\trabajo-4-rn\\venv\\lib\\site-packages (0.3.19)\n",
      "Requirement already satisfied: langchain-community in c:\\users\\hp\\documents\\trabajo-4-rn\\venv\\lib\\site-packages (0.3.18)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.35 in c:\\users\\hp\\documents\\trabajo-4-rn\\venv\\lib\\site-packages (from langchain) (0.3.40)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.6 in c:\\users\\hp\\documents\\trabajo-4-rn\\venv\\lib\\site-packages (from langchain) (0.3.6)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in c:\\users\\hp\\documents\\trabajo-4-rn\\venv\\lib\\site-packages (from langchain) (0.3.11)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\hp\\documents\\trabajo-4-rn\\venv\\lib\\site-packages (from langchain) (2.10.6)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\hp\\documents\\trabajo-4-rn\\venv\\lib\\site-packages (from langchain) (2.0.38)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\hp\\documents\\trabajo-4-rn\\venv\\lib\\site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\hp\\documents\\trabajo-4-rn\\venv\\lib\\site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\hp\\documents\\trabajo-4-rn\\venv\\lib\\site-packages (from langchain) (3.11.13)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\users\\hp\\documents\\trabajo-4-rn\\venv\\lib\\site-packages (from langchain) (9.0.0)\n",
      "Requirement already satisfied: numpy<3,>=1.26.2 in c:\\users\\hp\\documents\\trabajo-4-rn\\venv\\lib\\site-packages (from langchain) (2.2.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\hp\\documents\\trabajo-4-rn\\venv\\lib\\site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in c:\\users\\hp\\documents\\trabajo-4-rn\\venv\\lib\\site-packages (from langchain-community) (2.8.1)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in c:\\users\\hp\\documents\\trabajo-4-rn\\venv\\lib\\site-packages (from langchain-community) (0.4.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\hp\\documents\\trabajo-4-rn\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.8)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\hp\\documents\\trabajo-4-rn\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\hp\\documents\\trabajo-4-rn\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\hp\\documents\\trabajo-4-rn\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\hp\\documents\\trabajo-4-rn\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\hp\\documents\\trabajo-4-rn\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\hp\\documents\\trabajo-4-rn\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\hp\\documents\\trabajo-4-rn\\venv\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\hp\\documents\\trabajo-4-rn\\venv\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\hp\\documents\\trabajo-4-rn\\venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.35->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\hp\\documents\\trabajo-4-rn\\venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.35->langchain) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\hp\\documents\\trabajo-4-rn\\venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.35->langchain) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\hp\\documents\\trabajo-4-rn\\venv\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\hp\\documents\\trabajo-4-rn\\venv\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.15)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\hp\\documents\\trabajo-4-rn\\venv\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\hp\\documents\\trabajo-4-rn\\venv\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\hp\\documents\\trabajo-4-rn\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\hp\\documents\\trabajo-4-rn\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\hp\\documents\\trabajo-4-rn\\venv\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.0.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hp\\documents\\trabajo-4-rn\\venv\\lib\\site-packages (from requests<3,>=2->langchain) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hp\\documents\\trabajo-4-rn\\venv\\lib\\site-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hp\\documents\\trabajo-4-rn\\venv\\lib\\site-packages (from requests<3,>=2->langchain) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\documents\\trabajo-4-rn\\venv\\lib\\site-packages (from requests<3,>=2->langchain) (2025.1.31)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\hp\\documents\\trabajo-4-rn\\venv\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\hp\\documents\\trabajo-4-rn\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (4.8.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\hp\\documents\\trabajo-4-rn\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\hp\\documents\\trabajo-4-rn\\venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\hp\\documents\\trabajo-4-rn\\venv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.35->langchain) (3.0.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\hp\\documents\\trabajo-4-rn\\venv\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\hp\\documents\\trabajo-4-rn\\venv\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install langchain_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pypdf\n",
      "  Downloading pypdf-5.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Downloading pypdf-5.3.1-py3-none-any.whl (302 kB)\n",
      "   ---------------------------------------- 0.0/302.0 kB ? eta -:--:--\n",
      "   - -------------------------------------- 10.2/302.0 kB ? eta -:--:--\n",
      "   ------------------------------------ --- 276.5/302.0 kB 3.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 302.0/302.0 kB 3.1 MB/s eta 0:00:00\n",
      "Installing collected packages: pypdf\n",
      "Successfully installed pypdf-5.3.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence-transformers\n",
      "  Downloading sentence_transformers-3.4.1-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting transformers<5.0.0,>=4.41.0 (from sentence-transformers)\n",
      "  Downloading transformers-4.49.0-py3-none-any.whl.metadata (44 kB)\n",
      "     ---------------------------------------- 0.0/44.0 kB ? eta -:--:--\n",
      "     ----------------- -------------------- 20.5/44.0 kB 682.7 kB/s eta 0:00:01\n",
      "     -------------------------------------- 44.0/44.0 kB 718.8 kB/s eta 0:00:00\n",
      "Collecting tqdm (from sentence-transformers)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "     ---------------------------------------- 0.0/57.7 kB ? eta -:--:--\n",
      "     ---------------------------------------- 57.7/57.7 kB 3.2 MB/s eta 0:00:00\n",
      "Collecting torch>=1.11.0 (from sentence-transformers)\n",
      "  Downloading torch-2.6.0-cp312-cp312-win_amd64.whl.metadata (28 kB)\n",
      "Collecting scikit-learn (from sentence-transformers)\n",
      "  Using cached scikit_learn-1.6.1-cp312-cp312-win_amd64.whl.metadata (15 kB)\n",
      "Collecting scipy (from sentence-transformers)\n",
      "  Downloading scipy-1.15.2-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "     ---------------------------------------- 0.0/60.8 kB ? eta -:--:--\n",
      "     ---------------------------------------- 60.8/60.8 kB 3.2 MB/s eta 0:00:00\n",
      "Collecting huggingface-hub>=0.20.0 (from sentence-transformers)\n",
      "  Downloading huggingface_hub-0.29.1-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting Pillow (from sentence-transformers)\n",
      "  Downloading pillow-11.1.0-cp312-cp312-win_amd64.whl.metadata (9.3 kB)\n",
      "Collecting filelock (from huggingface-hub>=0.20.0->sentence-transformers)\n",
      "  Downloading filelock-3.17.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub>=0.20.0->sentence-transformers)\n",
      "  Downloading fsspec-2025.2.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\hp\\documents\\trabajo-4-rn\\venv\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\hp\\documents\\trabajo-4-rn\\venv\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: requests in c:\\users\\hp\\documents\\trabajo-4-rn\\venv\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\hp\\documents\\trabajo-4-rn\\venv\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.12.2)\n",
      "Collecting networkx (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting jinja2 (from torch>=1.11.0->sentence-transformers)\n",
      "  Using cached jinja2-3.1.5-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting setuptools (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading setuptools-75.8.2-py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting sympy==1.13.1 (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch>=1.11.0->sentence-transformers)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\hp\\documents\\trabajo-4-rn\\venv\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\hp\\documents\\trabajo-4-rn\\venv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.2.3)\n",
      "Collecting regex!=2019.12.17 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Downloading regex-2024.11.6-cp312-cp312-win_amd64.whl.metadata (41 kB)\n",
      "     ---------------------------------------- 0.0/41.5 kB ? eta -:--:--\n",
      "     ---------------------------------------- 41.5/41.5 kB 2.1 MB/s eta 0:00:00\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Downloading tokenizers-0.21.0-cp39-abi3-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Downloading safetensors-0.5.3-cp38-abi3-win_amd64.whl.metadata (3.9 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn->sentence-transformers)\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn->sentence-transformers)\n",
      "  Using cached threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch>=1.11.0->sentence-transformers)\n",
      "  Using cached MarkupSafe-3.0.2-cp312-cp312-win_amd64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hp\\documents\\trabajo-4-rn\\venv\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hp\\documents\\trabajo-4-rn\\venv\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hp\\documents\\trabajo-4-rn\\venv\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\documents\\trabajo-4-rn\\venv\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.1.31)\n",
      "Downloading sentence_transformers-3.4.1-py3-none-any.whl (275 kB)\n",
      "   ---------------------------------------- 0.0/275.9 kB ? eta -:--:--\n",
      "   ------------------------------------- - 266.2/275.9 kB 16.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 275.9/275.9 kB 8.6 MB/s eta 0:00:00\n",
      "Downloading huggingface_hub-0.29.1-py3-none-any.whl (468 kB)\n",
      "   ---------------------------------------- 0.0/468.0 kB ? eta -:--:--\n",
      "   --------------------------------------  460.8/468.0 kB 14.5 MB/s eta 0:00:01\n",
      "   --------------------------------------- 468.0/468.0 kB 10.0 MB/s eta 0:00:00\n",
      "Downloading torch-2.6.0-cp312-cp312-win_amd64.whl (204.1 MB)\n",
      "   ---------------------------------------- 0.0/204.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.6/204.1 MB 12.2 MB/s eta 0:00:17\n",
      "   ---------------------------------------- 1.2/204.1 MB 13.2 MB/s eta 0:00:16\n",
      "   ---------------------------------------- 1.6/204.1 MB 12.5 MB/s eta 0:00:17\n",
      "   ---------------------------------------- 2.3/204.1 MB 13.2 MB/s eta 0:00:16\n",
      "    --------------------------------------- 3.0/204.1 MB 13.8 MB/s eta 0:00:15\n",
      "    --------------------------------------- 3.6/204.1 MB 13.6 MB/s eta 0:00:15\n",
      "    --------------------------------------- 4.2/204.1 MB 12.8 MB/s eta 0:00:16\n",
      "    --------------------------------------- 4.8/204.1 MB 12.7 MB/s eta 0:00:16\n",
      "   - -------------------------------------- 5.6/204.1 MB 13.3 MB/s eta 0:00:15\n",
      "   - -------------------------------------- 6.1/204.1 MB 13.4 MB/s eta 0:00:15\n",
      "   - -------------------------------------- 6.7/204.1 MB 13.4 MB/s eta 0:00:15\n",
      "   - -------------------------------------- 7.4/204.1 MB 13.2 MB/s eta 0:00:15\n",
      "   - -------------------------------------- 8.0/204.1 MB 13.4 MB/s eta 0:00:15\n",
      "   - -------------------------------------- 8.6/204.1 MB 13.5 MB/s eta 0:00:15\n",
      "   - -------------------------------------- 9.2/204.1 MB 13.4 MB/s eta 0:00:15\n",
      "   - -------------------------------------- 10.0/204.1 MB 13.7 MB/s eta 0:00:15\n",
      "   -- ------------------------------------- 10.8/204.1 MB 13.9 MB/s eta 0:00:14\n",
      "   -- ------------------------------------- 11.6/204.1 MB 13.9 MB/s eta 0:00:14\n",
      "   -- ------------------------------------- 12.3/204.1 MB 14.2 MB/s eta 0:00:14\n",
      "   -- ------------------------------------- 13.0/204.1 MB 14.6 MB/s eta 0:00:14\n",
      "   -- ------------------------------------- 13.9/204.1 MB 14.9 MB/s eta 0:00:13\n",
      "   -- ------------------------------------- 14.8/204.1 MB 15.2 MB/s eta 0:00:13\n",
      "   --- ------------------------------------ 15.5/204.1 MB 15.6 MB/s eta 0:00:13\n",
      "   --- ------------------------------------ 16.3/204.1 MB 15.2 MB/s eta 0:00:13\n",
      "   --- ------------------------------------ 16.9/204.1 MB 15.2 MB/s eta 0:00:13\n",
      "   --- ------------------------------------ 17.8/204.1 MB 15.6 MB/s eta 0:00:12\n",
      "   --- ------------------------------------ 18.5/204.1 MB 15.6 MB/s eta 0:00:12\n",
      "   --- ------------------------------------ 19.1/204.1 MB 15.6 MB/s eta 0:00:12\n",
      "   --- ------------------------------------ 19.7/204.1 MB 15.6 MB/s eta 0:00:12\n",
      "   --- ------------------------------------ 20.4/204.1 MB 15.2 MB/s eta 0:00:13\n",
      "   ---- ----------------------------------- 20.9/204.1 MB 15.6 MB/s eta 0:00:12\n",
      "   ---- ----------------------------------- 21.5/204.1 MB 15.2 MB/s eta 0:00:12\n",
      "   ---- ----------------------------------- 22.3/204.1 MB 15.2 MB/s eta 0:00:12\n",
      "   ---- ----------------------------------- 23.2/204.1 MB 15.6 MB/s eta 0:00:12\n",
      "   ---- ----------------------------------- 23.9/204.1 MB 15.2 MB/s eta 0:00:12\n",
      "   ---- ----------------------------------- 24.6/204.1 MB 14.9 MB/s eta 0:00:13\n",
      "   ---- ----------------------------------- 25.4/204.1 MB 14.9 MB/s eta 0:00:13\n",
      "   ----- ---------------------------------- 26.1/204.1 MB 14.9 MB/s eta 0:00:12\n",
      "   ----- ---------------------------------- 26.8/204.1 MB 14.9 MB/s eta 0:00:12\n",
      "   ----- ---------------------------------- 27.5/204.1 MB 15.2 MB/s eta 0:00:12\n",
      "   ----- ---------------------------------- 28.1/204.1 MB 15.2 MB/s eta 0:00:12\n",
      "   ----- ---------------------------------- 28.9/204.1 MB 15.6 MB/s eta 0:00:12\n",
      "   ----- ---------------------------------- 29.8/204.1 MB 15.6 MB/s eta 0:00:12\n",
      "   ----- ---------------------------------- 30.4/204.1 MB 15.6 MB/s eta 0:00:12\n",
      "   ------ --------------------------------- 31.3/204.1 MB 16.0 MB/s eta 0:00:11\n",
      "   ------ --------------------------------- 31.9/204.1 MB 16.0 MB/s eta 0:00:11\n",
      "   ------ --------------------------------- 32.4/204.1 MB 16.0 MB/s eta 0:00:11\n",
      "   ------ --------------------------------- 33.0/204.1 MB 15.6 MB/s eta 0:00:11\n",
      "   ------ --------------------------------- 33.7/204.1 MB 15.6 MB/s eta 0:00:11\n",
      "   ------ --------------------------------- 34.4/204.1 MB 16.0 MB/s eta 0:00:11\n",
      "   ------ --------------------------------- 35.2/204.1 MB 16.0 MB/s eta 0:00:11\n",
      "   ------ --------------------------------- 35.7/204.1 MB 16.4 MB/s eta 0:00:11\n",
      "   ------- -------------------------------- 36.5/204.1 MB 16.4 MB/s eta 0:00:11\n",
      "   ------- -------------------------------- 37.5/204.1 MB 16.8 MB/s eta 0:00:10\n",
      "   ------- -------------------------------- 38.3/204.1 MB 16.8 MB/s eta 0:00:10\n",
      "   ------- -------------------------------- 39.3/204.1 MB 16.8 MB/s eta 0:00:10\n",
      "   ------- -------------------------------- 40.2/204.1 MB 16.8 MB/s eta 0:00:10\n",
      "   -------- ------------------------------- 40.9/204.1 MB 17.3 MB/s eta 0:00:10\n",
      "   -------- ------------------------------- 41.4/204.1 MB 16.8 MB/s eta 0:00:10\n",
      "   -------- ------------------------------- 42.0/204.1 MB 17.2 MB/s eta 0:00:10\n",
      "   -------- ------------------------------- 42.9/204.1 MB 18.2 MB/s eta 0:00:09\n",
      "   -------- ------------------------------- 43.6/204.1 MB 18.2 MB/s eta 0:00:09\n",
      "   -------- ------------------------------- 44.4/204.1 MB 17.7 MB/s eta 0:00:10\n",
      "   -------- ------------------------------- 45.2/204.1 MB 17.7 MB/s eta 0:00:09\n",
      "   -------- ------------------------------- 45.8/204.1 MB 17.7 MB/s eta 0:00:09\n",
      "   --------- ------------------------------ 46.6/204.1 MB 17.7 MB/s eta 0:00:09\n",
      "   --------- ------------------------------ 47.3/204.1 MB 17.7 MB/s eta 0:00:09\n",
      "   --------- ------------------------------ 48.1/204.1 MB 17.7 MB/s eta 0:00:09\n",
      "   --------- ------------------------------ 48.8/204.1 MB 17.2 MB/s eta 0:00:10\n",
      "   --------- ------------------------------ 49.4/204.1 MB 17.2 MB/s eta 0:00:09\n",
      "   --------- ------------------------------ 50.3/204.1 MB 16.8 MB/s eta 0:00:10\n",
      "   ---------- ----------------------------- 51.1/204.1 MB 17.2 MB/s eta 0:00:09\n",
      "   ---------- ----------------------------- 52.0/204.1 MB 16.4 MB/s eta 0:00:10\n",
      "   ---------- ----------------------------- 52.7/204.1 MB 16.4 MB/s eta 0:00:10\n",
      "   ---------- ----------------------------- 53.7/204.1 MB 16.4 MB/s eta 0:00:10\n",
      "   ---------- ----------------------------- 54.4/204.1 MB 16.4 MB/s eta 0:00:10\n",
      "   ---------- ----------------------------- 55.2/204.1 MB 16.4 MB/s eta 0:00:10\n",
      "   ---------- ----------------------------- 55.8/204.1 MB 16.4 MB/s eta 0:00:10\n",
      "   ----------- ---------------------------- 56.7/204.1 MB 16.4 MB/s eta 0:00:10\n",
      "   ----------- ---------------------------- 57.3/204.1 MB 16.4 MB/s eta 0:00:09\n",
      "   ----------- ---------------------------- 58.0/204.1 MB 16.4 MB/s eta 0:00:09\n",
      "   ----------- ---------------------------- 58.8/204.1 MB 16.4 MB/s eta 0:00:09\n",
      "   ----------- ---------------------------- 59.6/204.1 MB 16.4 MB/s eta 0:00:09\n",
      "   ----------- ---------------------------- 60.3/204.1 MB 16.4 MB/s eta 0:00:09\n",
      "   ----------- ---------------------------- 61.0/204.1 MB 16.4 MB/s eta 0:00:09\n",
      "   ------------ --------------------------- 61.8/204.1 MB 16.4 MB/s eta 0:00:09\n",
      "   ------------ --------------------------- 62.6/204.1 MB 16.8 MB/s eta 0:00:09\n",
      "   ------------ --------------------------- 63.3/204.1 MB 16.4 MB/s eta 0:00:09\n",
      "   ------------ --------------------------- 63.9/204.1 MB 16.4 MB/s eta 0:00:09\n",
      "   ------------ --------------------------- 64.8/204.1 MB 16.4 MB/s eta 0:00:09\n",
      "   ------------ --------------------------- 65.4/204.1 MB 16.4 MB/s eta 0:00:09\n",
      "   ------------ --------------------------- 66.3/204.1 MB 16.8 MB/s eta 0:00:09\n",
      "   ------------- -------------------------- 67.3/204.1 MB 17.3 MB/s eta 0:00:08\n",
      "   ------------- -------------------------- 68.1/204.1 MB 17.3 MB/s eta 0:00:08\n",
      "   ------------- -------------------------- 69.0/204.1 MB 16.8 MB/s eta 0:00:09\n",
      "   ------------- -------------------------- 69.6/204.1 MB 16.8 MB/s eta 0:00:09\n",
      "   ------------- -------------------------- 70.4/204.1 MB 17.2 MB/s eta 0:00:08\n",
      "   ------------- -------------------------- 71.2/204.1 MB 17.2 MB/s eta 0:00:08\n",
      "   -------------- ------------------------- 72.0/204.1 MB 17.2 MB/s eta 0:00:08\n",
      "   -------------- ------------------------- 72.5/204.1 MB 16.8 MB/s eta 0:00:08\n",
      "   -------------- ------------------------- 73.1/204.1 MB 16.8 MB/s eta 0:00:08\n",
      "   -------------- ------------------------- 73.8/204.1 MB 16.8 MB/s eta 0:00:08\n",
      "   -------------- ------------------------- 74.4/204.1 MB 16.4 MB/s eta 0:00:08\n",
      "   -------------- ------------------------- 75.3/204.1 MB 16.8 MB/s eta 0:00:08\n",
      "   -------------- ------------------------- 76.0/204.1 MB 16.0 MB/s eta 0:00:09\n",
      "   --------------- ------------------------ 77.0/204.1 MB 16.0 MB/s eta 0:00:08\n",
      "   --------------- ------------------------ 77.5/204.1 MB 16.4 MB/s eta 0:00:08\n",
      "   --------------- ------------------------ 78.3/204.1 MB 16.0 MB/s eta 0:00:08\n",
      "   --------------- ------------------------ 79.0/204.1 MB 16.4 MB/s eta 0:00:08\n",
      "   --------------- ------------------------ 79.8/204.1 MB 16.4 MB/s eta 0:00:08\n",
      "   --------------- ------------------------ 80.7/204.1 MB 16.4 MB/s eta 0:00:08\n",
      "   --------------- ------------------------ 81.2/204.1 MB 16.4 MB/s eta 0:00:08\n",
      "   ---------------- ----------------------- 82.1/204.1 MB 16.4 MB/s eta 0:00:08\n",
      "   ---------------- ----------------------- 82.8/204.1 MB 16.8 MB/s eta 0:00:08\n",
      "   ---------------- ----------------------- 83.7/204.1 MB 17.2 MB/s eta 0:00:07\n",
      "   ---------------- ----------------------- 84.5/204.1 MB 17.2 MB/s eta 0:00:07\n",
      "   ---------------- ----------------------- 85.5/204.1 MB 17.2 MB/s eta 0:00:07\n",
      "   ---------------- ----------------------- 86.5/204.1 MB 17.7 MB/s eta 0:00:07\n",
      "   ----------------- ---------------------- 87.1/204.1 MB 17.7 MB/s eta 0:00:07\n",
      "   ----------------- ---------------------- 87.9/204.1 MB 17.7 MB/s eta 0:00:07\n",
      "   ----------------- ---------------------- 88.6/204.1 MB 17.7 MB/s eta 0:00:07\n",
      "   ----------------- ---------------------- 89.4/204.1 MB 17.7 MB/s eta 0:00:07\n",
      "   ----------------- ---------------------- 90.5/204.1 MB 18.2 MB/s eta 0:00:07\n",
      "   ----------------- ---------------------- 91.5/204.1 MB 18.7 MB/s eta 0:00:07\n",
      "   ------------------ --------------------- 92.4/204.1 MB 18.7 MB/s eta 0:00:06\n",
      "   ------------------ --------------------- 93.2/204.1 MB 18.7 MB/s eta 0:00:06\n",
      "   ------------------ --------------------- 93.7/204.1 MB 17.7 MB/s eta 0:00:07\n",
      "   ------------------ --------------------- 94.6/204.1 MB 18.2 MB/s eta 0:00:07\n",
      "   ------------------ --------------------- 95.3/204.1 MB 17.7 MB/s eta 0:00:07\n",
      "   ------------------ --------------------- 95.9/204.1 MB 17.7 MB/s eta 0:00:07\n",
      "   ------------------ --------------------- 96.9/204.1 MB 17.7 MB/s eta 0:00:07\n",
      "   ------------------- -------------------- 97.7/204.1 MB 18.2 MB/s eta 0:00:06\n",
      "   ------------------- -------------------- 98.6/204.1 MB 18.2 MB/s eta 0:00:06\n",
      "   ------------------- -------------------- 99.2/204.1 MB 17.7 MB/s eta 0:00:06\n",
      "   ------------------- ------------------- 100.1/204.1 MB 17.7 MB/s eta 0:00:06\n",
      "   ------------------- ------------------- 100.9/204.1 MB 17.7 MB/s eta 0:00:06\n",
      "   ------------------- ------------------- 101.6/204.1 MB 17.3 MB/s eta 0:00:06\n",
      "   ------------------- ------------------- 102.6/204.1 MB 17.3 MB/s eta 0:00:06\n",
      "   ------------------- ------------------- 103.3/204.1 MB 17.2 MB/s eta 0:00:06\n",
      "   ------------------- ------------------- 104.0/204.1 MB 17.2 MB/s eta 0:00:06\n",
      "   -------------------- ------------------ 104.8/204.1 MB 17.2 MB/s eta 0:00:06\n",
      "   -------------------- ------------------ 105.5/204.1 MB 17.2 MB/s eta 0:00:06\n",
      "   -------------------- ------------------ 106.3/204.1 MB 17.7 MB/s eta 0:00:06\n",
      "   -------------------- ------------------ 107.1/204.1 MB 16.8 MB/s eta 0:00:06\n",
      "   -------------------- ------------------ 107.9/204.1 MB 16.8 MB/s eta 0:00:06\n",
      "   -------------------- ------------------ 108.8/204.1 MB 16.8 MB/s eta 0:00:06\n",
      "   -------------------- ------------------ 109.6/204.1 MB 16.8 MB/s eta 0:00:06\n",
      "   --------------------- ----------------- 110.5/204.1 MB 17.2 MB/s eta 0:00:06\n",
      "   --------------------- ----------------- 111.3/204.1 MB 17.2 MB/s eta 0:00:06\n",
      "   --------------------- ----------------- 112.0/204.1 MB 17.2 MB/s eta 0:00:06\n",
      "   --------------------- ----------------- 113.0/204.1 MB 16.8 MB/s eta 0:00:06\n",
      "   --------------------- ----------------- 113.9/204.1 MB 17.2 MB/s eta 0:00:06\n",
      "   --------------------- ----------------- 114.5/204.1 MB 16.8 MB/s eta 0:00:06\n",
      "   ---------------------- ---------------- 115.3/204.1 MB 17.3 MB/s eta 0:00:06\n",
      "   ---------------------- ---------------- 116.2/204.1 MB 16.8 MB/s eta 0:00:06\n",
      "   ---------------------- ---------------- 117.1/204.1 MB 16.8 MB/s eta 0:00:06\n",
      "   ---------------------- ---------------- 118.0/204.1 MB 17.2 MB/s eta 0:00:06\n",
      "   ---------------------- ---------------- 118.8/204.1 MB 17.3 MB/s eta 0:00:05\n",
      "   ---------------------- ---------------- 119.6/204.1 MB 17.3 MB/s eta 0:00:05\n",
      "   ----------------------- --------------- 120.5/204.1 MB 17.2 MB/s eta 0:00:05\n",
      "   ----------------------- --------------- 121.3/204.1 MB 17.2 MB/s eta 0:00:05\n",
      "   ----------------------- --------------- 122.0/204.1 MB 17.7 MB/s eta 0:00:05\n",
      "   ----------------------- --------------- 122.8/204.1 MB 17.2 MB/s eta 0:00:05\n",
      "   ----------------------- --------------- 123.6/204.1 MB 17.2 MB/s eta 0:00:05\n",
      "   ----------------------- --------------- 124.3/204.1 MB 17.2 MB/s eta 0:00:05\n",
      "   ----------------------- --------------- 124.9/204.1 MB 16.8 MB/s eta 0:00:05\n",
      "   ----------------------- --------------- 125.6/204.1 MB 17.2 MB/s eta 0:00:05\n",
      "   ------------------------ -------------- 126.3/204.1 MB 16.8 MB/s eta 0:00:05\n",
      "   ------------------------ -------------- 127.2/204.1 MB 17.3 MB/s eta 0:00:05\n",
      "   ------------------------ -------------- 127.9/204.1 MB 17.3 MB/s eta 0:00:05\n",
      "   ------------------------ -------------- 128.8/204.1 MB 16.8 MB/s eta 0:00:05\n",
      "   ------------------------ -------------- 129.7/204.1 MB 16.8 MB/s eta 0:00:05\n",
      "   ------------------------ -------------- 130.5/204.1 MB 16.8 MB/s eta 0:00:05\n",
      "   ------------------------- ------------- 131.3/204.1 MB 16.8 MB/s eta 0:00:05\n",
      "   ------------------------- ------------- 132.2/204.1 MB 16.8 MB/s eta 0:00:05\n",
      "   ------------------------- ------------- 133.1/204.1 MB 16.8 MB/s eta 0:00:05\n",
      "   ------------------------- ------------- 133.9/204.1 MB 16.8 MB/s eta 0:00:05\n",
      "   ------------------------- ------------- 134.7/204.1 MB 16.8 MB/s eta 0:00:05\n",
      "   ------------------------- ------------- 135.5/204.1 MB 16.8 MB/s eta 0:00:05\n",
      "   ------------------------- ------------- 136.0/204.1 MB 16.8 MB/s eta 0:00:05\n",
      "   -------------------------- ------------ 136.8/204.1 MB 16.4 MB/s eta 0:00:05\n",
      "   -------------------------- ------------ 137.5/204.1 MB 16.4 MB/s eta 0:00:05\n",
      "   -------------------------- ------------ 138.4/204.1 MB 16.4 MB/s eta 0:00:05\n",
      "   -------------------------- ------------ 139.0/204.1 MB 16.4 MB/s eta 0:00:04\n",
      "   -------------------------- ------------ 139.8/204.1 MB 16.0 MB/s eta 0:00:05\n",
      "   -------------------------- ------------ 140.4/204.1 MB 16.4 MB/s eta 0:00:04\n",
      "   -------------------------- ------------ 141.0/204.1 MB 16.0 MB/s eta 0:00:04\n",
      "   --------------------------- ----------- 141.6/204.1 MB 16.4 MB/s eta 0:00:04\n",
      "   --------------------------- ----------- 142.3/204.1 MB 16.4 MB/s eta 0:00:04\n",
      "   --------------------------- ----------- 143.3/204.1 MB 16.4 MB/s eta 0:00:04\n",
      "   --------------------------- ----------- 144.1/204.1 MB 16.4 MB/s eta 0:00:04\n",
      "   --------------------------- ----------- 144.9/204.1 MB 16.4 MB/s eta 0:00:04\n",
      "   --------------------------- ----------- 145.7/204.1 MB 16.4 MB/s eta 0:00:04\n",
      "   ---------------------------- ---------- 146.6/204.1 MB 16.4 MB/s eta 0:00:04\n",
      "   ---------------------------- ---------- 147.4/204.1 MB 16.8 MB/s eta 0:00:04\n",
      "   ---------------------------- ---------- 148.1/204.1 MB 16.4 MB/s eta 0:00:04\n",
      "   ---------------------------- ---------- 148.8/204.1 MB 16.8 MB/s eta 0:00:04\n",
      "   ---------------------------- ---------- 149.7/204.1 MB 16.8 MB/s eta 0:00:04\n",
      "   ---------------------------- ---------- 150.5/204.1 MB 16.8 MB/s eta 0:00:04\n",
      "   ---------------------------- ---------- 151.4/204.1 MB 17.2 MB/s eta 0:00:04\n",
      "   ----------------------------- --------- 152.2/204.1 MB 16.8 MB/s eta 0:00:04\n",
      "   ----------------------------- --------- 153.0/204.1 MB 16.8 MB/s eta 0:00:04\n",
      "   ----------------------------- --------- 154.0/204.1 MB 16.8 MB/s eta 0:00:03\n",
      "   ----------------------------- --------- 154.8/204.1 MB 16.8 MB/s eta 0:00:03\n",
      "   ----------------------------- --------- 155.4/204.1 MB 17.2 MB/s eta 0:00:03\n",
      "   ----------------------------- --------- 156.2/204.1 MB 16.8 MB/s eta 0:00:03\n",
      "   ------------------------------ -------- 157.1/204.1 MB 17.3 MB/s eta 0:00:03\n",
      "   ------------------------------ -------- 157.7/204.1 MB 16.8 MB/s eta 0:00:03\n",
      "   ------------------------------ -------- 158.7/204.1 MB 16.8 MB/s eta 0:00:03\n",
      "   ------------------------------ -------- 159.2/204.1 MB 16.8 MB/s eta 0:00:03\n",
      "   ------------------------------ -------- 160.0/204.1 MB 16.8 MB/s eta 0:00:03\n",
      "   ------------------------------ -------- 160.7/204.1 MB 17.2 MB/s eta 0:00:03\n",
      "   ------------------------------ -------- 161.5/204.1 MB 16.8 MB/s eta 0:00:03\n",
      "   ------------------------------ -------- 162.2/204.1 MB 17.2 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 163.1/204.1 MB 16.8 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 164.1/204.1 MB 16.8 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 164.9/204.1 MB 16.8 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 165.7/204.1 MB 16.4 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 166.6/204.1 MB 16.8 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 167.4/204.1 MB 16.8 MB/s eta 0:00:03\n",
      "   -------------------------------- ------ 168.0/204.1 MB 17.2 MB/s eta 0:00:03\n",
      "   -------------------------------- ------ 168.9/204.1 MB 17.3 MB/s eta 0:00:03\n",
      "   -------------------------------- ------ 169.7/204.1 MB 17.3 MB/s eta 0:00:02\n",
      "   -------------------------------- ------ 170.6/204.1 MB 17.7 MB/s eta 0:00:02\n",
      "   -------------------------------- ------ 171.5/204.1 MB 17.2 MB/s eta 0:00:02\n",
      "   -------------------------------- ------ 172.1/204.1 MB 17.2 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 173.0/204.1 MB 17.7 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 173.4/204.1 MB 16.8 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 174.2/204.1 MB 16.4 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 175.0/204.1 MB 16.8 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 175.8/204.1 MB 16.8 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 176.6/204.1 MB 16.8 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 177.2/204.1 MB 17.3 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 178.2/204.1 MB 16.8 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 178.8/204.1 MB 16.8 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 179.6/204.1 MB 16.8 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 180.4/204.1 MB 16.8 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 181.3/204.1 MB 17.2 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 182.2/204.1 MB 17.2 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 183.0/204.1 MB 16.8 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 183.6/204.1 MB 16.8 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 184.2/204.1 MB 17.2 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 185.0/204.1 MB 17.2 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 185.9/204.1 MB 17.3 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 186.8/204.1 MB 17.7 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 187.6/204.1 MB 17.7 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 188.2/204.1 MB 17.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 189.0/204.1 MB 17.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 189.7/204.1 MB 17.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 190.6/204.1 MB 17.7 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 191.4/204.1 MB 17.7 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 192.3/204.1 MB 17.3 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 193.0/204.1 MB 17.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 193.8/204.1 MB 17.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 194.6/204.1 MB 17.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 195.6/204.1 MB 18.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 196.6/204.1 MB 17.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 197.2/204.1 MB 17.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 198.2/204.1 MB 18.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  199.2/204.1 MB 18.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  200.2/204.1 MB 18.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  201.0/204.1 MB 18.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  202.0/204.1 MB 18.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  202.7/204.1 MB 18.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  203.7/204.1 MB 18.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  204.1/204.1 MB 19.3 MB/s eta 0:00:01\n",
      "   --------------------------------------  204.1/204.1 MB 19.3 MB/s eta 0:00:01\n",
      "   --------------------------------------  204.1/204.1 MB 19.3 MB/s eta 0:00:01\n",
      "   --------------------------------------  204.1/204.1 MB 19.3 MB/s eta 0:00:01\n",
      "   --------------------------------------  204.1/204.1 MB 19.3 MB/s eta 0:00:01\n",
      "   --------------------------------------  204.1/204.1 MB 19.3 MB/s eta 0:00:01\n",
      "   --------------------------------------  204.1/204.1 MB 19.3 MB/s eta 0:00:01\n",
      "   --------------------------------------  204.1/204.1 MB 19.3 MB/s eta 0:00:01\n",
      "   --------------------------------------  204.1/204.1 MB 19.3 MB/s eta 0:00:01\n",
      "   --------------------------------------- 204.1/204.1 MB 10.9 MB/s eta 0:00:00\n",
      "Downloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "   ---------------------------------------- 0.0/6.2 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.7/6.2 MB 14.6 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 1.4/6.2 MB 14.3 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 2.1/6.2 MB 15.1 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 2.8/6.2 MB 14.9 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 3.5/6.2 MB 15.0 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 4.5/6.2 MB 16.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 5.4/6.2 MB 16.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  6.2/6.2 MB 16.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.2/6.2 MB 15.2 MB/s eta 0:00:00\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "   ---------------------------------------- 0.0/78.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 78.5/78.5 kB 2.2 MB/s eta 0:00:00\n",
      "Downloading transformers-4.49.0-py3-none-any.whl (10.0 MB)\n",
      "   ---------------------------------------- 0.0/10.0 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.6/10.0 MB 18.5 MB/s eta 0:00:01\n",
      "   ----- ---------------------------------- 1.2/10.0 MB 15.9 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 2.1/10.0 MB 16.5 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 2.9/10.0 MB 15.1 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 3.8/10.0 MB 16.1 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 4.7/10.0 MB 16.6 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 5.5/10.0 MB 16.6 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 6.4/10.0 MB 16.9 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 7.4/10.0 MB 17.4 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 7.9/10.0 MB 16.9 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 8.7/10.0 MB 16.9 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 9.6/10.0 MB 17.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 10.0/10.0 MB 16.4 MB/s eta 0:00:00\n",
      "Downloading pillow-11.1.0-cp312-cp312-win_amd64.whl (2.6 MB)\n",
      "   ---------------------------------------- 0.0/2.6 MB ? eta -:--:--\n",
      "   ----------- ---------------------------- 0.8/2.6 MB 24.4 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 1.4/2.6 MB 18.4 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 2.2/2.6 MB 20.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.6/2.6 MB 16.8 MB/s eta 0:00:00\n",
      "Using cached scikit_learn-1.6.1-cp312-cp312-win_amd64.whl (11.1 MB)\n",
      "Downloading scipy-1.15.2-cp312-cp312-win_amd64.whl (40.9 MB)\n",
      "   ---------------------------------------- 0.0/40.9 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.7/40.9 MB 22.5 MB/s eta 0:00:02\n",
      "   - -------------------------------------- 1.3/40.9 MB 14.1 MB/s eta 0:00:03\n",
      "   -- ------------------------------------- 2.3/40.9 MB 15.9 MB/s eta 0:00:03\n",
      "   --- ------------------------------------ 3.2/40.9 MB 17.0 MB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 4.2/40.9 MB 17.8 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 5.2/40.9 MB 17.3 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 6.0/40.9 MB 18.2 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 6.2/40.9 MB 18.1 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 7.4/40.9 MB 17.6 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 8.3/40.9 MB 17.7 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 9.1/40.9 MB 17.2 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 9.8/40.9 MB 17.3 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 10.6/40.9 MB 16.8 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 11.4/40.9 MB 17.2 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 12.5/40.9 MB 17.7 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 13.1/40.9 MB 17.2 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 14.0/40.9 MB 17.2 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 14.7/40.9 MB 17.2 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 15.5/40.9 MB 17.2 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 16.4/40.9 MB 16.8 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 17.0/40.9 MB 18.2 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 17.7/40.9 MB 17.2 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 18.8/40.9 MB 17.2 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 19.5/40.9 MB 17.7 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 20.4/40.9 MB 18.2 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 21.3/40.9 MB 18.2 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 22.4/40.9 MB 17.7 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 23.1/40.9 MB 18.2 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 24.2/40.9 MB 17.7 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 25.1/40.9 MB 18.2 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 26.1/40.9 MB 18.2 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 27.0/40.9 MB 18.7 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 27.8/40.9 MB 18.2 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 28.5/40.9 MB 18.2 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 29.4/40.9 MB 18.7 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 30.3/40.9 MB 18.7 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 30.9/40.9 MB 18.7 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 31.7/40.9 MB 18.7 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 32.2/40.9 MB 17.7 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 33.1/40.9 MB 17.7 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 34.0/40.9 MB 17.7 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 34.8/40.9 MB 17.7 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 35.8/40.9 MB 17.7 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 36.4/40.9 MB 17.7 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 37.3/40.9 MB 17.7 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 37.9/40.9 MB 17.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 38.7/40.9 MB 17.7 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 39.4/40.9 MB 17.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  40.3/40.9 MB 17.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  40.9/40.9 MB 17.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  40.9/40.9 MB 17.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  40.9/40.9 MB 17.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 40.9/40.9 MB 14.9 MB/s eta 0:00:00\n",
      "Downloading fsspec-2025.2.0-py3-none-any.whl (184 kB)\n",
      "   ---------------------------------------- 0.0/184.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 184.5/184.5 kB 5.6 MB/s eta 0:00:00\n",
      "Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Downloading regex-2024.11.6-cp312-cp312-win_amd64.whl (273 kB)\n",
      "   ---------------------------------------- 0.0/273.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 273.6/273.6 kB 8.5 MB/s eta 0:00:00\n",
      "Downloading safetensors-0.5.3-cp38-abi3-win_amd64.whl (308 kB)\n",
      "   ---------------------------------------- 0.0/308.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 308.9/308.9 kB 9.6 MB/s eta 0:00:00\n",
      "Using cached threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Downloading tokenizers-0.21.0-cp39-abi3-win_amd64.whl (2.4 MB)\n",
      "   ---------------------------------------- 0.0/2.4 MB ? eta -:--:--\n",
      "   -------------- ------------------------- 0.9/2.4 MB 27.2 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 1.8/2.4 MB 22.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.4/2.4 MB 19.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.4/2.4 MB 16.9 MB/s eta 0:00:00\n",
      "Downloading filelock-3.17.0-py3-none-any.whl (16 kB)\n",
      "Using cached jinja2-3.1.5-py3-none-any.whl (134 kB)\n",
      "Downloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ------------------- -------------------- 0.8/1.7 MB 17.6 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 1.5/1.7 MB 16.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.7/1.7 MB 13.7 MB/s eta 0:00:00\n",
      "Downloading setuptools-75.8.2-py3-none-any.whl (1.2 MB)\n",
      "   ---------------------------------------- 0.0/1.2 MB ? eta -:--:--\n",
      "   ------------------------------ --------- 0.9/1.2 MB 29.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.2/1.2 MB 15.6 MB/s eta 0:00:00\n",
      "Using cached MarkupSafe-3.0.2-cp312-cp312-win_amd64.whl (15 kB)\n",
      "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "   ---------------------------------------- 0.0/536.2 kB ? eta -:--:--\n",
      "   ------------------------------------ -- 501.8/536.2 kB 30.7 MB/s eta 0:00:01\n",
      "   --------------------------------------- 536.2/536.2 kB 11.2 MB/s eta 0:00:00\n",
      "Installing collected packages: mpmath, tqdm, threadpoolctl, sympy, setuptools, scipy, safetensors, regex, Pillow, networkx, MarkupSafe, joblib, fsspec, filelock, scikit-learn, jinja2, huggingface-hub, torch, tokenizers, transformers, sentence-transformers\n",
      "Successfully installed MarkupSafe-3.0.2 Pillow-11.1.0 filelock-3.17.0 fsspec-2025.2.0 huggingface-hub-0.29.1 jinja2-3.1.5 joblib-1.4.2 mpmath-1.3.0 networkx-3.4.2 regex-2024.11.6 safetensors-0.5.3 scikit-learn-1.6.1 scipy-1.15.2 sentence-transformers-3.4.1 setuptools-75.8.2 sympy-1.13.1 threadpoolctl-3.5.0 tokenizers-0.21.0 torch-2.6.0 tqdm-4.67.1 transformers-4.49.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: chromadb in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (0.6.3)\n",
      "Requirement already satisfied: build>=1.0.3 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from chromadb) (1.2.2.post1)\n",
      "Requirement already satisfied: pydantic>=1.9 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from chromadb) (2.10.6)\n",
      "Requirement already satisfied: chroma-hnswlib==0.7.6 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from chromadb) (0.7.6)\n",
      "Requirement already satisfied: fastapi>=0.95.2 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from chromadb) (0.115.11)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.34.0)\n",
      "Requirement already satisfied: numpy>=1.22.5 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from chromadb) (2.2.3)\n",
      "Requirement already satisfied: posthog>=2.4.0 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from chromadb) (3.18.1)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from chromadb) (4.12.2)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from chromadb) (1.20.1)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from chromadb) (1.30.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from chromadb) (1.30.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from chromadb) (0.51b0)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from chromadb) (1.30.0)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from chromadb) (0.21.0)\n",
      "Requirement already satisfied: pypika>=0.48.9 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from chromadb) (0.48.9)\n",
      "Requirement already satisfied: tqdm>=4.65.0 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from chromadb) (4.67.1)\n",
      "Requirement already satisfied: overrides>=7.3.1 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from chromadb) (7.7.0)\n",
      "Requirement already satisfied: importlib-resources in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from chromadb) (6.5.2)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from chromadb) (1.70.0)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from chromadb) (4.3.0)\n",
      "Requirement already satisfied: typer>=0.9.0 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from chromadb) (0.15.2)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from chromadb) (32.0.1)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from chromadb) (9.0.0)\n",
      "Requirement already satisfied: PyYAML>=6.0.0 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from chromadb) (6.0.2)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from chromadb) (5.1.0)\n",
      "Requirement already satisfied: orjson>=3.9.12 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from chromadb) (3.10.15)\n",
      "Requirement already satisfied: httpx>=0.27.0 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from chromadb) (0.28.1)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from chromadb) (13.9.4)\n",
      "Requirement already satisfied: packaging>=19.1 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from build>=1.0.3->chromadb) (24.2)\n",
      "Requirement already satisfied: pyproject_hooks in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from build>=1.0.3->chromadb) (0.4.6)\n",
      "Requirement already satisfied: starlette<0.47.0,>=0.40.0 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from fastapi>=0.95.2->chromadb) (0.46.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from httpx>=0.27.0->chromadb) (4.8.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from httpx>=0.27.0->chromadb) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from httpx>=0.27.0->chromadb) (1.0.7)\n",
      "Requirement already satisfied: idna in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from httpx>=0.27.0->chromadb) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.14.0)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.38.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
      "Requirement already satisfied: requests in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.32.3)\n",
      "Requirement already satisfied: requests-oauthlib in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.3.0)\n",
      "Requirement already satisfied: durationpy>=0.7 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (0.9)\n",
      "Requirement already satisfied: coloredlogs in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (25.2.10)\n",
      "Requirement already satisfied: protobuf in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (5.29.3)\n",
      "Requirement already satisfied: sympy in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (1.13.1)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.18)\n",
      "Requirement already satisfied: importlib-metadata<=8.5.0,>=6.0 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from opentelemetry-api>=1.2.0->chromadb) (8.5.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.69.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.30.0 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.30.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.30.0 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.30.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.51b0 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.51b0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation==0.51b0 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.51b0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.51b0 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.51b0)\n",
      "Requirement already satisfied: opentelemetry-util-http==0.51b0 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.51b0)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from opentelemetry-instrumentation==0.51b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.17.2)\n",
      "Requirement already satisfied: asgiref~=3.0 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from opentelemetry-instrumentation-asgi==0.51b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (3.8.1)\n",
      "Requirement already satisfied: monotonic>=1.5 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from posthog>=2.4.0->chromadb) (1.6)\n",
      "Requirement already satisfied: backoff>=1.10.0 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
      "Requirement already satisfied: distro>=1.5.0 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from posthog>=2.4.0->chromadb) (1.9.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from pydantic>=1.9->chromadb) (2.27.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from rich>=10.11.0->chromadb) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from rich>=10.11.0->chromadb) (2.19.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from tokenizers>=0.13.2->chromadb) (0.29.1)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from typer>=0.9.0->chromadb) (8.1.8)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
      "Requirement already satisfied: httptools>=0.6.3 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.4)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.1)\n",
      "Requirement already satisfied: watchfiles>=0.13 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.4)\n",
      "Requirement already satisfied: websockets>=10.4 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (15.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
      "Requirement already satisfied: filelock in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.17.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2025.2.0)\n",
      "Requirement already satisfied: zipp>=3.20 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from importlib-metadata<=8.5.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.21.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from requests->kubernetes>=28.1.0->chromadb) (3.4.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from anyio->httpx>=0.27.0->chromadb) (1.3.1)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
      "Requirement already satisfied: pyreadline3 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from humanfriendly>=9.1->coloredlogs->onnxruntime>=1.14.1->chromadb) (3.5.4)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (1.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting google-generativeai\n",
      "  Downloading google_generativeai-0.8.4-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting google-ai-generativelanguage==0.6.15 (from google-generativeai)\n",
      "  Downloading google_ai_generativelanguage-0.6.15-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting google-api-core (from google-generativeai)\n",
      "  Downloading google_api_core-2.24.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting google-api-python-client (from google-generativeai)\n",
      "  Downloading google_api_python_client-2.162.0-py2.py3-none-any.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from google-generativeai) (2.38.0)\n",
      "Requirement already satisfied: protobuf in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from google-generativeai) (5.29.3)\n",
      "Requirement already satisfied: pydantic in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from google-generativeai) (2.10.6)\n",
      "Requirement already satisfied: tqdm in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from google-generativeai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from google-generativeai) (4.12.2)\n",
      "Collecting proto-plus<2.0.0dev,>=1.22.3 (from google-ai-generativelanguage==0.6.15->google-generativeai)\n",
      "  Downloading proto_plus-1.26.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from google-api-core->google-generativeai) (1.69.0)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from google-api-core->google-generativeai) (2.32.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (4.9)\n",
      "Collecting httplib2<1.dev0,>=0.19.0 (from google-api-python-client->google-generativeai)\n",
      "  Downloading httplib2-0.22.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting google-auth-httplib2<1.0.0,>=0.2.0 (from google-api-python-client->google-generativeai)\n",
      "  Downloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting uritemplate<5,>=3.0.1 (from google-api-python-client->google-generativeai)\n",
      "  Downloading uritemplate-4.1.1-py2.py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from pydantic->google-generativeai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from pydantic->google-generativeai) (2.27.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from tqdm->google-generativeai) (0.4.6)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.70.0)\n",
      "Collecting grpcio-status<2.0.dev0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai)\n",
      "  Downloading grpcio_status-1.70.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai)\n",
      "  Downloading pyparsing-3.2.1-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\documents\\trabajo-4-rn\\.venv\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2025.1.31)\n",
      "Downloading google_generativeai-0.8.4-py3-none-any.whl (175 kB)\n",
      "   ---------------------------------------- 0.0/175.4 kB ? eta -:--:--\n",
      "   -------------------------------- ------- 143.4/175.4 kB 4.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 175.4/175.4 kB 3.5 MB/s eta 0:00:00\n",
      "Downloading google_ai_generativelanguage-0.6.15-py3-none-any.whl (1.3 MB)\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   -------- ------------------------------- 0.3/1.3 MB 8.6 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 0.6/1.3 MB 7.6 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 1.0/1.3 MB 7.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.3/1.3 MB 7.0 MB/s eta 0:00:00\n",
      "Downloading google_api_core-2.24.1-py3-none-any.whl (160 kB)\n",
      "   ---------------------------------------- 0.0/160.1 kB ? eta -:--:--\n",
      "   --------------------------------------- 160.1/160.1 kB 10.0 MB/s eta 0:00:00\n",
      "Downloading google_api_python_client-2.162.0-py2.py3-none-any.whl (13.1 MB)\n",
      "   ---------------------------------------- 0.0/13.1 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.5/13.1 MB 10.2 MB/s eta 0:00:02\n",
      "   -- ------------------------------------- 0.9/13.1 MB 11.3 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 1.5/13.1 MB 11.7 MB/s eta 0:00:01\n",
      "   ------ --------------------------------- 2.1/13.1 MB 12.3 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 2.8/13.1 MB 13.0 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 3.3/13.1 MB 12.4 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 3.9/13.1 MB 13.2 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 4.6/13.1 MB 13.4 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 5.3/13.1 MB 13.6 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 6.1/13.1 MB 14.0 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 7.1/13.1 MB 14.7 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 8.1/13.1 MB 14.7 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 8.8/13.1 MB 15.1 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 9.5/13.1 MB 15.2 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 10.1/13.1 MB 15.5 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 10.9/13.1 MB 16.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 11.5/13.1 MB 16.0 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 12.0/13.1 MB 16.0 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 12.7/13.1 MB 16.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  13.1/13.1 MB 16.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 13.1/13.1 MB 15.2 MB/s eta 0:00:00\n",
      "Downloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl (9.3 kB)\n",
      "Downloading httplib2-0.22.0-py3-none-any.whl (96 kB)\n",
      "   ---------------------------------------- 0.0/96.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 96.9/96.9 kB 5.8 MB/s eta 0:00:00\n",
      "Downloading proto_plus-1.26.0-py3-none-any.whl (50 kB)\n",
      "   ---------------------------------------- 0.0/50.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 50.2/50.2 kB 2.5 MB/s eta 0:00:00\n",
      "Downloading uritemplate-4.1.1-py2.py3-none-any.whl (10 kB)\n",
      "Downloading grpcio_status-1.70.0-py3-none-any.whl (14 kB)\n",
      "Downloading pyparsing-3.2.1-py3-none-any.whl (107 kB)\n",
      "   ---------------------------------------- 0.0/107.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 107.7/107.7 kB 3.1 MB/s eta 0:00:00\n",
      "Installing collected packages: uritemplate, pyparsing, proto-plus, httplib2, grpcio-status, google-auth-httplib2, google-api-core, google-api-python-client, google-ai-generativelanguage, google-generativeai\n",
      "Successfully installed google-ai-generativelanguage-0.6.15 google-api-core-2.24.1 google-api-python-client-2.162.0 google-auth-httplib2-0.2.0 google-generativeai-0.8.4 grpcio-status-1.70.0 httplib2-0.22.0 proto-plus-1.26.0 pyparsing-3.2.1 uritemplate-4.1.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install google-generativeai\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leer el documentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cargar_documentos(ruta_archivo):\n",
    "    \"\"\"Carga documentos en PDF, TXT o DOCX y los convierte en texto.\"\"\"\n",
    "    if ruta_archivo.endswith(\".pdf\"):\n",
    "        loader = PyPDFLoader(ruta_archivo)\n",
    "    elif ruta_archivo.endswith(\".txt\"):\n",
    "        loader = TextLoader(ruta_archivo)\n",
    "    elif ruta_archivo.endswith(\".docx\"):\n",
    "        loader = Docx2txtLoader(ruta_archivo)\n",
    "    else:\n",
    "        raise ValueError(\"Formato no soportado. Usa PDF, TXT o DOCX.\")\n",
    "    \n",
    "    documentos = loader.load()\n",
    "    \n",
    "    return documentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'Acrobat Distiller 19.0 (Windows)', 'creator': 'PScript5.dll Version 5.2.2', 'creationdate': '2024-10-30T15:27:39-05:00', 'author': 'USUARIO', 'moddate': '2024-10-30T15:27:39-05:00', 'title': 'Microsoft PowerPoint - 1-01-Curso_PLN', 'source': 'data/1-01-Curso_PLN.pdf', 'total_pages': 4, 'page': 0, 'page_label': '1'}, page_content='30/10/2024\\n3011176 - Procesamiento del Lenguaje \\nNatural\\nFACULTAD DE MINAS\\nSede Medelln\\nSINTELWEB\\nGrupo de Investigacin\\nSistemas Inteligentes Web\\nJAIME ALBERTO GUZMAN LUNA, Ph.D\\nInformacin de contacto\\n\\uf06e Jaime Alberto Guzmn Luna\\n\\uf06e Doctor en Ingeniera de Sistemas e Informtica\\n\\uf06e M.Sc. en Ingeniera de Sistemas e Informtica\\n\\uf06e Especialista en comunicacin educativa\\n\\uf06e Ingeniero Civil\\n\\uf06e reas de trabajo\\n\\uf06e Inteligencia Artificial\\n\\uf06e Sistemas de recuperacin de informacin\\n\\uf06e Planificacin automtica de procesos \\n\\uf06e Aprendizaje de mquinas\\n\\uf06e PLN con aprendizaje profundo\\n\\uf06e Universidad Nacional de Colombia\\n\\uf06e Oficina M8A-306\\n\\uf06e Email: jaguzman@unal.edu.co \\n\\uf06e Horario de Atencin virtual (citas previas): \\n\\uf06e Lunes de 2:30 a 4:30 pm\\n\\uf0a7 Apoyo: \\n\\uf0a7 Alejandro Jimnez Franco\\n\\uf0a7 Email: aljimenezfr@unal.edu.co\\n1\\n2'),\n",
       " Document(metadata={'producer': 'Acrobat Distiller 19.0 (Windows)', 'creator': 'PScript5.dll Version 5.2.2', 'creationdate': '2024-10-30T15:27:39-05:00', 'author': 'USUARIO', 'moddate': '2024-10-30T15:27:39-05:00', 'title': 'Microsoft PowerPoint - 1-01-Curso_PLN', 'source': 'data/1-01-Curso_PLN.pdf', 'total_pages': 4, 'page': 1, 'page_label': '2'}, page_content='30/10/2024\\nObjetivos\\n\\uf06e Objetivo general\\n\\uf06e El objetivo de este curso es proporcionar a los estudiantes las habilidades y\\nconocimientos fundamentales en el campo del Procesamiento de Lenguaje Natural,\\nun campo de la inteligencia artificial que permite a las mquinas comprender y\\nmanipular el lenguaje humano. Los temas abarcan desde el procesamiento de\\ntexto bsico hasta la comprensin del lenguaje, con aplicaciones en anlisis de\\nsentimientos, traduccinautomtica, chatbots y ms.\\n\\uf06e Objetivos especficos\\n\\uf06e Comprender los conceptos clave en Procesamiento del Lenguaje Natural\\nfamiliarizndose con las bibliotecas populares de PLN (como NLTK, SpaCy,\\nTransformers de Hugging Face, etc.)\\n\\uf06e Familiarizarse con las tcnicas y algori tmos utilizados para el procesamiento de\\ntexto, anlisis de sentimiento, clasificacin de texto y extraccin de la informacin.\\n\\uf06e Entender los Modelos de Lenguaje y sus aplicaciones prcticas.\\n\\uf06e Aplicar modelos y herramientas de PLN avanzadas a problemas del mundo real\\n(traduccin automtica, Preguntas&Respuestas- QA, anlisis de conversaciones,\\netc)\\nContenido del Curso (1)\\n\\uf06e TEMA 1: Introduccin al Procesamiento de Lenguaje Natural.\\n\\uf06e Generalidades del Procesamiento de Lenguaje Natural y su importancia.\\n\\uf06e Limpieza y normalizacin de textos en Python\\n\\uf06e Manejo de errores ortogrficos: Pyspellchecker\\n\\uf06e TEMA 2: Procesamiento de Texto.\\n\\uf06e Tareas bsicas de procesamiento de texto: tokenizacin, stopswords,\\nstemming y lematizacin\\n\\uf06e Bibliotecas populares; NLTK, spaCy y TextBlob\\n\\uf06e TEMA 3:Manejo de corpus de texto.\\n\\uf06e Modelos Estadsticos de Lenguaje (N-gramas y modelos probabilsticos;\\nmodelo TF-IDF; e introduccin a la semntica latente-LSA).\\n\\uf06e Creacin de corpus desde textos y la Web (text mining y web scraping)\\n\\uf06e Mtricas bsicas para corpus de texto\\n3\\n4'),\n",
       " Document(metadata={'producer': 'Acrobat Distiller 19.0 (Windows)', 'creator': 'PScript5.dll Version 5.2.2', 'creationdate': '2024-10-30T15:27:39-05:00', 'author': 'USUARIO', 'moddate': '2024-10-30T15:27:39-05:00', 'title': 'Microsoft PowerPoint - 1-01-Curso_PLN', 'source': 'data/1-01-Curso_PLN.pdf', 'total_pages': 4, 'page': 2, 'page_label': '3'}, page_content='30/10/2024\\nContenido del Curso (2)\\n\\uf06e TEMA 4:Anlisis de Sentimientos, clasificacin y extraccin de informacin en textos.\\n\\uf06e Introduccin al anlisis de sentimientos; Mtodos supervisados y no supervisados; y \\nAplicaciones prcticas y casos de estudio\\n\\uf06e Clasificacin de Texto con algoritmos de aprendizaje automtico (Modelos de clasificacin \\npopulares: Naive Bayes, SVM, redes neuronales), Evaluacin de modelos de clasificacin de \\ntexto.\\n\\uf06e Extraccin de Informacin, Reconocimiento de entidades nombradas (NER) y Extraccin de \\nrelaciones entre entidades.\\n\\uf06e TEMA 5:Modelos Avanzados de Representacin de Texto.\\n\\uf06e Word embeddings: Word2Vec, GloVe.\\n\\uf06e Modelos basados en redes neuronales: embeddings de contexto (FastText, ELMo).\\n\\uf06e Transformadores y el modelo BERT. \\n\\uf06e TEMA 6:Generacin de Texto y Modelos de Lenguaje.\\n\\uf06e Redes neuronales recurrentes (RNN) y LSTM.\\n\\uf06e Transformadores para generacin de texto (GPT).\\n\\uf06e Aplicaciones prcticas en PLN Traduccin automtica, chatbots, resumen de texto, QA \\n(Question Answering), anlisis de conversaciones.\\nMetodologa\\n\\uf06e Actividades presenciales: \\n\\uf06e Clases magistrales por parte del docente.\\n\\uf06e Talleres: Alumnos en compaa del docente y monitores\\n\\uf06e Exposiciones de los estudiantes\\n\\uf06e Presentacin de prcticas por parte de los estudiantes.\\n\\uf06e Actividades Asncronas: \\n\\uf06e Videos de temas complementarios\\n\\uf06e Talleres en casa\\n5\\n6'),\n",
       " Document(metadata={'producer': 'Acrobat Distiller 19.0 (Windows)', 'creator': 'PScript5.dll Version 5.2.2', 'creationdate': '2024-10-30T15:27:39-05:00', 'author': 'USUARIO', 'moddate': '2024-10-30T15:27:39-05:00', 'title': 'Microsoft PowerPoint - 1-01-Curso_PLN', 'source': 'data/1-01-Curso_PLN.pdf', 'total_pages': 4, 'page': 3, 'page_label': '4'}, page_content='30/10/2024\\nEvaluacin\\n\\uf06e 2 trabajos prcticos: \\n\\uf06e Prctica 1: Aplicativo para el anlisis de sentimientos desde \\ntextos(25%)\\n\\uf06e Fecha: mircoles 27 de noviembre de 4 a 8 pm. \\n\\uf06e Prctica 2: Aplicativo practico basado en la Generacin de Texto y \\nModelos de Lenguaje (25%)\\n\\uf06e Fecha: mircoles 26 de febrero de 4 a 8 pm.\\n\\uf06e Exposiciones sobre temticas (20%)\\n\\uf06e Fecha mircoles 15 de enero de 4 a 8 pm\\n\\uf06e Seguimiento a Talleres (30%)\\n\\uf06e Mircoles 12 m\\nLecturas y Recursos Recomendados\\n7\\n8')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Leer documento pdf\n",
    "loader = PyPDFLoader(\"data/1-01-Curso_PLN.pdf\")\n",
    "pages = loader.load()\n",
    "pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/10/2024\n",
      "3011176 - Procesamiento del Lenguaje \n",
      "Natural\n",
      "FACULTAD DE MINAS\n",
      "Sede Medelln\n",
      "SINTELWEB\n",
      "Grupo de Investigacin\n",
      "Sistemas Inteligentes Web\n",
      "JAIME ALBERTO GUZMAN LUNA, Ph.D\n",
      "Informacin de contacto\n",
      "- Jaime Alberto Guzmn Luna\n",
      "- Doctor en Ingeniera de Sistemas e Informtica\n",
      "- M.Sc. en Ingeniera de Sistemas e Informtica\n",
      "- Especialista en comunicacin educativa\n",
      "- Ingeniero Civil\n",
      "- reas de trabajo\n",
      "- Inteligencia Artificial\n",
      "- Sistemas de recuperacin de informacin\n",
      "- Planificacin automtica de procesos \n",
      "- Aprendizaje de mquinas\n",
      "- PLN con aprendizaje profundo\n",
      "- Universidad Nacional de Colombia\n",
      "- Oficina M8A-306\n",
      "- Email: jaguzman@unal.edu.co \n",
      "- Horario de Atencin virtual (citas previas): \n",
      "- Lunes de 2:30 a 4:30 pm\n",
      "- Apoyo: \n",
      "- Alejandro Jimnez Franco\n",
      "- Email: aljimenezfr@unal.edu.co\n",
      "1\n",
      "2\n",
      "\n",
      "30/10/2024\n",
      "Objetivos\n",
      "- Objetivo general\n",
      "- El objetivo de este curso es proporcionar a los estudiantes las habilidades y\n",
      "conocimientos fundamentales en el campo del Procesamiento de Lenguaje Natural,\n",
      "un campo de la inteligencia artificial que permite a las mquinas comprender y\n",
      "manipular el lenguaje humano. Los temas abarcan desde el procesamiento de\n",
      "texto bsico hasta la comprensin del lenguaje, con aplicaciones en anlisis de\n",
      "sentimientos, traduccinautomtica, chatbots y ms.\n",
      "- Objetivos especficos\n",
      "- Comprender los conceptos clave en Procesamiento del Lenguaje Natural\n",
      "familiarizndose con las bibliotecas populares de PLN (como NLTK, SpaCy,\n",
      "Transformers de Hugging Face, etc.)\n",
      "- Familiarizarse con las tcnicas y algori tmos utilizados para el procesamiento de\n",
      "texto, anlisis de sentimiento, clasificacin de texto y extraccin de la informacin.\n",
      "- Entender los Modelos de Lenguaje y sus aplicaciones prcticas.\n",
      "- Aplicar modelos y herramientas de PLN avanzadas a problemas del mundo real\n",
      "(traduccin automtica, Preguntas&Respuestas- QA, anlisis de conversaciones,\n",
      "etc)\n",
      "Contenido del Curso (1)\n",
      "- TEMA 1: Introduccin al Procesamiento de Lenguaje Natural.\n",
      "- Generalidades del Procesamiento de Lenguaje Natural y su importancia.\n",
      "- Limpieza y normalizacin de textos en Python\n",
      "- Manejo de errores ortogrficos: Pyspellchecker\n",
      "- TEMA 2: Procesamiento de Texto.\n",
      "- Tareas bsicas de procesamiento de texto: tokenizacin, stopswords,\n",
      "stemming y lematizacin\n",
      "- Bibliotecas populares; NLTK, spaCy y TextBlob\n",
      "- TEMA 3:Manejo de corpus de texto.\n",
      "- Modelos Estadsticos de Lenguaje (N-gramas y modelos probabilsticos;\n",
      "modelo TF-IDF; e introduccin a la semntica latente-LSA).\n",
      "- Creacin de corpus desde textos y la Web (text mining y web scraping)\n",
      "- Mtricas bsicas para corpus de texto\n",
      "3\n",
      "4\n",
      "\n",
      "30/10/2024\n",
      "Contenido del Curso (2)\n",
      "- TEMA 4:Anlisis de Sentimientos, clasificacin y extraccin de informacin en textos.\n",
      "- Introduccin al anlisis de sentimientos; Mtodos supervisados y no supervisados; y \n",
      "Aplicaciones prcticas y casos de estudio\n",
      "- Clasificacin de Texto con algoritmos de aprendizaje automtico (Modelos de clasificacin \n",
      "populares: Naive Bayes, SVM, redes neuronales), Evaluacin de modelos de clasificacin de \n",
      "texto.\n",
      "- Extraccin de Informacin, Reconocimiento de entidades nombradas (NER) y Extraccin de \n",
      "relaciones entre entidades.\n",
      "- TEMA 5:Modelos Avanzados de Representacin de Texto.\n",
      "- Word embeddings: Word2Vec, GloVe.\n",
      "- Modelos basados en redes neuronales: embeddings de contexto (FastText, ELMo).\n",
      "- Transformadores y el modelo BERT. \n",
      "- TEMA 6:Generacin de Texto y Modelos de Lenguaje.\n",
      "- Redes neuronales recurrentes (RNN) y LSTM.\n",
      "- Transformadores para generacin de texto (GPT).\n",
      "- Aplicaciones prcticas en PLN Traduccin automtica, chatbots, resumen de texto, QA \n",
      "(Question Answering), anlisis de conversaciones.\n",
      "Metodologa\n",
      "- Actividades presenciales: \n",
      "- Clases magistrales por parte del docente.\n",
      "- Talleres: Alumnos en compaa del docente y monitores\n",
      "- Exposiciones de los estudiantes\n",
      "- Presentacin de prcticas por parte de los estudiantes.\n",
      "- Actividades Asncronas: \n",
      "- Videos de temas complementarios\n",
      "- Talleres en casa\n",
      "5\n",
      "6\n",
      "\n",
      "30/10/2024\n",
      "Evaluacin\n",
      "- 2 trabajos prcticos: \n",
      "- Prctica 1: Aplicativo para el anlisis de sentimientos desde \n",
      "textos(25%)\n",
      "- Fecha: mircoles 27 de noviembre de 4 a 8 pm. \n",
      "- Prctica 2: Aplicativo practico basado en la Generacin de Texto y \n",
      "Modelos de Lenguaje (25%)\n",
      "- Fecha: mircoles 26 de febrero de 4 a 8 pm.\n",
      "- Exposiciones sobre temticas (20%)\n",
      "- Fecha mircoles 15 de enero de 4 a 8 pm\n",
      "- Seguimiento a Talleres (30%)\n",
      "- Mircoles 12 m\n",
      "Lecturas y Recursos Recomendados\n",
      "7\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "# Cargar el PDF\n",
    "loader = PyPDFLoader(\"data/1-01-Curso_PLN.pdf\")\n",
    "pages = loader.load()\n",
    "\n",
    "# Funcin de limpieza\n",
    "def clean_text(text):\n",
    "    # Eliminar metadatos innecesarios\n",
    "    text = re.sub(r'USUARIO|PScript5\\.dll.*?\\n|Acrobat Distiller.*?\\n', '', text)\n",
    "    \n",
    "    # Reemplazar caracteres especiales (\\uf06e, \\uf0a7, etc.)\n",
    "    text = re.sub(r'[\\uf06e\\uf0a7]', '-', text)\n",
    "\n",
    "    # Eliminar saltos de lnea innecesarios, pero mantener prrafos\n",
    "    text = re.sub(r'\\n+', '\\n', text)\n",
    "\n",
    "    # Eliminar espacios en blanco al inicio y final del texto\n",
    "    text = text.strip()\n",
    "\n",
    "    return text\n",
    "\n",
    "# Limpiar cada pgina\n",
    "cleaned_pages = [clean_text(page.page_content) for page in pages]\n",
    "\n",
    "# Unir todas las pginas en un solo texto limpio\n",
    "final_text = \"\\n\\n\".join(cleaned_pages)\n",
    "\n",
    "# Mostrar el resultado limpio\n",
    "print(final_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fragmento 1:\n",
      "30/10/2024\n",
      "3011176 - Procesamiento del Lenguaje \n",
      "Natural\n",
      "FACULTAD DE MINAS\n",
      "Sede Medelln\n",
      "SINTELWEB\n",
      "Grupo de Investigacin\n",
      "Sistemas Inteligentes Web\n",
      "JAIME ALBERTO GUZMAN LUNA, Ph.D\n",
      "Informacin de contacto\n",
      "- Jaime Alberto Guzmn Luna\n",
      "- Doctor en Ingeniera de Sistemas e Informtica\n",
      "- M.Sc. en Ingeniera de Sistemas e Informtica\n",
      "- Especialista en comunicacin educativa\n",
      "- Ingeniero Civil\n",
      "- reas de trabajo\n",
      "- Inteligencia Artificial\n",
      "- Sistemas de recuperacin de informacin\n",
      "--------------------------------------------------\n",
      "\n",
      "Fragmento 2:\n",
      "- Sistemas de recuperacin de informacin\n",
      "- Planificacin automtica de procesos \n",
      "- Aprendizaje de mquinas\n",
      "- PLN con aprendizaje profundo\n",
      "- Universidad Nacional de Colombia\n",
      "- Oficina M8A-306\n",
      "- Email: jaguzman@unal.edu.co \n",
      "- Horario de Atencin virtual (citas previas): \n",
      "- Lunes de 2:30 a 4:30 pm\n",
      "- Apoyo: \n",
      "- Alejandro Jimnez Franco\n",
      "- Email: aljimenezfr@unal.edu.co\n",
      "1\n",
      "2\n",
      "--------------------------------------------------\n",
      "\n",
      "Fragmento 3:\n",
      "30/10/2024\n",
      "Objetivos\n",
      "- Objetivo general\n",
      "- El objetivo de este curso es proporcionar a los estudiantes las habilidades y\n",
      "conocimientos fundamentales en el campo del Procesamiento de Lenguaje Natural,\n",
      "un campo de la inteligencia artificial que permite a las mquinas comprender y\n",
      "manipular el lenguaje humano. Los temas abarcan desde el procesamiento de\n",
      "texto bsico hasta la comprensin del lenguaje, con aplicaciones en anlisis de\n",
      "sentimientos, traduccinautomtica, chatbots y ms.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "\n",
    "# Paso 1: Convertir el texto limpio en un objeto Document\n",
    "# Asegrate de que final_text es un string que contiene el contenido limpio\n",
    "document = Document(page_content=final_text)  # Debe ser un objeto Document\n",
    "\n",
    "# Paso 2: Funcin para dividir el texto en fragmentos\n",
    "def split_text(document):\n",
    "    \"\"\"Divide el texto en fragmentos ms pequeos para procesamiento.\"\"\"\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=500,      # Nmero de caracteres por fragmento\n",
    "        chunk_overlap=50,    # Traslape entre fragmentos\n",
    "        length_function=len, # Funcin de longitud\n",
    "        separators=[\"\\n\\n\", \"\\n\", \" \"]  # Separadores\n",
    "    )\n",
    "\n",
    "    # Aplicar el splitter al documento (documento debe ser una lista)\n",
    "    textos_fragmentados = text_splitter.split_documents([document])  # Pasamos una lista de documentos\n",
    "\n",
    "    return textos_fragmentados\n",
    "\n",
    "# Paso 3: Ejecutar la funcin y obtener los fragmentos\n",
    "chunks = split_text(document)\n",
    "\n",
    "# Mostrar un fragmento de ejemplo\n",
    "for i, chunk in enumerate(chunks[:3]):  # Mostramos solo los 3 primeros\n",
    "    print(f\"\\nFragmento {i+1}:\\n{chunk.page_content}\\n{'-'*50}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crear embeddings\n",
    "\n",
    "Se har uso de un modelo de Hugging Face all-MiniLM-L6-v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usar modelo de Hugging Face\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Almacenar  embeddings en ChromaDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "def create_vectorstore(chunks, embedding_function, vectorstore_path):\n",
    "\n",
    "    # Lista de valores unicos para documentos\n",
    "    ids = [str(uuid.uuid5(uuid.NAMESPACE_DNS, doc.page_content)) for doc in chunks]\n",
    "    \n",
    "    unique_ids = set()\n",
    "    unique_chunks = []\n",
    "    \n",
    "    unique_chunks = [] \n",
    "    for chunk, id in zip(chunks, ids):     \n",
    "        if id not in unique_ids:       \n",
    "            unique_ids.add(id)\n",
    "            unique_chunks.append(chunk) \n",
    "\n",
    "    #Crea una database de chroma\n",
    "    vectorstore = Chroma.from_documents(documents=unique_chunks, \n",
    "                                        ids=list(unique_ids),\n",
    "                                        embedding=embedding_function, \n",
    "                                        persist_directory = vectorstore_path)\n",
    "\n",
    "    vectorstore.persist()\n",
    "    \n",
    "    return vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = create_vectorstore(chunks=chunck, \n",
    "                                 embedding_function=embeddings, \n",
    "                                 vectorstore_path=\"./vectorstore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Consulta de datos relevantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cargamos el vectorstore\n",
    "database = Chroma(persist_directory=\"vectorstore\",embedding_function=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Eres un asistente para la generacin de materiales educativos basados en un programa de curso.\n",
      "Utiliza la siguiente informacin recuperada para crear materiales de aprendizaje estructurados.\n",
      "\n",
      "---\n",
      "\n",
      "**Ttulo del curso:** Cul es el ttulo del curso? [Document(metadata={'author': 'USUARIO', 'creationdate': '2024-10-30T15:27:39-05:00', 'creator': 'PScript5.dll Version 5.2.2', 'moddate': '2024-10-30T15:27:39-05:00', 'page': 1, 'page_label': '2', 'producer': 'Acrobat Distiller 19.0 (Windows)', 'source': 'data/1-01-Curso_PLN.pdf', 'title': 'Microsoft PowerPoint - 1-01-Curso_PLN', 'total_pages': 4}, page_content='\\uf06e Aplicar modelos y herramientas de PLN avanzadas a problemas del mundo real\\n(traduccin automtica, Preguntas&Respuestas- QA, anlisis de conversaciones,\\netc)\\nContenido del Curso (1)\\n\\uf06e TEMA 1: Introduccin al Procesamiento de Lenguaje Natural.\\n\\uf06e Generalidades del Procesamiento de Lenguaje Natural y su importancia.\\n\\uf06e Limpieza y normalizacin de textos en Python\\n\\uf06e Manejo de errores ortogrficos: Pyspellchecker\\n\\uf06e TEMA 2: Procesamiento de Texto.'), Document(metadata={'author': 'USUARIO', 'creationdate': '2024-10-30T15:27:39-05:00', 'creator': 'PScript5.dll Version 5.2.2', 'moddate': '2024-10-30T15:27:39-05:00', 'page': 1, 'page_label': '2', 'producer': 'Acrobat Distiller 19.0 (Windows)', 'source': 'data/1-01-Curso_PLN.pdf', 'title': 'Microsoft PowerPoint - 1-01-Curso_PLN', 'total_pages': 4}, page_content='30/10/2024\\nObjetivos\\n\\uf06e Objetivo general\\n\\uf06e El objetivo de este curso es proporcionar a los estudiantes las habilidades y\\nconocimientos fundamentales en el campo del Procesamiento de Lenguaje Natural,\\nun campo de la inteligencia artificial que permite a las mquinas comprender y\\nmanipular el lenguaje humano. Los temas abarcan desde el procesamiento de\\ntexto bsico hasta la comprensin del lenguaje, con aplicaciones en anlisis de\\nsentimientos, traduccinautomtica, chatbots y ms.'), Document(metadata={'author': 'USUARIO', 'creationdate': '2024-10-30T15:27:39-05:00', 'creator': 'PScript5.dll Version 5.2.2', 'moddate': '2024-10-30T15:27:39-05:00', 'page': 2, 'page_label': '3', 'producer': 'Acrobat Distiller 19.0 (Windows)', 'source': 'data/1-01-Curso_PLN.pdf', 'title': 'Microsoft PowerPoint - 1-01-Curso_PLN', 'total_pages': 4}, page_content='30/10/2024\\nContenido del Curso (2)\\n\\uf06e TEMA 4:Anlisis de Sentimientos, clasificacin y extraccin de informacin en textos.\\n\\uf06e Introduccin al anlisis de sentimientos; Mtodos supervisados y no supervisados; y \\nAplicaciones prcticas y casos de estudio\\n\\uf06e Clasificacin de Texto con algoritmos de aprendizaje automtico (Modelos de clasificacin \\npopulares: Naive Bayes, SVM, redes neuronales), Evaluacin de modelos de clasificacin de \\ntexto.'), Document(metadata={'author': 'USUARIO', 'creationdate': '2024-10-30T15:27:39-05:00', 'creator': 'PScript5.dll Version 5.2.2', 'moddate': '2024-10-30T15:27:39-05:00', 'page': 2, 'page_label': '3', 'producer': 'Acrobat Distiller 19.0 (Windows)', 'source': 'data/1-01-Curso_PLN.pdf', 'title': 'Microsoft PowerPoint - 1-01-Curso_PLN', 'total_pages': 4}, page_content='\\uf06e Talleres en casa\\n5\\n6')]\n",
      "\n",
      "**Temas principales:** Cules son los temas principales que se cubren en el curso? [Document(metadata={'author': 'USUARIO', 'creationdate': '2024-10-30T15:27:39-05:00', 'creator': 'PScript5.dll Version 5.2.2', 'moddate': '2024-10-30T15:27:39-05:00', 'page': 2, 'page_label': '3', 'producer': 'Acrobat Distiller 19.0 (Windows)', 'source': 'data/1-01-Curso_PLN.pdf', 'title': 'Microsoft PowerPoint - 1-01-Curso_PLN', 'total_pages': 4}, page_content='\\uf06e Transformadores para generacin de texto (GPT).\\n\\uf06e Aplicaciones prcticas en PLN Traduccin automtica, chatbots, resumen de texto, QA \\n(Question Answering), anlisis de conversaciones.\\nMetodologa\\n\\uf06e Actividades presenciales: \\n\\uf06e Clases magistrales por parte del docente.\\n\\uf06e Talleres: Alumnos en compaa del docente y monitores\\n\\uf06e Exposiciones de los estudiantes\\n\\uf06e Presentacin de prcticas por parte de los estudiantes.\\n\\uf06e Actividades Asncronas: \\n\\uf06e Videos de temas complementarios\\n\\uf06e Talleres en casa'), Document(metadata={'author': 'USUARIO', 'creationdate': '2024-10-30T15:27:39-05:00', 'creator': 'PScript5.dll Version 5.2.2', 'moddate': '2024-10-30T15:27:39-05:00', 'page': 2, 'page_label': '3', 'producer': 'Acrobat Distiller 19.0 (Windows)', 'source': 'data/1-01-Curso_PLN.pdf', 'title': 'Microsoft PowerPoint - 1-01-Curso_PLN', 'total_pages': 4}, page_content='\\uf06e Talleres en casa\\n5\\n6'), Document(metadata={'author': 'USUARIO', 'creationdate': '2024-10-30T15:27:39-05:00', 'creator': 'PScript5.dll Version 5.2.2', 'moddate': '2024-10-30T15:27:39-05:00', 'page': 1, 'page_label': '2', 'producer': 'Acrobat Distiller 19.0 (Windows)', 'source': 'data/1-01-Curso_PLN.pdf', 'title': 'Microsoft PowerPoint - 1-01-Curso_PLN', 'total_pages': 4}, page_content='\\uf06e Aplicar modelos y herramientas de PLN avanzadas a problemas del mundo real\\n(traduccin automtica, Preguntas&Respuestas- QA, anlisis de conversaciones,\\netc)\\nContenido del Curso (1)\\n\\uf06e TEMA 1: Introduccin al Procesamiento de Lenguaje Natural.\\n\\uf06e Generalidades del Procesamiento de Lenguaje Natural y su importancia.\\n\\uf06e Limpieza y normalizacin de textos en Python\\n\\uf06e Manejo de errores ortogrficos: Pyspellchecker\\n\\uf06e TEMA 2: Procesamiento de Texto.'), Document(metadata={'author': 'USUARIO', 'creationdate': '2024-10-30T15:27:39-05:00', 'creator': 'PScript5.dll Version 5.2.2', 'moddate': '2024-10-30T15:27:39-05:00', 'page': 1, 'page_label': '2', 'producer': 'Acrobat Distiller 19.0 (Windows)', 'source': 'data/1-01-Curso_PLN.pdf', 'title': 'Microsoft PowerPoint - 1-01-Curso_PLN', 'total_pages': 4}, page_content='30/10/2024\\nObjetivos\\n\\uf06e Objetivo general\\n\\uf06e El objetivo de este curso es proporcionar a los estudiantes las habilidades y\\nconocimientos fundamentales en el campo del Procesamiento de Lenguaje Natural,\\nun campo de la inteligencia artificial que permite a las mquinas comprender y\\nmanipular el lenguaje humano. Los temas abarcan desde el procesamiento de\\ntexto bsico hasta la comprensin del lenguaje, con aplicaciones en anlisis de\\nsentimientos, traduccinautomtica, chatbots y ms.')]\n",
      "\n",
      "**Objetivos de aprendizaje:** Cules son los objetivos de aprendizaje de este curso? [Document(metadata={'author': 'USUARIO', 'creationdate': '2024-10-30T15:27:39-05:00', 'creator': 'PScript5.dll Version 5.2.2', 'moddate': '2024-10-30T15:27:39-05:00', 'page': 2, 'page_label': '3', 'producer': 'Acrobat Distiller 19.0 (Windows)', 'source': 'data/1-01-Curso_PLN.pdf', 'title': 'Microsoft PowerPoint - 1-01-Curso_PLN', 'total_pages': 4}, page_content='30/10/2024\\nContenido del Curso (2)\\n\\uf06e TEMA 4:Anlisis de Sentimientos, clasificacin y extraccin de informacin en textos.\\n\\uf06e Introduccin al anlisis de sentimientos; Mtodos supervisados y no supervisados; y \\nAplicaciones prcticas y casos de estudio\\n\\uf06e Clasificacin de Texto con algoritmos de aprendizaje automtico (Modelos de clasificacin \\npopulares: Naive Bayes, SVM, redes neuronales), Evaluacin de modelos de clasificacin de \\ntexto.'), Document(metadata={'author': 'USUARIO', 'creationdate': '2024-10-30T15:27:39-05:00', 'creator': 'PScript5.dll Version 5.2.2', 'moddate': '2024-10-30T15:27:39-05:00', 'page': 1, 'page_label': '2', 'producer': 'Acrobat Distiller 19.0 (Windows)', 'source': 'data/1-01-Curso_PLN.pdf', 'title': 'Microsoft PowerPoint - 1-01-Curso_PLN', 'total_pages': 4}, page_content='\\uf06e Aplicar modelos y herramientas de PLN avanzadas a problemas del mundo real\\n(traduccin automtica, Preguntas&Respuestas- QA, anlisis de conversaciones,\\netc)\\nContenido del Curso (1)\\n\\uf06e TEMA 1: Introduccin al Procesamiento de Lenguaje Natural.\\n\\uf06e Generalidades del Procesamiento de Lenguaje Natural y su importancia.\\n\\uf06e Limpieza y normalizacin de textos en Python\\n\\uf06e Manejo de errores ortogrficos: Pyspellchecker\\n\\uf06e TEMA 2: Procesamiento de Texto.'), Document(metadata={'author': 'USUARIO', 'creationdate': '2024-10-30T15:27:39-05:00', 'creator': 'PScript5.dll Version 5.2.2', 'moddate': '2024-10-30T15:27:39-05:00', 'page': 0, 'page_label': '1', 'producer': 'Acrobat Distiller 19.0 (Windows)', 'source': 'data/1-01-Curso_PLN.pdf', 'title': 'Microsoft PowerPoint - 1-01-Curso_PLN', 'total_pages': 4}, page_content='\\uf06e Sistemas de recuperacin de informacin\\n\\uf06e Planificacin automtica de procesos \\n\\uf06e Aprendizaje de mquinas\\n\\uf06e PLN con aprendizaje profundo\\n\\uf06e Universidad Nacional de Colombia\\n\\uf06e Oficina M8A-306\\n\\uf06e Email: jaguzman@unal.edu.co \\n\\uf06e Horario de Atencin virtual (citas previas): \\n\\uf06e Lunes de 2:30 a 4:30 pm\\n\\uf0a7 Apoyo: \\n\\uf0a7 Alejandro Jimnez Franco\\n\\uf0a7 Email: aljimenezfr@unal.edu.co\\n1\\n2'), Document(metadata={'author': 'USUARIO', 'creationdate': '2024-10-30T15:27:39-05:00', 'creator': 'PScript5.dll Version 5.2.2', 'moddate': '2024-10-30T15:27:39-05:00', 'page': 2, 'page_label': '3', 'producer': 'Acrobat Distiller 19.0 (Windows)', 'source': 'data/1-01-Curso_PLN.pdf', 'title': 'Microsoft PowerPoint - 1-01-Curso_PLN', 'total_pages': 4}, page_content='\\uf06e Transformadores para generacin de texto (GPT).\\n\\uf06e Aplicaciones prcticas en PLN Traduccin automtica, chatbots, resumen de texto, QA \\n(Question Answering), anlisis de conversaciones.\\nMetodologa\\n\\uf06e Actividades presenciales: \\n\\uf06e Clases magistrales por parte del docente.\\n\\uf06e Talleres: Alumnos en compaa del docente y monitores\\n\\uf06e Exposiciones de los estudiantes\\n\\uf06e Presentacin de prcticas por parte de los estudiantes.\\n\\uf06e Actividades Asncronas: \\n\\uf06e Videos de temas complementarios\\n\\uf06e Talleres en casa')]\n",
      "\n",
      "**Lecturas y recursos recomendados:** Cules son las lecturas o recursos recomendados para este curso? [Document(metadata={'author': 'USUARIO', 'creationdate': '2024-10-30T15:27:39-05:00', 'creator': 'PScript5.dll Version 5.2.2', 'moddate': '2024-10-30T15:27:39-05:00', 'page': 1, 'page_label': '2', 'producer': 'Acrobat Distiller 19.0 (Windows)', 'source': 'data/1-01-Curso_PLN.pdf', 'title': 'Microsoft PowerPoint - 1-01-Curso_PLN', 'total_pages': 4}, page_content='\\uf06e Aplicar modelos y herramientas de PLN avanzadas a problemas del mundo real\\n(traduccin automtica, Preguntas&Respuestas- QA, anlisis de conversaciones,\\netc)\\nContenido del Curso (1)\\n\\uf06e TEMA 1: Introduccin al Procesamiento de Lenguaje Natural.\\n\\uf06e Generalidades del Procesamiento de Lenguaje Natural y su importancia.\\n\\uf06e Limpieza y normalizacin de textos en Python\\n\\uf06e Manejo de errores ortogrficos: Pyspellchecker\\n\\uf06e TEMA 2: Procesamiento de Texto.'), Document(metadata={'author': 'USUARIO', 'creationdate': '2024-10-30T15:27:39-05:00', 'creator': 'PScript5.dll Version 5.2.2', 'moddate': '2024-10-30T15:27:39-05:00', 'page': 2, 'page_label': '3', 'producer': 'Acrobat Distiller 19.0 (Windows)', 'source': 'data/1-01-Curso_PLN.pdf', 'title': 'Microsoft PowerPoint - 1-01-Curso_PLN', 'total_pages': 4}, page_content='\\uf06e Transformadores para generacin de texto (GPT).\\n\\uf06e Aplicaciones prcticas en PLN Traduccin automtica, chatbots, resumen de texto, QA \\n(Question Answering), anlisis de conversaciones.\\nMetodologa\\n\\uf06e Actividades presenciales: \\n\\uf06e Clases magistrales por parte del docente.\\n\\uf06e Talleres: Alumnos en compaa del docente y monitores\\n\\uf06e Exposiciones de los estudiantes\\n\\uf06e Presentacin de prcticas por parte de los estudiantes.\\n\\uf06e Actividades Asncronas: \\n\\uf06e Videos de temas complementarios\\n\\uf06e Talleres en casa'), Document(metadata={'author': 'USUARIO', 'creationdate': '2024-10-30T15:27:39-05:00', 'creator': 'PScript5.dll Version 5.2.2', 'moddate': '2024-10-30T15:27:39-05:00', 'page': 1, 'page_label': '2', 'producer': 'Acrobat Distiller 19.0 (Windows)', 'source': 'data/1-01-Curso_PLN.pdf', 'title': 'Microsoft PowerPoint - 1-01-Curso_PLN', 'total_pages': 4}, page_content='30/10/2024\\nObjetivos\\n\\uf06e Objetivo general\\n\\uf06e El objetivo de este curso es proporcionar a los estudiantes las habilidades y\\nconocimientos fundamentales en el campo del Procesamiento de Lenguaje Natural,\\nun campo de la inteligencia artificial que permite a las mquinas comprender y\\nmanipular el lenguaje humano. Los temas abarcan desde el procesamiento de\\ntexto bsico hasta la comprensin del lenguaje, con aplicaciones en anlisis de\\nsentimientos, traduccinautomtica, chatbots y ms.'), Document(metadata={'author': 'USUARIO', 'creationdate': '2024-10-30T15:27:39-05:00', 'creator': 'PScript5.dll Version 5.2.2', 'moddate': '2024-10-30T15:27:39-05:00', 'page': 1, 'page_label': '2', 'producer': 'Acrobat Distiller 19.0 (Windows)', 'source': 'data/1-01-Curso_PLN.pdf', 'title': 'Microsoft PowerPoint - 1-01-Curso_PLN', 'total_pages': 4}, page_content='\\uf06e Objetivos especficos\\n\\uf06e Comprender los conceptos clave en Procesamiento del Lenguaje Natural\\nfamiliarizndose con las bibliotecas populares de PLN (como NLTK, SpaCy,\\nTransformers de Hugging Face, etc.)\\n\\uf06e Familiarizarse con las tcnicas y algori tmos utilizados para el procesamiento de\\ntexto, anlisis de sentimiento, clasificacin de texto y extraccin de la informacin.\\n\\uf06e Entender los Modelos de Lenguaje y sus aplicaciones prcticas.')]\n",
      "\n",
      "**Preguntas para discusin:** Cules son algunas preguntas para discusin en este curso? [Document(metadata={'author': 'USUARIO', 'creationdate': '2024-10-30T15:27:39-05:00', 'creator': 'PScript5.dll Version 5.2.2', 'moddate': '2024-10-30T15:27:39-05:00', 'page': 2, 'page_label': '3', 'producer': 'Acrobat Distiller 19.0 (Windows)', 'source': 'data/1-01-Curso_PLN.pdf', 'title': 'Microsoft PowerPoint - 1-01-Curso_PLN', 'total_pages': 4}, page_content='\\uf06e Transformadores para generacin de texto (GPT).\\n\\uf06e Aplicaciones prcticas en PLN Traduccin automtica, chatbots, resumen de texto, QA \\n(Question Answering), anlisis de conversaciones.\\nMetodologa\\n\\uf06e Actividades presenciales: \\n\\uf06e Clases magistrales por parte del docente.\\n\\uf06e Talleres: Alumnos en compaa del docente y monitores\\n\\uf06e Exposiciones de los estudiantes\\n\\uf06e Presentacin de prcticas por parte de los estudiantes.\\n\\uf06e Actividades Asncronas: \\n\\uf06e Videos de temas complementarios\\n\\uf06e Talleres en casa'), Document(metadata={'author': 'USUARIO', 'creationdate': '2024-10-30T15:27:39-05:00', 'creator': 'PScript5.dll Version 5.2.2', 'moddate': '2024-10-30T15:27:39-05:00', 'page': 2, 'page_label': '3', 'producer': 'Acrobat Distiller 19.0 (Windows)', 'source': 'data/1-01-Curso_PLN.pdf', 'title': 'Microsoft PowerPoint - 1-01-Curso_PLN', 'total_pages': 4}, page_content='\\uf06e Talleres en casa\\n5\\n6'), Document(metadata={'author': 'USUARIO', 'creationdate': '2024-10-30T15:27:39-05:00', 'creator': 'PScript5.dll Version 5.2.2', 'moddate': '2024-10-30T15:27:39-05:00', 'page': 2, 'page_label': '3', 'producer': 'Acrobat Distiller 19.0 (Windows)', 'source': 'data/1-01-Curso_PLN.pdf', 'title': 'Microsoft PowerPoint - 1-01-Curso_PLN', 'total_pages': 4}, page_content='30/10/2024\\nContenido del Curso (2)\\n\\uf06e TEMA 4:Anlisis de Sentimientos, clasificacin y extraccin de informacin en textos.\\n\\uf06e Introduccin al anlisis de sentimientos; Mtodos supervisados y no supervisados; y \\nAplicaciones prcticas y casos de estudio\\n\\uf06e Clasificacin de Texto con algoritmos de aprendizaje automtico (Modelos de clasificacin \\npopulares: Naive Bayes, SVM, redes neuronales), Evaluacin de modelos de clasificacin de \\ntexto.'), Document(metadata={'author': 'USUARIO', 'creationdate': '2024-10-30T15:27:39-05:00', 'creator': 'PScript5.dll Version 5.2.2', 'moddate': '2024-10-30T15:27:39-05:00', 'page': 1, 'page_label': '2', 'producer': 'Acrobat Distiller 19.0 (Windows)', 'source': 'data/1-01-Curso_PLN.pdf', 'title': 'Microsoft PowerPoint - 1-01-Curso_PLN', 'total_pages': 4}, page_content='\\uf06e Aplicar modelos y herramientas de PLN avanzadas a problemas del mundo real\\n(traduccin automtica, Preguntas&Respuestas- QA, anlisis de conversaciones,\\netc)\\nContenido del Curso (1)\\n\\uf06e TEMA 1: Introduccin al Procesamiento de Lenguaje Natural.\\n\\uf06e Generalidades del Procesamiento de Lenguaje Natural y su importancia.\\n\\uf06e Limpieza y normalizacin de textos en Python\\n\\uf06e Manejo de errores ortogrficos: Pyspellchecker\\n\\uf06e TEMA 2: Procesamiento de Texto.')]\n",
      "\n",
      "**Ejercicios y problemas de prctica:** Qu ejercicios o problemas de prctica se incluyen en el programa del curso? [Document(metadata={'author': 'USUARIO', 'creationdate': '2024-10-30T15:27:39-05:00', 'creator': 'PScript5.dll Version 5.2.2', 'moddate': '2024-10-30T15:27:39-05:00', 'page': 1, 'page_label': '2', 'producer': 'Acrobat Distiller 19.0 (Windows)', 'source': 'data/1-01-Curso_PLN.pdf', 'title': 'Microsoft PowerPoint - 1-01-Curso_PLN', 'total_pages': 4}, page_content='\\uf06e Aplicar modelos y herramientas de PLN avanzadas a problemas del mundo real\\n(traduccin automtica, Preguntas&Respuestas- QA, anlisis de conversaciones,\\netc)\\nContenido del Curso (1)\\n\\uf06e TEMA 1: Introduccin al Procesamiento de Lenguaje Natural.\\n\\uf06e Generalidades del Procesamiento de Lenguaje Natural y su importancia.\\n\\uf06e Limpieza y normalizacin de textos en Python\\n\\uf06e Manejo de errores ortogrficos: Pyspellchecker\\n\\uf06e TEMA 2: Procesamiento de Texto.'), Document(metadata={'author': 'USUARIO', 'creationdate': '2024-10-30T15:27:39-05:00', 'creator': 'PScript5.dll Version 5.2.2', 'moddate': '2024-10-30T15:27:39-05:00', 'page': 2, 'page_label': '3', 'producer': 'Acrobat Distiller 19.0 (Windows)', 'source': 'data/1-01-Curso_PLN.pdf', 'title': 'Microsoft PowerPoint - 1-01-Curso_PLN', 'total_pages': 4}, page_content='30/10/2024\\nContenido del Curso (2)\\n\\uf06e TEMA 4:Anlisis de Sentimientos, clasificacin y extraccin de informacin en textos.\\n\\uf06e Introduccin al anlisis de sentimientos; Mtodos supervisados y no supervisados; y \\nAplicaciones prcticas y casos de estudio\\n\\uf06e Clasificacin de Texto con algoritmos de aprendizaje automtico (Modelos de clasificacin \\npopulares: Naive Bayes, SVM, redes neuronales), Evaluacin de modelos de clasificacin de \\ntexto.'), Document(metadata={'author': 'USUARIO', 'creationdate': '2024-10-30T15:27:39-05:00', 'creator': 'PScript5.dll Version 5.2.2', 'moddate': '2024-10-30T15:27:39-05:00', 'page': 2, 'page_label': '3', 'producer': 'Acrobat Distiller 19.0 (Windows)', 'source': 'data/1-01-Curso_PLN.pdf', 'title': 'Microsoft PowerPoint - 1-01-Curso_PLN', 'total_pages': 4}, page_content='\\uf06e Transformadores para generacin de texto (GPT).\\n\\uf06e Aplicaciones prcticas en PLN Traduccin automtica, chatbots, resumen de texto, QA \\n(Question Answering), anlisis de conversaciones.\\nMetodologa\\n\\uf06e Actividades presenciales: \\n\\uf06e Clases magistrales por parte del docente.\\n\\uf06e Talleres: Alumnos en compaa del docente y monitores\\n\\uf06e Exposiciones de los estudiantes\\n\\uf06e Presentacin de prcticas por parte de los estudiantes.\\n\\uf06e Actividades Asncronas: \\n\\uf06e Videos de temas complementarios\\n\\uf06e Talleres en casa'), Document(metadata={'author': 'USUARIO', 'creationdate': '2024-10-30T15:27:39-05:00', 'creator': 'PScript5.dll Version 5.2.2', 'moddate': '2024-10-30T15:27:39-05:00', 'page': 0, 'page_label': '1', 'producer': 'Acrobat Distiller 19.0 (Windows)', 'source': 'data/1-01-Curso_PLN.pdf', 'title': 'Microsoft PowerPoint - 1-01-Curso_PLN', 'total_pages': 4}, page_content='\\uf06e Sistemas de recuperacin de informacin\\n\\uf06e Planificacin automtica de procesos \\n\\uf06e Aprendizaje de mquinas\\n\\uf06e PLN con aprendizaje profundo\\n\\uf06e Universidad Nacional de Colombia\\n\\uf06e Oficina M8A-306\\n\\uf06e Email: jaguzman@unal.edu.co \\n\\uf06e Horario de Atencin virtual (citas previas): \\n\\uf06e Lunes de 2:30 a 4:30 pm\\n\\uf0a7 Apoyo: \\n\\uf0a7 Alejandro Jimnez Franco\\n\\uf0a7 Email: aljimenezfr@unal.edu.co\\n1\\n2')]\n",
      "\n",
      "---\n",
      "\n",
      "Basndote en la informacin anterior, genera los siguientes materiales educativos:\n",
      "1. Notas detalladas de clase.\n",
      "2. Problemas de prctica con soluciones.\n",
      "3. Preguntas para discusin.\n",
      "4. Objetivos de aprendizaje especficos para cada tema.\n",
      "5. Lecturas y recursos sugeridos.\n",
      "\n",
      "Estructura la respuesta de manera clara y detallada. Si no encuentras algo en el documento puedes utilizar informacin de internet\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "#Hacemos el prompt configurado con el retrieve\n",
    "PROMPT_TEMPLATE = \"\"\"\n",
    "Eres un asistente para la generacin de materiales educativos basados en un programa de curso.\n",
    "Utiliza la siguiente informacin recuperada para crear materiales de aprendizaje estructurados.\n",
    "\n",
    "---\n",
    "\n",
    "**Ttulo del curso:** Cul es el ttulo del curso? {title}\n",
    "\n",
    "**Temas principales:** Cules son los temas principales que se cubren en el curso? {topics}\n",
    "\n",
    "**Objetivos de aprendizaje:** Cules son los objetivos de aprendizaje de este curso? {objectives}\n",
    "\n",
    "**Lecturas y recursos recomendados:** Cules son las lecturas o recursos recomendados para este curso? {resources}\n",
    "\n",
    "**Preguntas para discusin:** Cules son algunas preguntas para discusin en este curso? {discussion_questions}\n",
    "\n",
    "**Ejercicios y problemas de prctica:** Qu ejercicios o problemas de prctica se incluyen en el programa del curso? {practice_problems}\n",
    "\n",
    "---\n",
    "\n",
    "Basndote en la informacin anterior, genera los siguientes materiales educativos:\n",
    "1. Notas detalladas de clase.\n",
    "2. Problemas de prctica con soluciones.\n",
    "3. Preguntas para discusin.\n",
    "4. Objetivos de aprendizaje especficos para cada tema.\n",
    "5. Lecturas y recursos sugeridos.\n",
    "\n",
    "Estructura la respuesta de manera clara y detallada. Si no encuentras algo en el documento puedes utilizar informacin de internet\n",
    "\"\"\"\n",
    "\n",
    "#Llamamos al retriever\n",
    "retriever = vectorstore.as_retriever(search_type=\"similarity\")\n",
    "\n",
    "title = retriever.invoke(\"Cul es el ttulo del curso?\")\n",
    "topics = retriever.invoke(\"Cules son los temas principales que se cubren en el curso?\")\n",
    "objectives = retriever.invoke(\"Cules son los objetivos de aprendizaje de este curso?\")\n",
    "resources = retriever.invoke(\"Cules son las lecturas o recursos recomendados para este curso?\")\n",
    "discussion_questions = retriever.invoke(\"Cules son algunas preguntas para discusin en este curso?\")\n",
    "practice_problems = retriever.invoke(\"Qu ejercicios o problemas de prctica se incluyen en el programa del curso?\")\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_template(PROMPT_TEMPLATE)\n",
    "#Insertamos los valores en el prompt\n",
    "final_prompt = PROMPT_TEMPLATE.format(\n",
    "    title=title,\n",
    "    topics=topics,\n",
    "    objectives=objectives,\n",
    "    resources=resources,\n",
    "    discussion_questions=discussion_questions,\n",
    "    practice_problems=practice_problems\n",
    ")\n",
    "\n",
    "print(final_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definimos el LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importamos el API Key de las variables de entorno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "os.environ['GOOGLE_API_KEY'] = os.getenv('GOOGLE_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementamos el modelo de Gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Absolutamente! Aqu tienes un conjunto de materiales educativos estructurados basados en la informacin proporcionada sobre el curso de Procesamiento del Lenguaje Natural (PLN).\n",
      "\n",
      "**Ttulo del Curso:** Procesamiento del Lenguaje Natural\n",
      "\n",
      "**Objetivo General del Curso:** Proporcionar a los estudiantes las habilidades y conocimientos fundamentales en el campo del Procesamiento del Lenguaje Natural, un campo de la inteligencia artificial que permite a las mquinas comprender y manipular el lenguaje humano.\n",
      "\n",
      "**1. Notas Detalladas de Clase**\n",
      "\n",
      "**TEMA 1: Introduccin al Procesamiento de Lenguaje Natural**\n",
      "\n",
      "*   **Generalidades del Procesamiento de Lenguaje Natural y su importancia:**\n",
      "\n",
      "    *   Definicin de PLN: Campo de la IA que se centra en la interaccin entre computadoras y el lenguaje humano.\n",
      "    *   Importancia: Permite a las mquinas comprender, interpretar y generar lenguaje humano de manera til.\n",
      "    *   Aplicaciones: Amplias y variadas (traduccin automtica, chatbots, anlisis de sentimientos, etc.).\n",
      "*   **Limpieza y normalizacin de textos en Python:**\n",
      "\n",
      "    *   Importancia de la limpieza: Elimina ruido y datos irrelevantes para mejorar la calidad del anlisis.\n",
      "    *   Tcnicas comunes: Eliminacin de maysculas, puntuacin, caracteres especiales, espacios en blanco adicionales.\n",
      "    *   Libreras de Python: `re` (expresiones regulares), `string` (manipulacin de cadenas).\n",
      "*   **Manejo de errores ortogrficos: Pyspellchecker:**\n",
      "\n",
      "    *   Importancia de corregir errores: Mejora la precisin y coherencia del anlisis.\n",
      "    *   `Pyspellchecker`: Biblioteca de Python para detectar y corregir errores ortogrficos.\n",
      "    *   Funcionamiento: Utiliza diccionarios y algoritmos probabilsticos para sugerir correcciones.\n",
      "\n",
      "**TEMA 2: Procesamiento de Texto**\n",
      "\n",
      "*(No hay detalles especficos proporcionados en el extracto, pero se puede asumir que cubre temas como tokenizacin, lematizacin, stemming, etc. - ver abajo en \"Lecturas y Recursos Sugeridos\" para complementar)*\n",
      "\n",
      "**TEMA 4: Anlisis de Sentimientos, clasificacin y extraccin de informacin en textos.**\n",
      "\n",
      "*   **Introduccin al anlisis de sentimientos:**\n",
      "    *   Definicin: Proceso de determinar la emocin o actitud expresada en un texto.\n",
      "    *   Mtodos supervisados: Utilizan datos etiquetados para entrenar modelos de clasificacin.\n",
      "    *   Mtodos no supervisados: Se basan en diccionarios de sentimientos y reglas heursticas.\n",
      "    *   Aplicaciones prcticas y casos de estudio: anlisis de redes sociales, reseas de productos, etc.\n",
      "*   **Clasificacin de Texto con algoritmos de aprendizaje automtico:**\n",
      "    *   Modelos de clasificacin populares: Naive Bayes, SVM, redes neuronales.\n",
      "    *   Evaluacin de modelos de clasificacin de texto.\n",
      "\n",
      "**TEMA Adicional: Transformadores para generacin de texto (GPT)**\n",
      "\n",
      "*   **Transformadores (GPT):**\n",
      "    *   Arquitectura: Funcionamiento interno de los modelos Transformer.\n",
      "    *   Entrenamiento: Cmo se entrenan estos modelos con grandes cantidades de texto.\n",
      "*   **Aplicaciones prcticas en PLN:**\n",
      "    *   Traduccin automtica: De un idioma a otro.\n",
      "    *   Chatbots: Interaccin conversacional con usuarios.\n",
      "    *   Resumen de texto: Generacin de resmenes concisos.\n",
      "    *   QA (Question Answering): Responder preguntas basadas en texto.\n",
      "    *   Anlisis de conversaciones: Identificacin de temas, sentimientos y patrones.\n",
      "\n",
      "**2. Problemas de Prctica con Soluciones**\n",
      "\n",
      "*(Nota: Los problemas aqu son ejemplos y pueden necesitar ser adaptados segn el nivel del curso)*\n",
      "\n",
      "**Tema 1: Limpieza y Normalizacin**\n",
      "\n",
      "*   **Problema:** Dado el siguiente texto, escribe un script en Python para eliminar la puntuacin, convertir todo a minsculas y eliminar las palabras vacas (stop words):\n",
      "\n",
      "    ```python\n",
      "    texto = \"Este es un ejemplo de texto! con... algunas MAYSCULAS y palabras vacas como: el, la, un.\"\n",
      "    ```\n",
      "\n",
      "    *   **Solucin:**\n",
      "\n",
      "    ```python\n",
      "    import string\n",
      "    from nltk.corpus import stopwords\n",
      "    from nltk.tokenize import word_tokenize\n",
      "\n",
      "    texto = \"Este es un ejemplo de texto! con... algunas MAYSCULAS y palabras vacas como: el, la, un.\"\n",
      "\n",
      "    # Eliminar puntuacin\n",
      "    texto = texto.translate(str.maketrans('', '', string.punctuation))\n",
      "\n",
      "    # Convertir a minsculas\n",
      "    texto = texto.lower()\n",
      "\n",
      "    # Tokenizar\n",
      "    tokens = word_tokenize(texto)\n",
      "\n",
      "    # Eliminar palabras vacas\n",
      "    stop_words = set(stopwords.words('spanish'))  # Puedes cambiar a 'english' si es necesario\n",
      "    tokens_sin_stopwords = [w for w in tokens if not w in stop_words]\n",
      "\n",
      "    print(tokens_sin_stopwords)\n",
      "    #Resultado: ['ejemplo', 'texto', 'maysculas', 'palabras', 'vacas']\n",
      "    ```\n",
      "\n",
      "**Tema 2: Anlisis de Sentimientos**\n",
      "\n",
      "*   **Problema:** Utiliza la librera `TextBlob` para determinar el sentimiento (polaridad y subjetividad) de las siguientes frases:\n",
      "\n",
      "    1.  \"Este es un da maravilloso.\"\n",
      "    2.  \"Estoy muy decepcionado con este producto.\"\n",
      "\n",
      "    *   **Solucin:**\n",
      "\n",
      "    ```python\n",
      "    from textblob import TextBlob\n",
      "\n",
      "    frases = [\"Este es un da maravilloso.\", \"Estoy muy decepcionado con este producto.\"]\n",
      "\n",
      "    for frase in frases:\n",
      "        analisis = TextBlob(frase)\n",
      "        polaridad = analisis.sentiment.polarity\n",
      "        subjetividad = analisis.sentiment.subjectivity\n",
      "        print(f\"Frase: {frase}\")\n",
      "        print(f\"Polaridad: {polaridad}, Subjetividad: {subjetividad}\\n\")\n",
      "    ```\n",
      "\n",
      "**Tema 4: Clasificacin de Texto**\n",
      "\n",
      "*   **Problema:** Construir un clasificador Naive Bayes que determine si un mensaje es spam o no spam.\n",
      "*   **Solucin:**\n",
      "\n",
      "    ```python\n",
      "    import nltk\n",
      "    import random\n",
      "    from nltk.corpus import movie_reviews\n",
      "\n",
      "    # construir lista de documentos\n",
      "    documents = [(list(movie_reviews.words(fileid)), category)\n",
      "                 for category in movie_reviews.categories()\n",
      "                 for fileid in movie_reviews.fileids(category)]\n",
      "\n",
      "    random.shuffle(documents)\n",
      "\n",
      "    # definir lista de todas las palabras\n",
      "    all_words = []\n",
      "    for w in movie_reviews.words():\n",
      "        all_words.append(w.lower())\n",
      "\n",
      "    # ordenar palabras por frecuencia\n",
      "    all_words = nltk.FreqDist(all_words)\n",
      "\n",
      "    # seleccionar las 3000 palabras mas frecuentes\n",
      "    word_features = list(all_words.keys())[:3000]\n",
      "\n",
      "    # determinar si las palabras mas frecuentes estan presentes en cada documento\n",
      "    def find_features(document):\n",
      "        words = set(document)\n",
      "        features = {}\n",
      "        for w in word_features:\n",
      "            features[w] = (w in words)\n",
      "\n",
      "        return features\n",
      "\n",
      "    # crea set de features\n",
      "    featuresets = [(find_features(rev), category) for (rev, category) in documents]\n",
      "\n",
      "    # dividir set de features en entrenamiento y test\n",
      "    training_set = featuresets[:1900]\n",
      "    testing_set = featuresets[1900:]\n",
      "\n",
      "    # crear clasificador\n",
      "    classifier = nltk.NaiveBayesClassifier.train(training_set)\n",
      "\n",
      "    print(\"Naive Bayes Algo accuracy percent:\", (nltk.classify.accuracy(classifier, testing_set))*100)\n",
      "\n",
      "    classifier.show_most_informative_features(15)\n",
      "    ```\n",
      "\n",
      "**3. Preguntas para Discusin**\n",
      "\n",
      "*   Cules son los desafos ticos asociados con el uso de modelos de lenguaje como GPT en aplicaciones como la generacin de noticias o la creacin de contenido?\n",
      "*   Cmo podemos mitigar los sesgos presentes en los datos de entrenamiento para evitar la discriminacin en los sistemas de PLN?\n",
      "*   Cul es el futuro del PLN en la interaccin humano-computadora? Cmo cambiar la forma en que interactuamos con las mquinas?\n",
      "*   Cmo se puede mejorar la interpretabilidad de los modelos de PLN para comprender mejor sus decisiones y resultados?\n",
      "*   Cules son las limitaciones actuales de las tcnicas de anlisis de sentimientos y cmo podemos superarlas?\n",
      "*   Qu consideraciones de privacidad son importantes al trabajar con datos de texto para aplicaciones de PLN?\n",
      "*   Cules son algunas formas creativas de aplicar el PLN en campos no tradicionales como la medicina, el arte o la msica?\n",
      "\n",
      "**4. Objetivos de Aprendizaje Especficos para Cada Tema**\n",
      "\n",
      "*   **Tema 1: Introduccin al PLN**\n",
      "    *   Definir el concepto de Procesamiento del Lenguaje Natural y su importancia en el campo de la Inteligencia Artificial.\n",
      "    *   Identificar las principales etapas de un proyecto de PLN (recopilacin de datos, preprocesamiento, modelado, evaluacin).\n",
      "    *   Implementar scripts bsicos en Python para limpiar y normalizar texto.\n",
      "    *   Utilizar la librera `Pyspellchecker` para corregir errores ortogrficos en textos.\n",
      "*   **Tema 2: Procesamiento de Texto**\n",
      "    *   Comprender y aplicar tcnicas de tokenizacin, stemming y lematizacin.\n",
      "    *   Utilizar expresiones regulares para buscar y manipular patrones en texto.\n",
      "    *   Extraer caractersticas relevantes de texto para su uso en modelos de PLN.\n",
      "*   **Tema 4: Anlisis de Sentimientos, Clasificacin y Extraccin de Informacin**\n",
      "    *   Comprender los conceptos fundamentales del anlisis de sentimientos y sus aplicaciones.\n",
      "    *   Implementar mtodos supervisados y no supervisados para el anlisis de sentimientos.\n",
      "    *   Construir y evaluar modelos de clasificacin de texto utilizando algoritmos de aprendizaje automtico (Naive Bayes, SVM, redes neuronales).\n",
      "    *   Aplicar tcnicas de extraccin de informacin para identificar entidades y relaciones en texto.\n",
      "*   **Tema Adicional: Transformadores para Generacin de Texto (GPT)**\n",
      "    *   Comprender la arquitectura y el funcionamiento de los modelos Transformer.\n",
      "    *   Utilizar modelos pre-entrenados como GPT para tareas de generacin de texto (traduccin, chatbots, resumen).\n",
      "    *   Adaptar y ajustar modelos Transformer para aplicaciones especficas de PLN.\n",
      "\n",
      "**5. Lecturas y Recursos Sugeridos**\n",
      "\n",
      "*   **Libros:**\n",
      "    *   \"Speech and Language Processing\" de Jurafsky y Martin (un clsico en el campo).\n",
      "    *   \"Natural Language Processing with Python\" de Steven Bird, Ewan Klein y Edward Loper (NLTK Book).\n",
      "    *   \"Deep Learning for Natural Language Processing\" de Jason Brownlee\n",
      "*   **Bibliotecas de Python:**\n",
      "    *   NLTK (Natural Language Toolkit): [http://www.nltk.org/](http://www.nltk.org/)\n",
      "    *   SpaCy: [https://spacy.io/](https://spacy.io/)\n",
      "    *   Transformers de Hugging Face: [https://huggingface.co/transformers/](https://huggingface.co/transformers/)\n",
      "    *   TextBlob: [https://textblob.readthedocs.io/en/dev/](https://textblob.readthedocs.io/en/dev/)\n",
      "*   **Cursos en lnea:**\n",
      "    *   Coursera: Cursos de PLN ofrecidos por universidades como Stanford, Universidad de Washington, etc.\n",
      "    *   Udemy: Amplia variedad de cursos sobre PLN y aprendizaje profundo.\n",
      "    *   Fast.ai: Cursos prcticos sobre PLN utilizando aprendizaje profundo.\n",
      "*   **Artculos de investigacin:**\n",
      "    *   ACL Anthology: Coleccin de artculos de investigacin en PLN.\n",
      "    *   Google Scholar: Para buscar artculos especficos sobre temas de inters.\n",
      "\n",
      "Espero que este material sea til para tu curso. Avsame si necesitas algo ms!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "# Inicializa el modelo Gemini\n",
    "model = genai.GenerativeModel('gemini-2.0-flash-001')\n",
    "\n",
    "# Genera una respuesta\n",
    "response = model.generate_content(final_prompt)\n",
    "\n",
    "# Imprime la respuesta\n",
    "print(response.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
